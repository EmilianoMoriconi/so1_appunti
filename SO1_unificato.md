
# SISTEMI OPERATIVI- MODULO 1

- [SISTEMI OPERATIVI- MODULO 1](#sistemi-operativi--modulo-1)
  - [Storia dei Sistemi Operativi](#storia-dei-sistemi-operativi)
    - [ðŸ”¹ Introduzione](#-introduzione)
    - [ðŸ”¹ 1. Prima generazione: calcolo manuale e programmazione diretta (anni â€™40 â€“ primi â€™50)](#-1-prima-generazione-calcolo-manuale-e-programmazione-diretta-anni-40--primi-50)
    - [ðŸ”¹ 2. Seconda generazione: sistemi batch (anni â€™50 â€“ metÃ  â€™60)](#-2-seconda-generazione-sistemi-batch-anni-50--metÃ -60)
      - [Funzionamento del sistema batch](#funzionamento-del-sistema-batch)
      - [Caratteristiche](#caratteristiche)
      - [Limiti](#limiti)
    - [ðŸ”¹ 3. Terza generazione: multiprogrammazione e time-sharing (anni â€™60 â€“ â€™70)](#-3-terza-generazione-multiprogrammazione-e-time-sharing-anni-60--70)
      - [Multiprogrammazione](#multiprogrammazione)
      - [Time-sharing](#time-sharing)
      - [Sistemi rappresentativi](#sistemi-rappresentativi)
    - [ðŸ”¹ 4. Quarta generazione: sistemi multiprocessore e distribuiti (anni â€™80 â€“ â€™90)](#-4-quarta-generazione-sistemi-multiprocessore-e-distribuiti-anni-80--90)
      - [Caratteristiche principali](#caratteristiche-principali)
      - [Sistemi notevoli](#sistemi-notevoli)
    - [ðŸ”¹ 5. Quinta generazione: sistemi moderni e virtualizzazione (2000 â€“ oggi)](#-5-quinta-generazione-sistemi-moderni-e-virtualizzazione-2000--oggi)
      - [Tendenze moderne](#tendenze-moderne)
    - [ðŸ”¹ 6. Evoluzione dellâ€™hardware e impatto sul SO](#-6-evoluzione-dellhardware-e-impatto-sul-so)
    - [ðŸ”¹ 7. Timeline sintetica](#-7-timeline-sintetica)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi)
  - [Architettura monoprocessore](#architettura-monoprocessore)
    - [ðŸ”¹ Introduzione](#-introduzione-1)
    - [ðŸ”¹ 1. Struttura generale della CPU](#-1-struttura-generale-della-cpu)
    - [ðŸ”¹ 2. Tipologie di registri](#-2-tipologie-di-registri)
      - [a) Registri utente](#a-registri-utente)
      - [b) Registri di controllo e di stato](#b-registri-di-controllo-e-di-stato)
      - [c) Registri interni (buffer)](#c-registri-interni-buffer)
    - [ðŸ”¹ 3. Ciclo di esecuzione: Fetchâ€“Decodeâ€“Execute](#-3-ciclo-di-esecuzione-fetchdecodeexecute)
      - [a) Fase di Fetch (prelievo)](#a-fase-di-fetch-prelievo)
      - [b) Fase di Decode (decodifica)](#b-fase-di-decode-decodifica)
      - [c) Fase di Execute (esecuzione)](#c-fase-di-execute-esecuzione)
    - [ðŸ”¹ 4. ModalitÃ  di indirizzamento](#-4-modalitÃ -di-indirizzamento)
    - [ðŸ”¹ 5. Ciclo di istruzione e ruolo del sistema operativo](#-5-ciclo-di-istruzione-e-ruolo-del-sistema-operativo)
    - [ðŸ”¹ 6. Categorie di istruzioni macchina](#-6-categorie-di-istruzioni-macchina)
    - [ðŸ”¹ 7. Interazione CPU â€“ Memoria â€“ I/O](#-7-interazione-cpu--memoria--io)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-1)
  - [Memorie + Sistema Operativo](#memorie--sistema-operativo)
    - [ðŸ”¹ Introduzione generale](#-introduzione-generale)
    - [ðŸ”¹ 1. Gerarchia delle memorie](#-1-gerarchia-delle-memorie)
      - [Struttura a livelli](#struttura-a-livelli)
    - [ðŸ”¹ 2. Tipologie di memoria](#-2-tipologie-di-memoria)
      - [a) Memoria primaria](#a-memoria-primaria)
      - [b) Memoria secondaria](#b-memoria-secondaria)
      - [c) Memoria terziaria e virtuale](#c-memoria-terziaria-e-virtuale)
    - [ðŸ”¹ 3. Memoria cache](#-3-memoria-cache)
      - [Principio di localitÃ ](#principio-di-localitÃ )
      - [Organizzazione](#organizzazione)
      - [Politiche di scrittura](#politiche-di-scrittura)
    - [ðŸ”¹ 4. Mappatura e sostituzione in cache](#-4-mappatura-e-sostituzione-in-cache)
      - [Tipi di mappatura](#tipi-di-mappatura)
      - [Politiche di rimpiazzo](#politiche-di-rimpiazzo)
    - [ðŸ”¹ 5. Ruolo del Sistema Operativo nella memoria](#-5-ruolo-del-sistema-operativo-nella-memoria)
      - [Meccanismi principali](#meccanismi-principali)
    - [ðŸ”¹ 6. Struttura logica del Sistema Operativo](#-6-struttura-logica-del-sistema-operativo)
      - [a) Kernel](#a-kernel)
      - [b) Shell e interfaccia utente](#b-shell-e-interfaccia-utente)
      - [c) Livelli di astrazione del SO](#c-livelli-di-astrazione-del-so)
    - [ðŸ”¹ 7. Kernel vs Microkernel](#-7-kernel-vs-microkernel)
      - [Kernel monolitico](#kernel-monolitico)
      - [Microkernel](#microkernel)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-2)
  - [Interrupt e I/O](#interrupt-e-io)
    - [ðŸ”¹ Introduzione](#-introduzione-2)
    - [ðŸ”¹ 1. Concetto di interrupt](#-1-concetto-di-interrupt)
    - [ðŸ”¹ 2. Tipologie di interrupt](#-2-tipologie-di-interrupt)
      - [a) Interrupt hardware](#a-interrupt-hardware)
      - [b) Interrupt software](#b-interrupt-software)
      - [c) Classificazione funzionale](#c-classificazione-funzionale)
    - [ðŸ”¹ 3. Meccanismo di gestione di un interrupt](#-3-meccanismo-di-gestione-di-un-interrupt)
      - [Fasi principali](#fasi-principali)
    - [ðŸ”¹ 4. Vettore degli interrupt](#-4-vettore-degli-interrupt)
    - [ðŸ”¹ 5. Gestione sequenziale e annidata degli interrupt](#-5-gestione-sequenziale-e-annidata-degli-interrupt)
      - [a) Gestione sequenziale](#a-gestione-sequenziale)
      - [b) Gestione annidata](#b-gestione-annidata)
    - [ðŸ”¹ 6. Context switch e interrupt](#-6-context-switch-e-interrupt)
    - [ðŸ”¹ 7. Tecniche di I/O](#-7-tecniche-di-io)
      - [a) I/O programmato](#a-io-programmato)
      - [b) I/O con interrupt](#b-io-con-interrupt)
      - [c) I/O con DMA (Direct Memory Access)](#c-io-con-dma-direct-memory-access)
    - [ðŸ”¹ 8. Ruolo del sistema operativo negli interrupt e nellâ€™I/O](#-8-ruolo-del-sistema-operativo-negli-interrupt-e-nellio)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-3)
  - [Gestione I/O (I)](#gestione-io-i)
    - [ðŸ”¹ Introduzione](#-introduzione-3)
    - [ðŸ”¹ 1. Architettura del sottosistema I/O](#-1-architettura-del-sottosistema-io)
      - [Livelli principali](#livelli-principali)
      - [Flusso generale](#flusso-generale)
    - [ðŸ”¹ 2. Componenti dellâ€™I/O](#-2-componenti-dellio)
      - [a) Device Controller](#a-device-controller)
      - [b) Device Driver](#b-device-driver)
    - [ðŸ”¹ 3. Tecniche di comunicazione CPUâ€“Dispositivo](#-3-tecniche-di-comunicazione-cpudispositivo)
      - [a) I/O programmato (Polling)](#a-io-programmato-polling)
      - [b) I/O con interrupt](#b-io-con-interrupt-1)
      - [c) I/O con DMA (Direct Memory Access)](#c-io-con-dma-direct-memory-access-1)
    - [ðŸ”¹ 4. Bufferizzazione](#-4-bufferizzazione)
      - [Tipi di buffer](#tipi-di-buffer)
        - [a) Single Buffer](#a-single-buffer)
        - [b) Double Buffer](#b-double-buffer)
        - [c) Circular Buffer](#c-circular-buffer)
      - [Vantaggi](#vantaggi)
      - [Svantaggi](#svantaggi)
    - [ðŸ”¹ 5. Spooling](#-5-spooling)
      - [Funzionamento](#funzionamento)
      - [Vantaggi](#vantaggi-1)
    - [ðŸ”¹ 6. Struttura software del sistema I/O](#-6-struttura-software-del-sistema-io)
      - [Livelli tipici](#livelli-tipici)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-4)
  - [Gestione I/O (II)](#gestione-io-ii)
    - [ðŸ”¹ Introduzione](#-introduzione-4)
    - [ðŸ”¹ 1. Struttura fisica e tempi di accesso al disco](#-1-struttura-fisica-e-tempi-di-accesso-al-disco)
      - [Tempi di accesso](#tempi-di-accesso)
    - [ðŸ”¹ 2. Scheduling dei dischi](#-2-scheduling-dei-dischi)
      - [a) FCFS â€“ *First Come, First Served*](#a-fcfs--first-come-first-served)
      - [b) SSTF â€“ *Shortest Seek Time First*](#b-sstf--shortest-seek-time-first)
      - [c) SCAN (Elevator Algorithm)](#c-scan-elevator-algorithm)
      - [d) C-SCAN â€“ *Circular SCAN*](#d-c-scan--circular-scan)
      - [e) LOOK e C-LOOK](#e-look-e-c-look)
      - [f) Confronto generale](#f-confronto-generale)
    - [ðŸ”¹ 3. RAID â€“ Redundant Array of Independent Disks](#-3-raid--redundant-array-of-independent-disks)
      - [Motivazioni](#motivazioni)
      - [Livelli principali](#livelli-principali-1)
      - [Considerazioni](#considerazioni)
    - [ðŸ”¹ 4. HDD vs SSD](#-4-hdd-vs-ssd)
      - [HDD (Hard Disk Drive)](#hdd-hard-disk-drive)
      - [SSD (Solid State Drive)](#ssd-solid-state-drive)
      - [Implicazioni per il sistema operativo](#implicazioni-per-il-sistema-operativo)
    - [ðŸ”¹ 5. Gestione I/O in Linux](#-5-gestione-io-in-linux)
      - [Sottosistema del block I/O](#sottosistema-del-block-io)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-5)
  - [Processi](#processi)
    - [ðŸ”¹ Introduzione](#-introduzione-5)
    - [ðŸ”¹ 1. Processo vs programma](#-1-processo-vs-programma)
    - [ðŸ”¹ 2. Componenti di un processo](#-2-componenti-di-un-processo)
      - [a) Spazio di indirizzamento (address space)](#a-spazio-di-indirizzamento-address-space)
      - [b) Stato e contesto](#b-stato-e-contesto)
    - [ðŸ”¹ 3. Stati del processo](#-3-stati-del-processo)
      - [a) Modello a 2 stati](#a-modello-a-2-stati)
      - [b) Modello a 5 stati](#b-modello-a-5-stati)
      - [c) Stati sospesi](#c-stati-sospesi)
    - [ðŸ”¹ 4. Transizioni di stato](#-4-transizioni-di-stato)
      - [Casi principali](#casi-principali)
    - [ðŸ”¹ 5. PCB â€“ Process Control Block](#-5-pcb--process-control-block)
      - [Struttura tipica del PCB](#struttura-tipica-del-pcb)
    - [ðŸ”¹ 6. Code di processi](#-6-code-di-processi)
    - [ðŸ”¹ 7. Operazioni sui processi](#-7-operazioni-sui-processi)
      - [a) Creazione](#a-creazione)
      - [b) Terminazione](#b-terminazione)
      - [c) Blocco e sblocco](#c-blocco-e-sblocco)
    - [ðŸ”¹ 8. Processi e gerarchie](#-8-processi-e-gerarchie)
    - [ðŸ”¹ 9. Relazione con i thread](#-9-relazione-con-i-thread)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-6)
  - [ðŸ“˜ Thread](#-thread)
    - [ðŸ”¹ Introduzione generale](#-introduzione-generale-1)
    - [ðŸ”¹ Vantaggi dellâ€™approccio multithread](#-vantaggi-dellapproccio-multithread)
    - [ðŸ”¹ Thread a livello utente (ULT) e a livello kernel (KLT)](#-thread-a-livello-utente-ult-e-a-livello-kernel-klt)
      - [â–«ï¸ Thread a livello utente (ULT)](#ï¸-thread-a-livello-utente-ult)
      - [â–«ï¸ Thread a livello kernel (KLT)](#ï¸-thread-a-livello-kernel-klt)
      - [â–«ï¸ Riepilogo comparativo ULT vs KLT](#ï¸-riepilogo-comparativo-ult-vs-klt)
    - [ðŸ”¹ Operazioni fondamentali sui thread](#-operazioni-fondamentali-sui-thread)
    - [ðŸ”¹ Thread in Linux: LWP e PCB](#-thread-in-linux-lwp-e-pcb)
      - [Stati principali in Linux](#stati-principali-in-linux)
    - [ðŸ”¹ Sintesi finale](#-sintesi-finale)
    - [ðŸ”¹ Sincronizzazione tra Thread](#-sincronizzazione-tra-thread)
      - [â–«ï¸ Problema di concorrenza e sezione critica](#ï¸-problema-di-concorrenza-e-sezione-critica)
    - [ðŸ”¹ Strumenti di sincronizzazione](#-strumenti-di-sincronizzazione)
      - [1. **Mutex (Mutual Exclusion Lock)**](#1-mutex-mutual-exclusion-lock)
      - [2. **Semafori**](#2-semafori)
      - [3. **Condition Variable**](#3-condition-variable)
      - [4. **Join e sincronizzazione del flusso**](#4-join-e-sincronizzazione-del-flusso)
      - [5. **Barrier**](#5-barrier)
    - [ðŸ”¹ Problemi tipici della sincronizzazione](#-problemi-tipici-della-sincronizzazione)
      - [â–«ï¸ Deadlock](#ï¸-deadlock)
      - [â–«ï¸ Starvation](#ï¸-starvation)
      - [â–«ï¸ Busy waiting e spinlock](#ï¸-busy-waiting-e-spinlock)
    - [ðŸ”¹ Sincronizzazione in Linux](#-sincronizzazione-in-linux)
    - [ðŸ”¹ Sintesi generale](#-sintesi-generale)
  - [Scheduling](#scheduling)
    - [ðŸ”¹ Introduzione generale](#-introduzione-generale-2)
    - [ðŸ”¹ Obiettivi dello scheduling](#-obiettivi-dello-scheduling)
      - [1. Obiettivi nei sistemi batch](#1-obiettivi-nei-sistemi-batch)
      - [2. Obiettivi nei sistemi interattivi](#2-obiettivi-nei-sistemi-interattivi)
      - [3. Compromessi](#3-compromessi)
    - [ðŸ”¹ Tipi di scheduling](#-tipi-di-scheduling)
      - [1. Long-Term Scheduling (a lungo termine)](#1-long-term-scheduling-a-lungo-termine)
      - [2. Medium-Term Scheduling (a medio termine)](#2-medium-term-scheduling-a-medio-termine)
      - [3. Short-Term Scheduling (a breve termine)](#3-short-term-scheduling-a-breve-termine)
      - [4. I/O Scheduling](#4-io-scheduling)
    - [ðŸ”¹ Tipologie di scheduling: preemptive vs non-preemptive](#-tipologie-di-scheduling-preemptive-vs-non-preemptive)
    - [ðŸ”¹ Algoritmi di scheduling della CPU](#-algoritmi-di-scheduling-della-cpu)
      - [FCFS â€“ *First Come, First Served*](#fcfs--first-come-first-served)
      - [RR â€“ *Round Robin*](#rr--round-robin)
      - [SPN â€“ *Shortest Process Next* (o SJF â€“ Shortest Job First)](#spn--shortest-process-next-o-sjf--shortest-job-first)
      - [SRT â€“ *Shortest Remaining Time*](#srt--shortest-remaining-time)
      - [HRRN â€“ *Highest Response Ratio Next*](#hrrn--highest-response-ratio-next)
      - [Tabella comparativa algoritmi](#tabella-comparativa-algoritmi)
    - [ðŸ”¹ Scheduling multiprocessore e Scheduling UNIX/Linux](#-scheduling-multiprocessore-e-scheduling-unixlinux)
    - [ðŸ”¹ 1. Introduzione](#-1-introduzione)
    - [ðŸ”¹ 2. Tipologie di scheduling multiprocessore](#-2-tipologie-di-scheduling-multiprocessore)
      - [a) Asymmetric Multiprocessing (AMP)](#a-asymmetric-multiprocessing-amp)
      - [b) Symmetric Multiprocessing (SMP)](#b-symmetric-multiprocessing-smp)
    - [ðŸ”¹ 3. CPU Affinity](#-3-cpu-affinity)
      - [Tipi di affinitÃ ](#tipi-di-affinitÃ )
        - [1. Soft affinity](#1-soft-affinity)
        - [2. Hard affinity](#2-hard-affinity)
    - [ðŸ”¹ 4. Load Balancing](#-4-load-balancing)
      - [Strategie principali](#strategie-principali)
        - [Push migration](#push-migration)
        - [Pull migration](#pull-migration)
    - [ðŸ”¹ 5. Scheduling in UNIX / Linux](#-5-scheduling-in-unix--linux)
    - [ðŸ”¹ 6. Scheduler O(1)](#-6-scheduler-o1)
      - [Struttura](#struttura)
      - [Caratteristiche principali](#caratteristiche-principali-1)
    - [ðŸ”¹ 7. Completely Fair Scheduler (CFS)](#-7-completely-fair-scheduler-cfs)
      - [Principio di funzionamento](#principio-di-funzionamento)
      - [Vantaggi del CFS](#vantaggi-del-cfs)
      - [Intervallo temporale](#intervallo-temporale)
    - [ðŸ”¹ 8. Politiche di scheduling in Linux](#-8-politiche-di-scheduling-in-linux)
    - [ðŸ”¹ 9. Struttura del PCB in Linux per lo scheduling](#-9-struttura-del-pcb-in-linux-per-lo-scheduling)
    - [ðŸ”¹ 10. Sintesi concettuale per mappa](#-10-sintesi-concettuale-per-mappa)
  - [Sincronizzazione (I)](#sincronizzazione-i)
    - [ðŸ”¹ Introduzione](#-introduzione-6)
    - [ðŸ”¹ 1. Sezione critica](#-1-sezione-critica)
      - [Struttura generale di un processo](#struttura-generale-di-un-processo)
    - [ðŸ”¹ 2. Condizioni di competizione (Race Conditions)](#-2-condizioni-di-competizione-race-conditions)
      - [Esempio classico](#esempio-classico)
    - [ðŸ”¹ 3. Soluzioni software alla mutua esclusione](#-3-soluzioni-software-alla-mutua-esclusione)
      - [a) Disabilitazione degli interrupt (solo kernel)](#a-disabilitazione-degli-interrupt-solo-kernel)
      - [b) Soluzione di Peterson](#b-soluzione-di-peterson)
      - [c) Algoritmo del panettiere (Bakery Algorithm)](#c-algoritmo-del-panettiere-bakery-algorithm)
    - [ðŸ”¹ 4. Soluzioni hardware](#-4-soluzioni-hardware)
      - [a) Test-and-Set](#a-test-and-set)
      - [b) Swap (Exchange)](#b-swap-exchange)
      - [c) Compare-and-Swap (CAS)](#c-compare-and-swap-cas)
    - [ðŸ”¹ 5. Semafori](#-5-semafori)
      - [Tipologie di semafori](#tipologie-di-semafori)
      - [Vantaggi](#vantaggi-2)
      - [Svantaggi](#svantaggi-1)
    - [ðŸ”¹ 6. Problema Produttoreâ€“Consumatore](#-6-problema-produttoreconsumatore)
      - [Descrizione](#descrizione)
      - [Soluzione con semafori](#soluzione-con-semafori)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-7)
  - [Sincronizzazione (II)](#sincronizzazione-ii)
    - [ðŸ”¹ Introduzione](#-introduzione-7)
    - [ðŸ”¹ 1. Monitor](#-1-monitor)
      - [Concetto](#concetto)
      - [Variabili di condizione](#variabili-di-condizione)
      - [Vantaggi](#vantaggi-3)
      - [Svantaggi](#svantaggi-2)
    - [ðŸ”¹ 2. Deadlock](#-2-deadlock)
      - [Esempio classico](#esempio-classico-1)
    - [ðŸ”¹ 3. Condizioni necessarie per il deadlock](#-3-condizioni-necessarie-per-il-deadlock)
    - [ðŸ”¹ 4. Rappresentazione con il grafo delle risorse](#-4-rappresentazione-con-il-grafo-delle-risorse)
      - [Esempio](#esempio)
    - [ðŸ”¹ 5. Strategie per la gestione del deadlock](#-5-strategie-per-la-gestione-del-deadlock)
      - [a) Prevenzione](#a-prevenzione)
      - [b) Evitamento (Dynamic avoidance)](#b-evitamento-dynamic-avoidance)
      - [c) Rilevazione e recupero](#c-rilevazione-e-recupero)
    - [ðŸ”¹ 6. Algoritmo del Banchiere (Bankerâ€™s Algorithm)](#-6-algoritmo-del-banchiere-bankers-algorithm)
      - [Concetto](#concetto-1)
      - [Parametri principali](#parametri-principali)
      - [Procedura](#procedura)
      - [Esempio (semplificato)](#esempio-semplificato)
      - [Limiti](#limiti-1)
    - [ðŸ”¹ 7. Riepilogo comparativo](#-7-riepilogo-comparativo)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-8)
  - [Gestione della memoria (I)](#gestione-della-memoria-i)
    - [ðŸ”¹ Introduzione](#-introduzione-8)
    - [ðŸ”¹ 1. Rilocazione](#-1-rilocazione)
      - [Concetto](#concetto-2)
        - [1. Rilocazione statica](#1-rilocazione-statica)
        - [2. Rilocazione dinamica](#2-rilocazione-dinamica)
      - [Implementazione hardware](#implementazione-hardware)
    - [ðŸ”¹ 2. Protezione](#-2-protezione)
      - [Meccanismi di protezione](#meccanismi-di-protezione)
    - [ðŸ”¹ 3. Partizionamento della memoria](#-3-partizionamento-della-memoria)
      - [Tipi principali](#tipi-principali)
        - [1. Partizionamento fisso (Fixed Partitioning)](#1-partizionamento-fisso-fixed-partitioning)
        - [2. Partizionamento variabile (Dynamic Partitioning)](#2-partizionamento-variabile-dynamic-partitioning)
    - [ðŸ”¹ 4. Buddy System](#-4-buddy-system)
      - [Funzionamento](#funzionamento-1)
        - [Allocazione](#allocazione)
        - [Deallocazione](#deallocazione)
      - [Vantaggi](#vantaggi-4)
      - [Svantaggi](#svantaggi-3)
    - [ðŸ”¹ 5. Considerazioni generali](#-5-considerazioni-generali)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-9)
  - [Gestione della memoria (II)](#gestione-della-memoria-ii)
    - [ðŸ”¹ Introduzione](#-introduzione-9)
    - [ðŸ”¹ 1. Memoria virtuale](#-1-memoria-virtuale)
      - [Obiettivi principali](#obiettivi-principali)
    - [ðŸ”¹ 2. Paging](#-2-paging)
      - [Concetti fondamentali](#concetti-fondamentali)
      - [Funzionamento](#funzionamento-2)
      - [Vantaggi del paging](#vantaggi-del-paging)
      - [Svantaggi](#svantaggi-4)
    - [ðŸ”¹ 3. Page Table (Tabella delle pagine)](#-3-page-table-tabella-delle-pagine)
      - [Contenuto di ogni voce (entry)](#contenuto-di-ogni-voce-entry)
      - [Accesso alla Page Table](#accesso-alla-page-table)
    - [ðŸ”¹ 4. Translation Lookaside Buffer (TLB)](#-4-translation-lookaside-buffer-tlb)
      - [Funzionamento](#funzionamento-3)
      - [Vantaggi](#vantaggi-5)
      - [Svantaggi](#svantaggi-5)
    - [ðŸ”¹ 5. Paging multilivello](#-5-paging-multilivello)
      - [Funzionamento](#funzionamento-4)
      - [Vantaggi](#vantaggi-6)
      - [Svantaggi](#svantaggi-6)
    - [ðŸ”¹ 6. Segmentazione](#-6-segmentazione)
      - [Concetto](#concetto-3)
      - [Struttura hardware](#struttura-hardware)
      - [Vantaggi](#vantaggi-7)
      - [Svantaggi](#svantaggi-7)
    - [ðŸ”¹ 7. Segmentazione con Paging (ibrido)](#-7-segmentazione-con-paging-ibrido)
      - [Funzionamento](#funzionamento-5)
      - [Vantaggi](#vantaggi-8)
      - [Svantaggi](#svantaggi-8)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-10)
  - [Gestione della memoria (III)](#gestione-della-memoria-iii)
    - [ðŸ”¹ Introduzione](#-introduzione-10)
    - [ðŸ”¹ 1. Page Fault e Swapping](#-1-page-fault-e-swapping)
    - [ðŸ”¹ 2. Algoritmi di rimpiazzo delle pagine](#-2-algoritmi-di-rimpiazzo-delle-pagine)
      - [FIFO â€“ *First In, First Out*](#fifo--first-in-first-out)
      - [OPT â€“ *Optimal Replacement* (teorico)](#opt--optimal-replacement-teorico)
      - [LRU â€“ *Least Recently Used*](#lru--least-recently-used)
      - [Second-Chance (Clock Algorithm)](#second-chance-clock-algorithm)
      - [NRU â€“ *Not Recently Used*](#nru--not-recently-used)
      - [LFU â€“ *Least Frequently Used*](#lfu--least-frequently-used)
    - [ðŸ”¹ 3. Algoritmi di allocazione dei frame](#-3-algoritmi-di-allocazione-dei-frame)
      - [Allocazione fissa vs dinamica](#allocazione-fissa-vs-dinamica)
      - [Allocazione proporzionale](#allocazione-proporzionale)
      - [Allocazione con prioritÃ ](#allocazione-con-prioritÃ )
    - [ðŸ”¹ 4. Thrashing](#-4-thrashing)
      - [Cause principali](#cause-principali)
      - [Effetti](#effetti)
    - [ðŸ”¹ 5. Modelli di controllo del thrashing](#-5-modelli-di-controllo-del-thrashing)
      - [a) Working Set Model](#a-working-set-model)
      - [b) Page Fault Frequency (PFF)](#b-page-fault-frequency-pff)
    - [ðŸ”¹ 6. Prestazioni e compromessi](#-6-prestazioni-e-compromessi)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-11)
  - [File System (I)](#file-system-i)
    - [ðŸ”¹ Introduzione generale](#-introduzione-generale-3)
    - [ðŸ”¹ 1. Concetto di file](#-1-concetto-di-file)
      - [Tipi di file](#tipi-di-file)
      - [Attributi di un file](#attributi-di-un-file)
    - [ðŸ”¹ 2. Operazioni sui file](#-2-operazioni-sui-file)
    - [ðŸ”¹ 3. Struttura logica del file system](#-3-struttura-logica-del-file-system)
      - [Livelli principali](#livelli-principali-2)
    - [ðŸ”¹ 4. Struttura delle directory](#-4-struttura-delle-directory)
      - [Tipi di struttura delle directory](#tipi-di-struttura-delle-directory)
        - [a) Struttura a livello singolo](#a-struttura-a-livello-singolo)
        - [b) Struttura a due livelli](#b-struttura-a-due-livelli)
        - [c) Struttura gerarchica (ad albero)](#c-struttura-gerarchica-ad-albero)
        - [d) Strutture con link](#d-strutture-con-link)
    - [ðŸ”¹ 5. Gestione dello spazio su disco](#-5-gestione-dello-spazio-su-disco)
      - [Metodi di allocazione](#metodi-di-allocazione)
        - [a) Allocazione contigua](#a-allocazione-contigua)
        - [b) Allocazione concatenata (Linked allocation)](#b-allocazione-concatenata-linked-allocation)
        - [c) Allocazione indicizzata](#c-allocazione-indicizzata)
    - [ðŸ”¹ 6. Gestione dei metadati: inode](#-6-gestione-dei-metadati-inode)
      - [Contenuto di un inode](#contenuto-di-un-inode)
    - [ðŸ”¹ 7. Montaggio del file system](#-7-montaggio-del-file-system)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-12)
  - [File System (II)](#file-system-ii)
    - [ðŸ”¹ Introduzione](#-introduzione-11)
    - [ðŸ”¹ 1. Gestione dello spazio libero](#-1-gestione-dello-spazio-libero)
      - [Tecniche principali](#tecniche-principali)
        - [a) Bitmap (mappa dei bit)](#a-bitmap-mappa-dei-bit)
        - [b) Lista concatenata di blocchi liberi (Linked free list)](#b-lista-concatenata-di-blocchi-liberi-linked-free-list)
        - [c) Gruppi di blocchi liberi (Grouping)](#c-gruppi-di-blocchi-liberi-grouping)
        - [d) Contatori (Counting)](#d-contatori-counting)
    - [ðŸ”¹ 2. Strutture dati interne: FAT e inode](#-2-strutture-dati-interne-fat-e-inode)
      - [a) FAT â€“ *File Allocation Table*](#a-fat--file-allocation-table)
      - [b) inode (UNIX / Linux)](#b-inode-unix--linux)
    - [ðŸ”¹ 3. Gestione dello spazio libero e allocazione combinata](#-3-gestione-dello-spazio-libero-e-allocazione-combinata)
      - [Extent](#extent)
    - [ðŸ”¹ 4. Journaling e coerenza del file system](#-4-journaling-e-coerenza-del-file-system)
      - [Funzionamento](#funzionamento-6)
      - [Tipi di journaling](#tipi-di-journaling)
      - [Vantaggi](#vantaggi-9)
      - [Svantaggi](#svantaggi-9)
    - [ðŸ”¹ 5. Cache del disco e buffering](#-5-cache-del-disco-e-buffering)
      - [Tipologie di cache](#tipologie-di-cache)
      - [Vantaggi](#vantaggi-10)
      - [Svantaggi](#svantaggi-10)
    - [ðŸ”¹ 6. Verifica e recupero della consistenza](#-6-verifica-e-recupero-della-consistenza)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-13)
  - [Sicurezza e Protezione](#sicurezza-e-protezione)
    - [ðŸ”¹ Introduzione](#-introduzione-12)
    - [ðŸ”¹ 1. Obiettivi della protezione](#-1-obiettivi-della-protezione)
    - [ðŸ”¹ 2. Domini di protezione](#-2-domini-di-protezione)
      - [Implementazione pratica](#implementazione-pratica)
    - [ðŸ”¹ 3. Matrice di accesso](#-3-matrice-di-accesso)
      - [Esempio](#esempio-1)
      - [Rappresentazioni compatte](#rappresentazioni-compatte)
        - [a) Liste di controllo dâ€™accesso (ACL â€“ Access Control List)](#a-liste-di-controllo-daccesso-acl--access-control-list)
        - [b) Capability List](#b-capability-list)
    - [ðŸ”¹ 4. Meccanismi di controllo accessi](#-4-meccanismi-di-controllo-accessi)
      - [a) File system e permessi UNIX](#a-file-system-e-permessi-unix)
      - [b) Bit speciali](#b-bit-speciali)
    - [ðŸ”¹ 5. Autenticazione e autorizzazione](#-5-autenticazione-e-autorizzazione)
      - [Autenticazione](#autenticazione)
      - [Autorizzazione](#autorizzazione)
    - [ðŸ”¹ 6. Protezione in modalitÃ  kernel e utente](#-6-protezione-in-modalitÃ -kernel-e-utente)
    - [ðŸ”¹ 7. Sicurezza dei dati e cifratura](#-7-sicurezza-dei-dati-e-cifratura)
      - [a) Cifratura simmetrica](#a-cifratura-simmetrica)
      - [b) Cifratura asimmetrica](#b-cifratura-asimmetrica)
      - [c) Hash e integritÃ ](#c-hash-e-integritÃ )
      - [d) Cifratura del file system](#d-cifratura-del-file-system)
    - [ðŸ”¹ 8. Audit e logging](#-8-audit-e-logging)
    - [ðŸ”¹ 9. Backup e ripristino](#-9-backup-e-ripristino)
      - [Tipi principali](#tipi-principali-1)
      - [Buone pratiche](#buone-pratiche)
    - [ðŸ§  Mappa concettuale di sintesi](#-mappa-concettuale-di-sintesi-14)

## Storia dei Sistemi Operativi

---

### ðŸ”¹ Introduzione

I sistemi operativi non sono nati con i computer moderni: si sono **evoluti gradualmente** insieme allâ€™hardware e alle esigenze dellâ€™utenza.
Ogni nuova generazione di computer ha richiesto **soluzioni piÃ¹ efficienti per gestire il tempo di calcolo, la memoria e le periferiche**, portando alla nascita di modelli sempre piÃ¹ complessi di gestione dei processi.

Comprendere questa evoluzione permette di capire **perchÃ© oggi i sistemi operativi funzionano come li conosciamo** (multitasking, time-sharing, multiprocessore, ecc.), e su quali principi si basano i meccanismi che studiamo a livello tecnico.

---

### ðŸ”¹ 1. Prima generazione: calcolo manuale e programmazione diretta (anni â€™40 â€“ primi â€™50)

I primi calcolatori elettronici, come **ENIAC (1946)**, **EDSAC (1949)** e **UNIVAC (1951)**, non avevano un sistema operativo.
Ogni programma veniva **caricato manualmente** in memoria tramite **schede perforate, interruttori o nastri magnetici**, e controllato direttamente dallâ€™operatore.

Caratteristiche principali:

    - Nessuna multiprogrammazione: un solo programma alla volta.
    - Input/Output gestiti manualmente.
    - Il tempo della CPU spesso sprecato durante le operazioni I/O.

ðŸ’¡ **Obiettivo tecnico:** automatizzare il caricamento e lâ€™esecuzione dei programmi per ridurre i tempi morti.

---

### ðŸ”¹ 2. Seconda generazione: sistemi batch (anni â€™50 â€“ metÃ  â€™60)

Con lâ€™introduzione dei **mainframe IBM 700 e 1400**, nacquero i **sistemi batch**.
I programmi non venivano piÃ¹ caricati manualmente, ma **raggruppati in lotti (batch)** e **gestiti automaticamente** dal sistema operativo.

#### Funzionamento del sistema batch

1. Lâ€™operatore prepara un **nastro batch** contenente una sequenza di job.
2. Il **monitor residente** (precursore del kernel) carica ed esegue ogni job in sequenza.
3. Al termine, il controllo torna al monitor per passare al successivo.

#### Caratteristiche

- **Esecuzione sequenziale non interattiva.**
- Il sistema si occupa di **caricare, eseguire e scaricare** i programmi automaticamente.
- La CPU resta attiva per la maggior parte del tempo â†’ aumento dellâ€™efficienza.

#### Limiti

- Nessuna interazione utente.
- Se un job falliva, lâ€™intera sequenza veniva interrotta.
- ImpossibilitÃ  di correggere o osservare il comportamento del programma in tempo reale.

Esempio: **IBM 7094** con sistema **FMS (Fortran Monitor System)**, poi **IBSYS**.

---

### ðŸ”¹ 3. Terza generazione: multiprogrammazione e time-sharing (anni â€™60 â€“ â€™70)

Con lâ€™introduzione dei **transistor** e dei primi **sistemi multiutente**, i computer divennero piÃ¹ potenti e si iniziÃ² a pensare al calcolo **condiviso**.

#### Multiprogrammazione

La CPU puÃ² **tenere piÃ¹ processi in memoria contemporaneamente**, alternandone lâ€™esecuzione quando uno si blocca (es. per I/O).
â†’ Migliore utilizzo della CPU, riduzione dei tempi morti.

Il **sistema operativo gestisce il carico**, mantenendo una **ready queue** e passando da un processo allâ€™altro tramite **scheduling e context switch**.

#### Time-sharing

Evoluzione naturale della multiprogrammazione:
il tempo della CPU viene **suddiviso in quanti (time slice)** assegnati ciclicamente ai vari utenti o processi.

- Ogni utente percepisce di avere un computer dedicato.
- Nascono i **terminali interattivi**, con input da tastiera e output video.
- Compare la **preemption**, cioÃ¨ la possibilitÃ  di interrompere un processo per assegnare la CPU a un altro.

#### Sistemi rappresentativi

- **CTSS (Compatible Time Sharing System)** del MIT (1961).
- **MULTICS (Multiplexed Information and Computing Service)** (1965):
  â†’ introduce concetti moderni come file system gerarchico, protezione, memoria virtuale.
  â†’ da MULTICS nascerÃ  **UNIX** (1970).

ðŸ’¡ Da qui derivano molti concetti base di tutti i sistemi moderni: processi, shell, file system, permessi e scheduling.

---

### ðŸ”¹ 4. Quarta generazione: sistemi multiprocessore e distribuiti (anni â€™80 â€“ â€™90)

Lâ€™aumento della potenza e la miniaturizzazione portarono alla diffusione dei **microprocessori** e dei **personal computer**.
Si cominciÃ² a parlare di:

- **sistemi multiprocessore**, con piÃ¹ CPU che cooperano sullo stesso bus o su piÃ¹ core;
- **sistemi distribuiti**, con piÃ¹ macchine interconnesse in rete che condividono risorse.

#### Caratteristiche principali

- Esecuzione parallela di processi su piÃ¹ CPU.
- Introduzione della **cache multipla** e della **coerenza della memoria**.
- Comunicazione tramite **reti locali (LAN)** e **protocolli TCP/IP**.
- Concetti di **trasparenza di rete** e **file system distribuito**.

#### Sistemi notevoli

- UNIX (Berkeley BSD, System V).
- VAX/VMS, OS/2, Windows NT.
- Prime versioni di **Linux** (1991) come evoluzione open source del paradigma UNIX.

---

### ðŸ”¹ 5. Quinta generazione: sistemi moderni e virtualizzazione (2000 â€“ oggi)

Oggi i sistemi operativi gestiscono ambienti **ibridi, multipiattaforma e virtualizzati**, con risorse distribuite tra piÃ¹ macchine fisiche o virtuali.

#### Tendenze moderne

- **Multicore e hyperthreading:** schedulazione su core logici paralleli.
- **Virtualizzazione:** esecuzione di piÃ¹ sistemi operativi su una singola macchina (VMware, KVM, Hyper-V).
- **Containerizzazione:** isolamento dei processi in ambienti leggeri (Docker, LXC).
- **Cloud computing:** risorse distribuite e scalabili su cluster remoti.
- **Sicurezza avanzata:** sandboxing, SELinux, controllo degli accessi, cifratura integrata.
- **Gestione energetica:** scheduling adattivo e gestione dei consumi per dispositivi mobili.

ðŸ’¡ Il principio fondante resta invariato: il SO deve **astrarre e gestire lâ€™hardware**, fornendo un ambiente sicuro, efficiente e trasparente agli utenti e alle applicazioni.

---

### ðŸ”¹ 6. Evoluzione dellâ€™hardware e impatto sul SO

Ogni innovazione hardware ha determinato unâ€™evoluzione corrispondente nel software di sistema:

| Innovazione hardware | Impatto sul sistema operativo             |
| -------------------- | ----------------------------------------- |
| Timer hardware       | Scheduling preemptive e time-sharing      |
| Interrupt controller | Gestione asincrona di eventi              |
| Memoria virtuale     | Separazione spazi utente e kernel         |
| Dischi e SSD         | File system complessi e caching           |
| Multiprocessori      | Scheduling parallelo, CPU affinity        |
| Virtualizzazione     | Gestione di macchine virtuali e container |

---

### ðŸ”¹ 7. Timeline sintetica

| Periodo       | Caratteristiche                    | Esempi di sistemi       |
| ------------- | ---------------------------------- | ----------------------- |
| **1940â€“50**   | Nessun OS, programmazione manuale  | ENIAC, UNIVAC           |
| **1950â€“60**   | Sistemi batch                      | IBM 709, FMS            |
| **1960â€“70**   | Multiprogrammazione, time-sharing  | CTSS, MULTICS           |
| **1970â€“90**   | UNIX, multiprocessori, distribuiti | BSD, VAX/VMS            |
| **2000â€“oggi** | Virtualizzazione, cloud, mobile    | Linux, Windows, Android |

---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      STORIA DEI SISTEMI OPERATIVI
      â”‚
      â”œâ”€â”€ 1Âª generazione â†’ nessun OS
      â”‚   â””â”€ Programmazione manuale, ENIAC
      â”‚
      â”œâ”€â”€ 2Âª generazione â†’ sistemi batch
      â”‚   â”œâ”€ Lotti di job automatici
      â”‚   â””â”€ Nessuna interazione utente
      â”‚
      â”œâ”€â”€ 3Âª generazione â†’ multiprogrammazione e time-sharing
      â”‚   â”œâ”€ Processi multipli in memoria
      â”‚   â”œâ”€ Scheduling, context switch
      â”‚   â””â”€ Nascita di MULTICS e UNIX
      â”‚
      â”œâ”€â”€ 4Âª generazione â†’ multiprocessore e distribuiti
      â”‚   â”œâ”€ CPU multiple, rete, trasparenza
      â”‚   â””â”€ UNIX, VMS, Linux
      â”‚
      â”œâ”€â”€ 5Âª generazione â†’ moderni e virtualizzati
      â”‚   â”œâ”€ Multicore, container, cloud
      â”‚   â””â”€ Sicurezza e isolamento
      â”‚
      â””â”€â”€ Hardware â†” Software
         â”œâ”€ Timer â†’ scheduling
         â”œâ”€ Memoria virtuale â†’ isolamento
         â”œâ”€ Multiprocessori â†’ parallelismo
         â””â”€ Virtualizzazione â†’ risorse dinamiche

      ```

## Architettura monoprocessore

---

### ðŸ”¹ Introduzione

Un sistema di elaborazione monoprocessore Ã¨ un sistema dotato di **una sola unitÃ  di controllo (CPU)**, responsabile dellâ€™esecuzione sequenziale delle istruzioni di tutti i processi presenti nel sistema.
Tutti i meccanismi di esecuzione, gestione della memoria, I/O e scheduling ruotano attorno alla CPU, che costituisce il **cuore logico del computer**.

Il sistema operativo deve garantire che la CPU sia utilizzata in modo **efficiente** e **ordinato**, coordinando lâ€™accesso alle sue risorse da parte dei processi.
Per comprendere il funzionamento di un sistema operativo, Ã¨ quindi fondamentale capire **come Ã¨ organizzata la CPU** e **come essa esegue un programma**.

---

### ðŸ”¹ 1. Struttura generale della CPU

La **CPU (Central Processing Unit)** Ã¨ composta da una serie di unitÃ  funzionali che cooperano per eseguire le istruzioni dei programmi.
Le tre macro-componenti principali sono:

1. **ALU (Arithmetic Logic Unit)**
   Lâ€™unitÃ  aritmetico-logica, che esegue le operazioni matematiche (addizione, sottrazione, moltiplicazione, divisione) e logiche (AND, OR, NOT, XOR).

2. **CU (Control Unit)**
   Lâ€™unitÃ  di controllo, che coordina le varie parti della CPU, interpreta le istruzioni e regola il flusso delle operazioni.
   Ãˆ responsabile della **sequenza di esecuzione**: preleva le istruzioni dalla memoria, le decodifica e comanda lâ€™ALU o altre unitÃ .

3. **Registri interni**
   Piccole aree di memoria ad altissima velocitÃ  utilizzate per memorizzare temporaneamente dati, indirizzi o informazioni di controllo durante lâ€™esecuzione.

---

### ðŸ”¹ 2. Tipologie di registri

I registri rappresentano il livello piÃ¹ veloce e vicino alla CPU.
Ogni registro ha una funzione specifica e insieme formano la base della **microarchitettura del processore**.

#### a) Registri utente

Sono utilizzati direttamente dai programmi per memorizzare dati intermedi o indirizzi.
Esempi tipici:

- **AX, BX, CX, DX** nei processori x86;
- **R0â€“R31** nei processori RISC (ARM, MIPS, ecc.).

Possono contenere:

- Operandi per le istruzioni aritmetiche.
- Risultati temporanei.
- Indirizzi di memoria (es. puntatori o indici di array).

#### b) Registri di controllo e di stato

Non sono direttamente accessibili ai programmi utente: servono al **sistema operativo** e allâ€™hardware per gestire lâ€™esecuzione.

I principali sono:

- **Program Counter (PC)** â†’ contiene lâ€™indirizzo della prossima istruzione da eseguire.
- **Instruction Register (IR)** â†’ mantiene lâ€™istruzione attualmente in esecuzione.
- **Stack Pointer (SP)** â†’ punta alla cima dello stack del processo.
- **Status Register / Flag Register** â†’ contiene i flag (zero, carry, overflow, interrupt enable, ecc.) che indicano lo stato del processore.

#### c) Registri interni (buffer)

Usati per collegare la CPU con la memoria e i dispositivi I/O:

- **MAR (Memory Address Register):** contiene lâ€™indirizzo della cella di memoria da leggere o scrivere.
- **MBR (Memory Buffer Register):** contiene i dati letti o da scrivere in memoria.

---

### ðŸ”¹ 3. Ciclo di esecuzione: Fetchâ€“Decodeâ€“Execute

Ogni programma Ã¨ composto da una sequenza di **istruzioni macchina** che la CPU deve eseguire.
Il processo con cui la CPU legge ed elabora le istruzioni Ã¨ chiamato **ciclo di fetchâ€“decodeâ€“execute**.

#### a) Fase di Fetch (prelievo)

- Il **Program Counter (PC)** indica lâ€™indirizzo della prossima istruzione in memoria.
- Lâ€™indirizzo viene copiato nel **MAR** e la CPU richiede la lettura alla memoria principale.
- Lâ€™istruzione viene caricata nel **Instruction Register (IR)**.
- Il PC viene incrementato (salvo istruzioni di salto).

#### b) Fase di Decode (decodifica)

- Lâ€™unitÃ  di controllo interpreta il contenuto dellâ€™IR e determina quale operazione deve essere eseguita.
- Vengono identificati gli operandi e le modalitÃ  di indirizzamento (diretto, indiretto, immediato, indicizzato...).

#### c) Fase di Execute (esecuzione)

- Lâ€™ALU esegue lâ€™operazione richiesta (aritmetica o logica).
- Se necessario, i risultati vengono scritti nei registri o in memoria.
- Viene aggiornato lo **Status Register** in base al risultato (es. flag di overflow o zero).

Questo ciclo si ripete continuamente, miliardi di volte al secondo, scandito dal **clock** del processore.

---

### ðŸ”¹ 4. ModalitÃ  di indirizzamento

Le istruzioni macchina devono specificare **come accedere agli operandi** (cioÃ¨ dove si trovano i dati).
Le modalitÃ  di indirizzamento piÃ¹ comuni sono:

| ModalitÃ         | Descrizione                                                                          | Esempio            |
| --------------- | ------------------------------------------------------------------------------------ | ------------------ |
| **Immediato**   | Lâ€™operando Ã¨ contenuto direttamente nellâ€™istruzione                                  | `MOV R1, #5`       |
| **Diretto**     | Lâ€™istruzione contiene lâ€™indirizzo effettivo del dato                                 | `MOV R1, (1000)`   |
| **Indiretto**   | Lâ€™istruzione contiene un riferimento a un registro che contiene lâ€™indirizzo del dato | `MOV R1, (R2)`     |
| **Indicizzato** | Lâ€™indirizzo Ã¨ ottenuto sommando un valore base e un indice                           | `MOV R1, (R2 + 4)` |

Le modalitÃ  di indirizzamento sono fondamentali perchÃ© permettono di gestire dati e istruzioni in modo flessibile, senza dover riscrivere codice per ogni indirizzo.

---

### ðŸ”¹ 5. Ciclo di istruzione e ruolo del sistema operativo

Durante il ciclo di esecuzione, la CPU puÃ² essere **interrotta** da eventi esterni o interni (interrupt, eccezioni, trap).
Quando ciÃ² accade:

1. La CPU sospende il ciclo in corso.
2. Salva lo stato corrente del processo (registri, PC, flag) nel PCB.
3. Passa al **kernel mode** e invoca il gestore dellâ€™interrupt.
4. Dopo la gestione, ripristina il contesto e riprende lâ€™esecuzione.

Questo meccanismo consente al sistema operativo di **coordinare processi multipli** anche su una singola CPU, simulando il parallelismo attraverso la **commutazione rapida del contesto (context switch)**.

---

### ðŸ”¹ 6. Categorie di istruzioni macchina

Le istruzioni che una CPU puÃ² eseguire appartengono a diverse categorie, ognuna con scopi diversi:

| Categoria               | Esempio                   | Funzione                                       |
| ----------------------- | ------------------------- | ---------------------------------------------- |
| **Dati**                | `LOAD`, `STORE`, `MOV`    | Trasferimento dati tra memoria e registri      |
| **Aritmetiche/logiche** | `ADD`, `SUB`, `AND`, `OR` | Calcoli e operazioni bitwise                   |
| **Controllo di flusso** | `JMP`, `CALL`, `RET`      | Salti, chiamate a funzioni, ritorni            |
| **Gestione I/O**        | `IN`, `OUT`               | Comunicazione con dispositivi                  |
| **Sistema**             | `INT`, `HLT`              | Trap, interruzioni, arresti, cambi di modalitÃ  |

---

### ðŸ”¹ 7. Interazione CPU â€“ Memoria â€“ I/O

La CPU non lavora isolata: per funzionare deve comunicare costantemente con:

- **la memoria principale (RAM)** per caricare istruzioni e dati;
- **i dispositivi di I/O** per leggere e scrivere dati.

Questa comunicazione avviene tramite **bus**:

1. **Bus dati** â†’ trasporta i valori binari.
2. **Bus indirizzi** â†’ indica dove leggere/scrivere.
3. **Bus di controllo** â†’ gestisce segnali di sincronizzazione (read/write, interrupt, clock).

Il sistema operativo regola questo flusso e **decide quale processo puÃ² usare la CPU**, realizzando cosÃ¬ il principio di **multiprogrammazione**.

---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      ARCHITETTURA MONOPROCESSORE
      â”‚
      â”œâ”€â”€ Struttura CPU
      â”‚   â”œâ”€ ALU â†’ esegue operazioni logico-aritmetiche
      â”‚   â”œâ”€ CU â†’ coordina il ciclo istruzioni
      â”‚   â””â”€ Registri â†’ memorie veloci interne
      â”‚
      â”œâ”€â”€ Registri
      â”‚   â”œâ”€ Utente â†’ dati e indirizzi
      â”‚   â”œâ”€ Controllo â†’ PC, IR, SP, flag
      â”‚   â””â”€ Interni â†’ MAR, MBR per memoria
      â”‚
      â”œâ”€â”€ Ciclo istruzione
      â”‚   â”œâ”€ Fetch â†’ prelievo
      â”‚   â”œâ”€ Decode â†’ decodifica
      â”‚   â””â”€ Execute â†’ esecuzione ALU
      â”‚
      â”œâ”€â”€ Indirizzamento
      â”‚   â”œâ”€ Immediato, Diretto, Indiretto, Indicizzato
      â”‚   â””â”€ FlessibilitÃ  e riuso codice
      â”‚
      â”œâ”€â”€ Interruzioni
      â”‚   â”œâ”€ Salvataggio contesto
      â”‚   â”œâ”€ Gestione kernel mode
      â”‚   â””â”€ Context switch tra processi
      â”‚
      â”œâ”€â”€ Categorie istruzioni
      â”‚   â”œâ”€ Dati, Aritmetiche, Controllo, I/O, Sistema
      â”‚   â””â”€ Funzioni operative della CPU
      â”‚
      â””â”€â”€ Comunicazione
         â”œâ”€ Bus dati / indirizzi / controllo
         â””â”€ CPUâ€“Memoriaâ€“I/O â†’ multiprogrammazione

      ```

## Memorie + Sistema Operativo

---

### ðŸ”¹ Introduzione generale

Ogni sistema di elaborazione si fonda su un principio fondamentale: **la CPU elabora i dati molto piÃ¹ rapidamente di quanto la memoria o i dispositivi esterni possano fornirli**.
Per garantire efficienza e continuitÃ  nellâ€™esecuzione dei programmi, Ã¨ necessario organizzare la memoria in **piÃ¹ livelli** con caratteristiche diverse di **velocitÃ , costo e capacitÃ **.

Parallelamente, il **Sistema Operativo (SO)** si occupa di **gestire e coordinare** lâ€™uso di queste memorie, garantendo che i processi:

- abbiano accesso sicuro e controllato ai dati;
- possano convivere in memoria senza conflitti;
- ottimizzino lâ€™uso delle risorse fisiche disponibili.

Comprendere la **gerarchia delle memorie** e il **ruolo del SO** nella loro gestione Ã¨ la base per capire la logica di tutto il sistema informatico.

---

### ðŸ”¹ 1. Gerarchia delle memorie

Il concetto di **gerarchia di memoria** nasce per conciliare tre fattori in conflitto:

1. **VelocitÃ ** (quanto rapidamente si accede ai dati),
2. **Costo per bit** (quanto costa realizzarla),
3. **CapacitÃ ** (quanti dati puÃ² contenere).

La regola generale Ã¨:

> piÃ¹ la memoria Ã¨ vicina alla CPU â†’ piÃ¹ Ã¨ veloce â†’ piÃ¹ Ã¨ costosa â†’ meno Ã¨ capiente.

#### Struttura a livelli

| Livello                | Tipo di memoria    | Tempo di accesso | CapacitÃ    | Gestione               |
| ---------------------- | ------------------ | ---------------- | ---------- | ---------------------- |
| **L1 / L2 / L3**       | Cache              | nanosecondi      | KBâ€“MB      | Hardware (trasparente) |
| **RAM**                | Memoria principale | decine di ns     | GB         | Sistema operativo      |
| **Memoria secondaria** | SSD / HDD          | millisecondi     | TB         | Sistema operativo      |
| **Memoria terziaria**  | Nastri, cloud      | secondi          | molto alta | Manuale / batch        |

---

### ðŸ”¹ 2. Tipologie di memoria

#### a) Memoria primaria

Include **cache e RAM**.
Ãˆ **volatile**: il contenuto si perde allo spegnimento.
Contiene:

- i programmi in esecuzione,
- i dati attivi,
- le strutture di controllo del sistema operativo.

#### b) Memoria secondaria

Comprende **dischi magnetici** e **unitÃ  a stato solido (SSD)**.
Non Ã¨ volatile e serve per **conservare permanentemente** programmi e dati.

#### c) Memoria terziaria e virtuale

Usata per backup o archiviazione (nastri, cloud, optical storage).
La **memoria virtuale** Ã¨ una tecnica logica del SO che permette di **estendere la memoria principale** utilizzando parte del disco (swap area).

---

### ðŸ”¹ 3. Memoria cache

La **cache** Ã¨ una memoria ad altissima velocitÃ  che funge da **ponte tra CPU e RAM**, riducendo il tempo medio di accesso ai dati.

#### Principio di localitÃ 

La cache sfrutta due proprietÃ  fondamentali dei programmi:

- **LocalitÃ  temporale:** se un dato Ã¨ stato usato di recente, probabilmente sarÃ  usato di nuovo.
- **LocalitÃ  spaziale:** se Ã¨ stato usato un dato in memoria, probabilmente saranno usati anche quelli vicini.

#### Organizzazione

I dati vengono trasferiti in blocchi chiamati **linee di cache**.
Ogni linea contiene una copia di una parte di memoria principale.
Quando la CPU richiede un indirizzo:

1. Se il dato Ã¨ giÃ  in cache â†’ **cache hit** (accesso veloce).
2. Se non Ã¨ presente â†’ **cache miss** (dato recuperato dalla RAM).

#### Politiche di scrittura

- **Write-through:** ogni modifica in cache viene immediatamente scritta in RAM.
  â†’ piÃ¹ sicura ma lenta.
- **Write-back:** la scrittura in RAM avviene solo quando il blocco viene rimpiazzato.
  â†’ piÃ¹ veloce, ma richiede coerenza.

---

### ðŸ”¹ 4. Mappatura e sostituzione in cache

#### Tipi di mappatura

| Tipo                                       | Descrizione                                             | Caratteristica                     |
| ------------------------------------------ | ------------------------------------------------------- | ---------------------------------- |
| **Diretta**                                | Ogni blocco di memoria mappa in una sola linea di cache | semplice ma puÃ² generare conflitti |
| **Associativa**                            | Un blocco puÃ² occupare qualsiasi linea                  | flessibile ma costosa              |
| **Associativa a gruppi (set-associative)** | Compromesso: la cache Ã¨ divisa in gruppi di linee       | bilanciamento prestazioni/costo    |

#### Politiche di rimpiazzo

Quando la cache Ã¨ piena e serve spazio:

- **LRU (Least Recently Used):** elimina il blocco usato meno di recente.
- **FIFO (First In First Out):** elimina il blocco piÃ¹ vecchio.
- **Random:** scelta casuale, semplice ma non ottimale.

---

### ðŸ”¹ 5. Ruolo del Sistema Operativo nella memoria

Il SO **non gestisce direttamente la cache** (controllata dallâ€™hardware), ma ha il pieno controllo su:

- **Memoria principale (RAM)**
  â†’ allocazione e rilascio per i processi.
- **Memoria secondaria (swap)**
  â†’ gestione della memoria virtuale.
- **Protezione**
  â†’ impedisce che un processo acceda alla memoria di un altro.

#### Meccanismi principali

1. **Rilocazione dinamica:** traduzione indirizzi logici â†’ fisici.
2. **Protezione:** verifica degli indirizzi validi per ogni processo.
3. **Condivisione:** possibilitÃ  di usare la stessa area di memoria (es. librerie condivise).
4. **Organizzazione logica:** gestione dello spazio degli indirizzi dei processi.
5. **Organizzazione fisica:** mappatura su memoria e swap.

---

### ðŸ”¹ 6. Struttura logica del Sistema Operativo

Il sistema operativo puÃ² essere visto come un insieme di **moduli cooperanti**, organizzati a livelli di astrazione.

#### a) Kernel

Ãˆ il **cuore del sistema operativo**, sempre residente in memoria.
Si occupa di:

- Gestione dei processi e scheduling.
- Gestione della memoria principale e virtuale.
- Gestione del file system.
- Gestione delle interruzioni e dei dispositivi.

#### b) Shell e interfaccia utente

Fornisce i mezzi per interagire con il sistema operativo (prompt, GUI, comandi).
Ãˆ un **programma utente privilegiato**, ma non parte del kernel.

#### c) Livelli di astrazione del SO

| Livello                      | Funzione principale                |
| ---------------------------- | ---------------------------------- |
| **1 â€“ Hardware**             | CPU, memoria, dispositivi fisici   |
| **2 â€“ Microkernel / Kernel** | Gestione risorse di base           |
| **3 â€“ Servizi di sistema**   | File system, I/O, processi         |
| **4 â€“ Librerie e API**       | Interfaccia per i programmi utente |
| **5 â€“ Utente / Shell**       | Interazione e comandi              |

In sistemi didattici o teorici, la stratificazione puÃ² arrivare fino a 13 livelli (da hardware fino allâ€™utente finale), dove ogni livello offre servizi a quello superiore e si appoggia su quello inferiore.

---

### ðŸ”¹ 7. Kernel vs Microkernel

#### Kernel monolitico

Tutte le funzioni (file system, driver, memoria, I/O, ecc.) sono integrate in un unico grande blocco eseguibile in modalitÃ  kernel.

- **Pro:** alte prestazioni, accesso diretto alle risorse.
- **Contro:** scarsa modularitÃ , manutenzione difficile, vulnerabile a crash globali.

#### Microkernel

Contiene solo le funzioni essenziali (gestione processi, memoria, comunicazione).
Tutto il resto (driver, file system, GUI) gira in **user mode** come processi separati.

- **Pro:** alta affidabilitÃ  e isolamento dei moduli.
- **Contro:** comunicazioni piÃ¹ lente (messaggi inter-processo).

Esempi:

- Kernel monolitici â†’ Linux, BSD.
- Microkernel â†’ MINIX, Mach (base di macOS).

---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      MEMORIE + SISTEMA OPERATIVO
      â”‚
      â”œâ”€â”€ Gerarchia delle memorie
      â”‚   â”œâ”€ Cache â†’ veloce, costosa, piccola
      â”‚   â”œâ”€ RAM â†’ principale, volatile
      â”‚   â”œâ”€ Disco â†’ secondaria, persistente
      â”‚   â””â”€ Terziaria â†’ backup, archiviazione
      â”‚
      â”œâ”€â”€ Cache
      â”‚   â”œâ”€ LocalitÃ  temporale e spaziale
      â”‚   â”œâ”€ Write-through / write-back
      â”‚   â”œâ”€ Mappatura â†’ diretta, associativa, set-associativa
      â”‚   â””â”€ Rimpiazzo â†’ LRU, FIFO, Random
      â”‚
      â”œâ”€â”€ Ruolo del SO
      â”‚   â”œâ”€ Gestione RAM e swap
      â”‚   â”œâ”€ Rilocazione e protezione
      â”‚   â”œâ”€ Condivisione e organizzazione logica
      â”‚   â””â”€ Memoria virtuale
      â”‚
      â”œâ”€â”€ Struttura del SO
      â”‚   â”œâ”€ Kernel â†’ gestione risorse
      â”‚   â”œâ”€ Shell â†’ interfaccia utente
      â”‚   â””â”€ Livelli (1â€“5 o fino a 13)
      â”‚
      â””â”€â”€ Kernel vs Microkernel
         â”œâ”€ Monolitico â†’ veloce, poco modulare
         â””â”€ Microkernel â†’ affidabile, piÃ¹ lento

      ```

## Interrupt e I/O

---

### ðŸ”¹ Introduzione

Un sistema operativo deve essere in grado di **gestire eventi asincroni** provenienti sia dallâ€™hardware sia dal software, garantendo che la CPU non rimanga inattiva e che il flusso di esecuzione dei programmi proceda in modo corretto.
Questo comportamento Ã¨ reso possibile grazie agli **interrupt**, meccanismi che permettono al processore di **interrompere temporaneamente lâ€™esecuzione di un programma** per gestire un evento piÃ¹ urgente.

Gli interrupt sono quindi il **mezzo fondamentale di comunicazione tra CPU, sistema operativo e periferiche di I/O**.
Capire come funzionano significa comprendere il cuore del meccanismo reattivo del sistema operativo.

---

### ðŸ”¹ 1. Concetto di interrupt

Un **interrupt** Ã¨ un segnale che richiede al processore di sospendere lâ€™attivitÃ  corrente e di passare temporaneamente allâ€™esecuzione di una **routine di servizio** (Interrupt Handler o Interrupt Service Routine, ISR).
Dopo aver gestito lâ€™evento, il processore **riprende esattamente dal punto in cui era stato interrotto**.

Questo meccanismo permette al sistema di:

- reagire rapidamente a eventi esterni (es. arrivo dati da tastiera o rete);
- gestire errori o eccezioni interne;
- evitare che la CPU sprechi tempo in attesa di dispositivi lenti.

---

### ðŸ”¹ 2. Tipologie di interrupt

Gli interrupt si classificano in base allâ€™origine e alla modalitÃ  di generazione.

#### a) Interrupt hardware

Generati dai dispositivi esterni per segnalare eventi come:

- completamento di unâ€™operazione di I/O;
- errori hardware;
- richieste da timer o dispositivi di rete.

Esempio:
una stampante invia un segnale di interrupt per indicare che ha terminato la stampa.

#### b) Interrupt software

Generati da istruzioni specifiche del programma (es. `INT n` su x86) o da **eccezioni** come divisione per zero o accesso a memoria non valida.
Sono utilizzati dal sistema operativo per gestire le **system call** e i **trap**.

#### c) Classificazione funzionale

| Tipo          | Origine                               | Esempi                 | Descrizione                           |
| ------------- | ------------------------------------- | ---------------------- | ------------------------------------- |
| **Sincroni**  | Durante lâ€™esecuzione di unâ€™istruzione | Trap, eccezioni, fault | Dipendono dal programma in corso      |
| **Asincroni** | Da eventi esterni alla CPU            | Timer, I/O completato  | Indipendenti dal flusso di istruzioni |

---

### ðŸ”¹ 3. Meccanismo di gestione di un interrupt

Quando si verifica un interrupt, la CPU esegue una sequenza precisa di operazioni per garantire che lâ€™intervento sia gestito in modo sicuro e coerente.

#### Fasi principali

1. **Rilevamento dellâ€™interrupt**
   Il processore verifica a ogni ciclo di clock se Ã¨ presente un segnale di interrupt attivo.

2. **Salvataggio del contesto**
   La CPU salva in modo automatico le informazioni necessarie per riprendere il processo interrotto:

   - Program Counter (PC)
   - Registri di stato
   - Altri registri generali (salvati dal kernel o dallâ€™handler)

3. **Cambio di modalitÃ **
   La CPU passa da **user mode** a **kernel mode** per poter eseguire istruzioni privilegiate.

4. **Identificazione della causa**
   Tramite la **tabella vettore degli interrupt**, la CPU individua quale evento ha generato lâ€™interrupt e salta alla **Interrupt Service Routine** corrispondente.

5. **Esecuzione dellâ€™handler**
   Lâ€™ISR gestisce lâ€™evento (es. legge un dato dal dispositivo, aggiorna un buffer, segnala la fine dellâ€™I/O).

6. **Ripristino del contesto**
   Dopo la gestione, il sistema ripristina lo stato precedente del processo e ritorna al punto esatto in cui era stato interrotto.

---

### ðŸ”¹ 4. Vettore degli interrupt

Ogni tipo di interrupt Ã¨ associato a una specifica **voce del vettore degli interrupt**, una tabella contenente gli indirizzi delle routine di servizio.

Esempio (semplificato):

| Codice | Sorgente interrupt       | Routine associata |
| ------ | ------------------------ | ----------------- |
| 0      | Divisione per zero       | `ISR_DIVZERO`     |
| 8      | Timer                    | `ISR_TIMER`       |
| 13     | Violazione di protezione | `ISR_PROTFAULT`   |
| 33     | Tastiera                 | `ISR_KEYBOARD`    |

Quando lâ€™interrupt viene rilevato, la CPU accede direttamente alla voce corrispondente del vettore e salta alla funzione associata.

---

### ðŸ”¹ 5. Gestione sequenziale e annidata degli interrupt

#### a) Gestione sequenziale

In modalitÃ  **sequenziale**, la CPU accetta un nuovo interrupt solo quando ha terminato di gestire quello corrente.
â†’ soluzione semplice, ma poco efficiente per sistemi con eventi frequenti.

#### b) Gestione annidata

In modalitÃ  **annidata**, un interrupt puÃ² essere interrotto da un altro di **prioritÃ  superiore**.
Serve una **prioritÃ  gerarchica** per evitare conflitti e perdita di eventi.

Esempio:

- Un interrupt della tastiera puÃ² interrompere un processo in esecuzione.
- Ma un interrupt del timer (piÃ¹ urgente) puÃ² a sua volta interrompere lâ€™handler della tastiera.

Il kernel gestisce una **maschera di prioritÃ ** per abilitare o disabilitare certi interrupt in momenti specifici.

---

### ðŸ”¹ 6. Context switch e interrupt

Ogni interrupt implica un **context switch** temporaneo:
la CPU deve salvare lo stato del processo corrente per poterlo ripristinare successivamente.

Questo meccanismo Ã¨ analogo a quello utilizzato dallo **scheduler** per passare da un processo allâ€™altro, ma:

- nel caso dello scheduler â†’ il cambio Ã¨ pianificato (es. time quantum scaduto);
- nel caso dellâ€™interrupt â†’ Ã¨ **improvviso e asincrono**.

Un interrupt quindi **non solo segnala un evento**, ma Ã¨ anche **il meccanismo tecnico con cui il kernel ottiene il controllo della CPU**.

---

### ðŸ”¹ 7. Tecniche di I/O

Le operazioni di I/O (Input/Output) rappresentano la comunicazione tra CPU e dispositivi periferici.
PoichÃ© i dispositivi sono molto piÃ¹ lenti della CPU, il sistema deve adottare tecniche che massimizzino lâ€™efficienza.

#### a) I/O programmato

La CPU interroga continuamente il dispositivo (polling) fino a che non Ã¨ pronto.
â†’ semplice ma inefficiente: la CPU resta bloccata in attesa.

#### b) I/O con interrupt

Il dispositivo genera un interrupt quando Ã¨ pronto o ha completato unâ€™operazione.
â†’ la CPU nel frattempo puÃ² eseguire altri processi.
â†’ metodo standard nei sistemi moderni.

#### c) I/O con DMA (Direct Memory Access)

Un **DMA controller** trasferisce i dati direttamente tra memoria e dispositivo, senza intervento della CPU per ogni byte.
â†’ riduce drasticamente lâ€™overhead della CPU.
â†’ usato per dischi, schede di rete e audio.

---

### ðŸ”¹ 8. Ruolo del sistema operativo negli interrupt e nellâ€™I/O

Il sistema operativo gestisce gli interrupt come **porte di ingresso verso il kernel**:

- Decide **quali interrupt abilitare** (prioritÃ , maschere).
- Fornisce le **routine ISR** appropriate.
- Coordina i **driver dei dispositivi** che interagiscono con lâ€™hardware.
- Gestisce **code di I/O** e **sincronizzazione** dei processi in attesa.

Lâ€™insieme di queste funzioni costituisce il **sottosistema di I/O del kernel**, base della comunicazione CPUâ€“dispositivi.

---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      INTERRUPT E I/O
      â”‚
      â”œâ”€â”€ Concetto
      â”‚   â”œâ”€ Interruzione esecuzione CPU
      â”‚   â”œâ”€ Routine ISR â†’ gestisce evento
      â”‚   â””â”€ Ripresa del programma
      â”‚
      â”œâ”€â”€ Tipi
      â”‚   â”œâ”€ Hardware â†’ dispositivi, timer
      â”‚   â”œâ”€ Software â†’ trap, eccezioni
      â”‚   â””â”€ Sincroni / Asincroni
      â”‚
      â”œâ”€â”€ Gestione
      â”‚   â”œâ”€ Rilevamento â†’ segnale interrupt
      â”‚   â”œâ”€ Salvataggio contesto
      â”‚   â”œâ”€ Kernel mode + vettore interrupt
      â”‚   â””â”€ Ripristino stato processo
      â”‚
      â”œâ”€â”€ PrioritÃ 
      â”‚   â”œâ”€ Sequenziale â†’ uno per volta
      â”‚   â””â”€ Annidata â†’ prioritÃ  gerarchica
      â”‚
      â”œâ”€â”€ Tecniche I/O
      â”‚   â”œâ”€ Programmato â†’ polling
      â”‚   â”œâ”€ Interrupt-driven â†’ CPU libera
      â”‚   â””â”€ DMA â†’ accesso diretto a memoria
      â”‚
      â””â”€â”€ Ruolo SO
         â”œâ”€ Gestione ISR e driver
         â”œâ”€ Scheduling I/O
         â””â”€ Interfaccia CPUâ€“dispositivi

      ```

## Gestione I/O (I)

### ðŸ”¹ Introduzione

Lâ€™**Input/Output (I/O)** rappresenta la parte del sistema operativo che gestisce la **comunicazione tra la CPU e i dispositivi periferici** (dischi, tastiere, stampanti, reti, ecc.).
Questa componente Ã¨ essenziale, poichÃ© consente al sistema di **interagire con il mondo esterno**, trasferendo dati tra memoria e dispositivi.

Lâ€™I/O Ã¨ intrinsecamente **piÃ¹ lento** rispetto alla CPU e alla memoria: per questo motivo, uno dei compiti fondamentali del sistema operativo Ã¨ **ottimizzare il tempo di attesa** e massimizzare la **concorrenza tra calcolo e trasferimento dati**.

In generale, il sottosistema I/O si occupa di:

- nascondere le differenze tra i vari dispositivi;
- gestire errori e stati;
- ottimizzare lâ€™uso delle risorse hardware;
- fornire unâ€™interfaccia uniforme ai processi utente.

---

### ðŸ”¹ 1. Architettura del sottosistema I/O

Il sistema operativo organizza la gestione dellâ€™I/O secondo una **struttura multilivello**, che va dal software applicativo fino al dispositivo fisico.

#### Livelli principali

1. **Livello utente (User Level):**

   - Lâ€™applicazione interagisce con il sistema tramite **chiamate di sistema (system call)** come `read()`, `write()`, `open()`, `close()`.
   - Il programmatore non si occupa dei dettagli hardware: la gestione Ã¨ delegata al kernel.

2. **Livello kernel (Kernel Level):**

   - Include il **file system**, i **device driver**, la **gestione buffer**, e il **scheduling dellâ€™I/O**.
   - Si occupa di tradurre le richieste utente in operazioni fisiche sul dispositivo.

3. **Livello hardware:**

   - Composto dai **controller dei dispositivi**, che comunicano direttamente con la CPU e la memoria.
   - Ogni controller gestisce uno o piÃ¹ dispositivi fisici.

#### Flusso generale

      ```text

      Programma utente
         â†“
      System call (es. read/write)
         â†“
      Driver dispositivo
         â†“
      Controller hardware
         â†“
      Dispositivo fisico (disk, printer, etc.)

      ```

Il sistema operativo fa da **intermediario e coordinatore**, fornendo un livello di astrazione che rende uniforme lâ€™accesso a dispositivi anche molto diversi tra loro.

---

### ðŸ”¹ 2. Componenti dellâ€™I/O

#### a) Device Controller

Ãˆ unâ€™unitÃ  hardware che funge da **interfaccia tra la CPU e il dispositivo fisico**.
Ogni controller gestisce uno o piÃ¹ dispositivi dello stesso tipo (es. un controller SATA per i dischi, un controller USB per le periferiche esterne).

- *Funzioni principali:**

- interpretare i comandi provenienti dal driver;
- gestire i registri di stato, controllo e dati;
- segnalare alla CPU il completamento di unâ€™operazione (tramite interrupt).

#### b) Device Driver

Ãˆ un modulo software (parte del kernel) che **traduce le richieste generiche del sistema operativo in comandi specifici per il controller**.
Ogni tipo di dispositivo ha il proprio driver.

- *ResponsabilitÃ  principali:**

- inviare comandi al controller;
- gestire gli interrupt di completamento o errore;
- fornire unâ€™interfaccia standard al kernel (es. funzioni `read()`, `write()`).

Il driver rappresenta il punto di contatto diretto tra **software e hardware**, e deve rispettare precise specifiche per interagire con il kernel.

---

### ðŸ”¹ 3. Tecniche di comunicazione CPUâ€“Dispositivo

Le operazioni di I/O possono essere realizzate con diverse modalitÃ , che variano per **grado di coinvolgimento della CPU**.

#### a) I/O programmato (Polling)

- La CPU controlla periodicamente lo stato del dispositivo leggendo un **registro di stato**.
- Quando il dispositivo Ã¨ pronto, la CPU trasferisce manualmente i dati.

- *Vantaggi:**

- Implementazione semplice.

- *Svantaggi:**

- La CPU resta impegnata in attesa del dispositivo â†’ **spreco di tempo di calcolo**.
- Poco efficiente per dispositivi lenti.

#### b) I/O con interrupt

- Il dispositivo genera un **interrupt** quando termina unâ€™operazione o Ã¨ pronto per trasferire dati.
- La CPU puÃ² dedicarsi ad altro nel frattempo.

- *Funzionamento:**

1. Il processo richiede unâ€™operazione I/O.
2. Il driver configura il controller e mette il processo in attesa (stato *blocked*).
3. Il dispositivo esegue lâ€™operazione autonomamente.
4. Al completamento, il controller genera un interrupt â†’ il kernel risveglia il processo.

- *Vantaggi:**

- La CPU non resta inattiva.
- Maggiore efficienza e reattivitÃ .

- *Svantaggi:**

- Overhead dovuto alla gestione dellâ€™interrupt (context switch).
- Maggiore complessitÃ  del kernel.

#### c) I/O con DMA (Direct Memory Access)

Il **DMA** Ã¨ un meccanismo hardware che permette al controller del dispositivo di **accedere direttamente alla memoria**, senza passare dalla CPU per ogni byte trasferito.

- *Funzionamento:**

1. La CPU prepara la richiesta I/O (indirizzo sorgente, destinazione, quantitÃ ).
2. Il **DMA controller** gestisce il trasferimento autonomamente.
3. Al termine, genera un **interrupt** per segnalare il completamento.

- *Vantaggi:**

- Drastica riduzione del carico sulla CPU.
- Prestazioni elevate per trasferimenti di grandi dimensioni (es. disco â†’ RAM).

- *Svantaggi:**

- Hardware piÃ¹ complesso.
- Richiede sincronizzazione tra CPU e DMA per evitare conflitti sulla memoria.

---

### ðŸ”¹ 4. Bufferizzazione

La **bufferizzazione (buffering)** serve a **compensare le differenze di velocitÃ ** tra CPU, memoria e dispositivi di I/O.
Un **buffer** Ã¨ una zona di memoria temporanea usata per accumulare dati in transito.

#### Tipi di buffer

##### a) Single Buffer

Un solo buffer tra dispositivo e processo.
â†’ Quando il buffer Ã¨ pieno, il processo viene sospeso finchÃ© non viene svuotato.

##### b) Double Buffer

Due buffer usati in alternanza:

- mentre uno viene riempito, lâ€™altro viene svuotato.
  â†’ Migliora la sovrapposizione tra calcolo e I/O.

##### c) Circular Buffer

PiÃ¹ buffer in sequenza collegati circolarmente (FIFO).
â†’ Usato in sistemi ad alto throughput (streaming, rete).

#### Vantaggi

- Aumenta il parallelismo tra CPU e I/O.
- Riduce i tempi morti del dispositivo.

#### Svantaggi

- Maggiore uso di memoria.
- NecessitÃ  di gestione sincronizzata (accesso concorrente).

---

### ðŸ”¹ 5. Spooling

Il termine **spooling** (Simultaneous Peripheral Operation On-Line) indica una **tecnica di gestione concorrente** di dispositivi di I/O condivisi, come stampanti o unitÃ  disco.

#### Funzionamento

- Le richieste I/O non vengono servite immediatamente ma **accodate in unâ€™area di memoria o su disco (spool area)**.
- Un **demone (spooler)** legge periodicamente la coda e le esegue in ordine.

- *Esempio classico:**
PiÃ¹ utenti inviano stampe â†’ i file vengono messi in coda â†’ lo spooler li stampa in sequenza.

#### Vantaggi

- Permette lâ€™uso **condiviso** di dispositivi non rientranti (non multitasking).
- Evita blocchi del sistema in attesa del completamento di un I/O.
- Migliora la **concorrenza e il throughput complessivo**.

---

### ðŸ”¹ 6. Struttura software del sistema I/O

Il sottosistema I/O Ã¨ organizzato su piÃ¹ livelli, dal piÃ¹ astratto (software utente) al piÃ¹ vicino allâ€™hardware.

#### Livelli tipici

| Livello                 | Funzione principale                              |
| ----------------------- | ------------------------------------------------ |
| **Software utente**     | Chiamate di sistema (`read`, `write`)            |
| **Software di sistema** | File system e librerie I/O                       |
| **Device driver**       | Traduzione comandi generici in comandi specifici |
| **Interrupt handler**   | Gestione segnali di completamento o errore       |
| **Controller**          | Comunicazione diretta con il dispositivo fisico  |

Ogni livello comunica con il successivo tramite **interfacce standard**, rendendo il sistema modulare e facilmente estendibile.

---

### ðŸ§  Mappa concettuale di sintesi

      ```text

      GESTIONE I/O (I)
      â”‚
      â”œâ”€â”€ Architettura
      â”‚   â”œâ”€ Livello utente â†’ system call (read/write)
      â”‚   â”œâ”€ Livello kernel â†’ driver, buffer, scheduler
      â”‚   â””â”€ Livello hardware â†’ controller, device
      â”‚
      â”œâ”€â”€ Componenti
      â”‚   â”œâ”€ Device controller â†’ gestisce registri e interrupt
      â”‚   â””â”€ Driver â†’ traduce richieste OS â†’ hardware
      â”‚
      â”œâ”€â”€ Tecniche I/O
      â”‚   â”œâ”€ Programmato â†’ polling, CPU attiva
      â”‚   â”œâ”€ Interrupt-driven â†’ CPU notificata
      â”‚   â””â”€ DMA â†’ accesso diretto memoria
      â”‚
      â”œâ”€â”€ Buffering
      â”‚   â”œâ”€ Single â†’ uno solo
      â”‚   â”œâ”€ Double â†’ due alternati
      â”‚   â””â”€ Circular â†’ multipli (FIFO)
      â”‚
      â”œâ”€â”€ Spooling
      â”‚   â”œâ”€ Accodamento richieste I/O
      â”‚   â”œâ”€ Gestito da spooler
      â”‚   â””â”€ Esempio â†’ stampa multipla
      â”‚
      â””â”€â”€ Struttura software
         â”œâ”€ Utente â†’ system call
         â”œâ”€ Kernel â†’ driver e interrupt handler
         â””â”€ Hardware â†’ controller dispositivo

      ```

## Gestione I/O (II)

### ðŸ”¹ Introduzione

La seconda parte della gestione dellâ€™I/O approfondisce **le strategie di ottimizzazione e di affidabilitÃ ** nella gestione dei dispositivi di massa, in particolare i **dischi** (magnetici e SSD).
Qui il sistema operativo non si limita piÃ¹ a coordinare le operazioni di lettura e scrittura, ma deve anche:

- **ordinare e schedulare le richieste di I/O** per ridurre i tempi di accesso al disco;
- **distribuire e replicare i dati** per aumentare lâ€™affidabilitÃ  (RAID);
- **adattarsi alla diversa natura fisica** dei dispositivi (HDD vs SSD);
- **gestire i dispositivi in ambiente Linux**, attraverso il sottosistema dei **block device**.

---

### ðŸ”¹ 1. Struttura fisica e tempi di accesso al disco

Un **disco magnetico (HDD)** Ã¨ composto da piatti rotanti rivestiti di materiale magnetico, divisi in **tracce** e **settori**.
Il **braccio di lettura/scrittura** si sposta tra le tracce, e i dati vengono letti quando il settore desiderato passa sotto la testina.

#### Tempi di accesso

Il tempo totale per soddisfare una richiesta di lettura/scrittura si compone di tre elementi:

1. **Seek time (T_seek):** tempo necessario per spostare la testina sulla traccia corretta.
   â†’ di solito tra 3 e 10 ms.

2. **Rotational latency (T_rot):** tempo di attesa finchÃ© il settore desiderato passa sotto la testina.
   â†’ dipende dalla velocitÃ  di rotazione del disco (es. 7200 rpm â‰ˆ 4,2 ms in media).

3. **Transfer time (T_trans):** tempo necessario per leggere o scrivere i dati del settore.
   â†’ molto piÃ¹ breve (pochi Î¼s).

[
T_{accesso} = T_{seek} + T_{rot} + T_{trans}
]

PoichÃ© i primi due contributi sono dominanti, **minimizzare gli spostamenti della testina** Ã¨ lâ€™obiettivo principale degli algoritmi di **disk scheduling**.

---

### ðŸ”¹ 2. Scheduling dei dischi

Il **disk scheduler** ordina le richieste di I/O pendenti in modo da ridurre i movimenti della testina e migliorare il throughput.
Ogni algoritmo adotta un criterio diverso per decidere **quale richiesta servire per prima**.

#### a) FCFS â€“ *First Come, First Served*

Le richieste vengono servite nellâ€™ordine di arrivo.
â†’ Semplice ma inefficiente: la testina puÃ² muoversi continuamente avanti e indietro.

- *Vantaggio:** equitÃ .
- *Svantaggio:** tempi medi di accesso elevati.

---

#### b) SSTF â€“ *Shortest Seek Time First*

Viene servita la richiesta **piÃ¹ vicina alla posizione corrente** della testina.
â†’ Riduce i tempi medi di spostamento.

- *Problema:** puÃ² causare **starvation** per richieste lontane se continuano ad arrivare richieste vicine.

---

#### c) SCAN (Elevator Algorithm)

La testina si muove in una direzione servendo tutte le richieste fino al bordo del disco, poi inverte la direzione e serve le richieste nellâ€™altro senso.

- *Analogia:** come un ascensore che sale e scende servendo i piani nellâ€™ordine.

- *Vantaggi:**

- Tempi medi piÃ¹ stabili.
- Nessuna starvation sistematica.

- *Svantaggi:**

- Le richieste alle estremitÃ  del disco attendono piÃ¹ a lungo.

---

#### d) C-SCAN â€“ *Circular SCAN*

Variante di SCAN: la testina serve solo in una direzione (es. da inizio a fine disco) e poi **torna rapidamente allâ€™inizio senza servire richieste nel ritorno**.
â†’ Garantisce tempi di attesa piÃ¹ uniformi.

---

#### e) LOOK e C-LOOK

Sono varianti ottimizzate di SCAN e C-SCAN:

- La testina **non si spinge fino ai bordi del disco**, ma si ferma allâ€™ultima richiesta nella direzione corrente.
- Riduce ulteriormente i movimenti inutili.

---

#### f) Confronto generale

| Algoritmo         | Tipo            | Vantaggi                  | Svantaggi                     |
| ----------------- | --------------- | ------------------------- | ----------------------------- |
| **FCFS**          | Non ottimizzato | Semplice, equo            | Movimenti elevati             |
| **SSTF**          | Ottimizzato     | Buon compromesso          | Possibile starvation          |
| **SCAN**          | Bidirezionale   | Buon throughput           | Latenza ai bordi              |
| **C-SCAN**        | Circolare       | Tempi uniformi            | Ritorno a vuoto               |
| **LOOK / C-LOOK** | Ottimizzati     | Evitano movimenti inutili | PiÃ¹ complessi da implementare |

Nei sistemi moderni, vengono spesso utilizzati **scheduler ibridi**, che combinano logiche simili a SSTF e C-LOOK con prioritÃ  dinamiche e bilanciamento della latenza.

---

### ðŸ”¹ 3. RAID â€“ Redundant Array of Independent Disks

Il **RAID** Ã¨ una tecnica che combina piÃ¹ dischi fisici in un unico insieme logico, con lâ€™obiettivo di migliorare **prestazioni**, **affidabilitÃ ** o **entrambe**.

#### Motivazioni

- **Prestazioni:** letture/scritture parallele su piÃ¹ dischi.
- **AffidabilitÃ :** ridondanza dei dati â†’ tolleranza ai guasti.
- **CapacitÃ  logica:** unione di piÃ¹ dischi in un volume unico.

---

#### Livelli principali

| Livello           | Descrizione                                                    | Vantaggi                                 | Svantaggi                          |
| ----------------- | -------------------------------------------------------------- | ---------------------------------------- | ---------------------------------- |
| **RAID 0**        | *Striping* â†’ suddivide i dati tra i dischi senza ridondanza    | Massime prestazioni                      | Nessuna tolleranza ai guasti       |
| **RAID 1**        | *Mirroring* â†’ copia identica su due dischi                     | Alta affidabilitÃ                         | CapacitÃ  dimezzata                 |
| **RAID 5**        | *Striping con paritÃ  distribuita* â†’ paritÃ  su dischi alternati | Buon equilibrio prestazioni/affidabilitÃ  | PenalitÃ  in scrittura              |
| **RAID 6**        | Come RAID 5 ma con doppia paritÃ                                | Resiste a 2 guasti simultanei            | Maggiore overhead                  |
| **RAID 10 (1+0)** | Mirroring + striping                                           | Ottimo bilanciamento                     | Costo elevato (richiede â‰¥4 dischi) |

#### Considerazioni

- RAID 0 â†’ performance pura (es. cache temporanee).
- RAID 1 â†’ sistemi critici (database, server).
- RAID 5/6 â†’ file server e NAS.
- RAID 10 â†’ ambienti enterprise ad alte prestazioni.

---

### ðŸ”¹ 4. HDD vs SSD

Negli ultimi anni, gli **SSD (Solid State Drive)** hanno sostituito in gran parte i dischi magnetici tradizionali, ma la loro gestione a livello di sistema operativo differisce notevolmente.

#### HDD (Hard Disk Drive)

- Accesso meccanico (testina + piatti).
- Tempi dominati da seek e rotazione.
- Prestazioni influenzate dalla posizione fisica dei dati.
- Usura trascurabile ma sensibile agli urti.

#### SSD (Solid State Drive)

- Nessuna parte meccanica â†’ accesso **completamente elettronico**.
- Tempi di accesso costanti (nessun seek time).
- Prestazioni molto superiori in lettura casuale.
- Numero limitato di cicli di scrittura (usura celle).

#### Implicazioni per il sistema operativo

- Gli algoritmi di **disk scheduling** diventano meno rilevanti (nessun movimento testina).
- I driver devono gestire **wear leveling**, **garbage collection** e **comandi TRIM** per mantenere prestazioni costanti.
- Le operazioni di I/O vengono spesso accodate in modo asincrono per massimizzare la concorrenza.

---

### ðŸ”¹ 5. Gestione I/O in Linux

Linux gestisce lâ€™I/O attraverso una struttura modulare basata su **device file** e **driver a due categorie principali**:

| Tipo                  | Descrizione                                   | Esempi                   |
| --------------------- | --------------------------------------------- | ------------------------ |
| **Character devices** | Scambio dati byte per byte, flusso continuo   | Terminali, porte seriali |
| **Block devices**     | Accesso a blocchi di dati di dimensione fissa | Dischi, SSD, memorie USB |

Ogni dispositivo Ã¨ rappresentato da un **file speciale** in `/dev`, identificato da due numeri:

- **Major number:** identifica il driver associato.
- **Minor number:** identifica lâ€™istanza specifica del dispositivo.

#### Sottosistema del block I/O

Ogni richiesta di I/O passa attraverso:

1. **Page cache / buffer cache**
2. **Elevator scheduler (CFQ, deadline, noop, bfq)**
3. **Driver del dispositivo**
4. **Controller hardware**

Linux offre piÃ¹ **scheduler I/O** selezionabili (es. con `cat /sys/block/sda/queue/scheduler`):

- `noop` â†’ semplice FIFO (ottimo per SSD)
- `deadline` â†’ prioritÃ  temporali per evitare starvation
- `cfq` â†’ fairness tra processi (per HDD tradizionali)
- `bfq` â†’ bilanciamento ottimizzato per carichi misti

---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      GESTIONE I/O (II)
      â”‚
      â”œâ”€â”€ Struttura disco
      â”‚   â”œâ”€ Tracce e settori
      â”‚   â””â”€ T_accesso = T_seek + T_rot + T_trans
      â”‚
      â”œâ”€â”€ Scheduling dischi
      â”‚   â”œâ”€ FCFS â†’ ordine di arrivo
      â”‚   â”œâ”€ SSTF â†’ minimo spostamento
      â”‚   â”œâ”€ SCAN / C-SCAN â†’ movimento â€œascensoreâ€
      â”‚   â””â”€ LOOK / C-LOOK â†’ ottimizzati
      â”‚
      â”œâ”€â”€ RAID
      â”‚   â”œâ”€ RAID 0 â†’ striping, veloce
      â”‚   â”œâ”€ RAID 1 â†’ mirroring, sicuro
      â”‚   â”œâ”€ RAID 5 â†’ paritÃ  distribuita
      â”‚   â”œâ”€ RAID 6 â†’ doppia paritÃ 
      â”‚   â””â”€ RAID 10 â†’ mirroring + striping
      â”‚
      â”œâ”€â”€ HDD vs SSD
      â”‚   â”œâ”€ HDD â†’ meccanico, lento, seek time
      â”‚   â”œâ”€ SSD â†’ elettronico, rapido, usura celle
      â”‚   â””â”€ TRIM e wear leveling
      â”‚
      â””â”€â”€ I/O in Linux
         â”œâ”€ Character / Block device
         â”œâ”€ Major e minor number
         â”œâ”€ Scheduler: noop, deadline, cfq, bfq
         â””â”€ Stack I/O â†’ cache â†’ scheduler â†’ driver â†’ controller

      ```

## Processi

---

### ðŸ”¹ Introduzione

Uno dei compiti fondamentali di un sistema operativo Ã¨ la **gestione dei processi**, cioÃ¨ lâ€™insieme delle attivitÃ  in esecuzione nel sistema.
Un processo rappresenta lâ€™**unitÃ  fondamentale di esecuzione**: Ã¨ un programma â€œvivoâ€, in corso di esecuzione, con un proprio stato, risorse assegnate e contesto operativo.

Il SO deve poter:

- **creare**, **schedulare** e **terminare** i processi;
- **tenere traccia** del loro stato e delle risorse utilizzate;
- **garantire isolamento e sincronizzazione** quando piÃ¹ processi condividono la CPU o la memoria.

Il concetto di processo Ã¨ quindi alla base di tutto il funzionamento dinamico del sistema operativo.

---

### ðŸ”¹ 1. Processo vs programma

Un **programma** Ã¨ un insieme statico di istruzioni memorizzate su disco.
Un **processo**, invece, Ã¨ la **manifestazione dinamica del programma** in esecuzione: include contesto, risorse, variabili, stack e stato di avanzamento.

| Aspetto   | Programma                         | Processo                         |
| --------- | --------------------------------- | -------------------------------- |
| Natura    | Statico                           | Dinamico                         |
| Posizione | Disco                             | Memoria                          |
| Contenuto | Codice                            | Codice + dati + stato            |
| Scopo     | Rappresenta un compito potenziale | Esegue effettivamente un compito |

Esempio:

> Aprire due finestre di â€œCalcolatriceâ€ esegue **lo stesso programma** due volte, ma genera **due processi distinti**, ognuno con le proprie variabili e stato interno.

---

### ðŸ”¹ 2. Componenti di un processo

Un processo in esecuzione Ã¨ composto da diverse **sezioni di memoria** e **strutture di gestione**.

#### a) Spazio di indirizzamento (address space)

Il sistema operativo assegna a ciascun processo un proprio **spazio logico di memoria** suddiviso in sezioni:

| Sezione           | Contenuto                                   |
| ----------------- | ------------------------------------------- |
| **Text (o code)** | Istruzioni eseguibili del programma         |
| **Data**          | Variabili globali e statiche                |
| **Heap**          | Allocazioni dinamiche (es. `malloc`, `new`) |
| **Stack**         | Chiamate di funzione e variabili locali     |

Ogni processo crede di avere un proprio spazio di memoria indipendente, ma in realtÃ  il SO lo mappa sulla memoria fisica in modo controllato.

#### b) Stato e contesto

Il **contesto** di un processo rappresenta il suo â€œpunto di vitaâ€ nel sistema:

- Valore dei registri CPU (PC, SP, ecc.)
- Stato del processo (ready, running, waitingâ€¦)
- Informazioni su memoria, file aperti, prioritÃ , ecc.

Questo contesto Ã¨ ciÃ² che il SO salva e ripristina durante i **context switch**.

---

### ðŸ”¹ 3. Stati del processo

Durante il suo ciclo di vita, un processo attraversa diversi **stati logici**, ciascuno gestito dal SO.

#### a) Modello a 2 stati

- **Running:** il processo Ã¨ in esecuzione sulla CPU.
- **Not running:** il processo Ã¨ pronto o in attesa.

Semplice ma limitato: non distingue tra â€œprontoâ€ e â€œbloccatoâ€.

#### b) Modello a 5 stati

Ãˆ il modello piÃ¹ comune nei sistemi moderni.

| Stato                 | Descrizione                                       |
| --------------------- | ------------------------------------------------- |
| **New**               | Il processo Ã¨ stato creato ma non ancora avviato. |
| **Ready**             | In memoria, attende la CPU.                       |
| **Running**           | Sta eseguendo istruzioni.                         |
| **Blocked (Waiting)** | Attende un evento (es. I/O, segnale).             |
| **Terminated**        | Ha terminato lâ€™esecuzione o Ã¨ stato ucciso.       |

#### c) Stati sospesi

Oltre ai 5 classici, molti SO aggiungono:

- **Ready suspended**: pronto ma spostato su disco per mancanza di memoria.
- **Blocked suspended**: bloccato e non residente in memoria.

Questi stati consentono al SO di gestire la **memoria virtuale** e lo **swap**.

---

### ðŸ”¹ 4. Transizioni di stato

Le transizioni rappresentano i **passaggi logici** tra gli stati durante la vita del processo.

Esempio di ciclo tipico:

      ```text
      NEW â†’ READY â†’ RUNNING â†’ WAITING â†’ READY â†’ TERMINATED

      ```

#### Casi principali

- **Creazione:** `new â†’ ready` (ammissione in memoria).
- **Scheduling:** `ready â†’ running` (assegnazione CPU).
- **Preemption:** `running â†’ ready` (fine quanto).
- **I/O request:** `running â†’ waiting`.
- **I/O completion:** `waiting â†’ ready`.
- **Exit:** `running â†’ terminated`.

Il **dispatcher** del SO gestisce queste transizioni tramite **context switch**.

---

### ðŸ”¹ 5. PCB â€“ Process Control Block

Per ogni processo, il sistema operativo mantiene una struttura dati chiamata **PCB (Process Control Block)**, che contiene tutte le informazioni necessarie per la sua gestione.

#### Struttura tipica del PCB

| Categoria               | Contenuto                                   |
| ----------------------- | ------------------------------------------- |
| **Identificazione**     | PID (Process ID), PPID (Parent ID), utente  |
| **Stato di esecuzione** | Stato (ready, runningâ€¦), contesto CPU       |
| **Scheduling**          | PrioritÃ , tempo CPU usato, puntatore a code |
| **Memoria**             | Puntatori a tabelle delle pagine o segmenti |
| **File e I/O**          | File aperti, dispositivi assegnati          |
| **Sicurezza**           | UID, permessi di accesso                    |

Durante un **context switch**, il kernel salva il PCB del processo uscente e carica quello del processo entrante.
Ãˆ attraverso questa struttura che il SO â€œricordaâ€ esattamente dove ogni processo si era fermato.

---

### ðŸ”¹ 6. Code di processi

Per gestire i diversi stati, il SO organizza i processi in **code**.

| Coda                | Descrizione                                |
| ------------------- | ------------------------------------------ |
| **Ready queue**     | Processi pronti in attesa di CPU           |
| **Device queues**   | Processi in attesa di completamento I/O    |
| **Job queue**       | Tutti i processi presenti nel sistema      |
| **Suspended queue** | Processi temporaneamente rimossi dalla RAM |

Ogni scheduler opera su una coda diversa (long, short, medium-term scheduler).

---

### ðŸ”¹ 7. Operazioni sui processi

#### a) Creazione

Un processo puÃ² generare nuovi processi figli tramite una **system call** (es. `fork()` in UNIX).
Il processo figlio eredita parte dello stato del padre (file aperti, variabili, ambiente).

#### b) Terminazione

Un processo puÃ² terminare:

- **Volontariamente** (`exit()`)
- **Forzatamente** (`kill()`, errore, segnale del SO)

Quando un processo termina, il suo PCB viene rimosso e le risorse liberate.

#### c) Blocco e sblocco

Durante lâ€™esecuzione, un processo puÃ²:

- essere **bloccato** (es. in attesa di I/O);
- essere **risvegliato** quando lâ€™evento atteso si verifica.

---

### ðŸ”¹ 8. Processi e gerarchie

Nei sistemi moderni i processi formano **alberi di esecuzione**:

- Ogni processo padre puÃ² generare piÃ¹ processi figli.
- I figli possono a loro volta creare altri processi.

Esempio in UNIX:

      ```text
      init (PID 1)
      â”œâ”€ systemd
      â”‚   â”œâ”€ login
      â”‚   â”œâ”€ sshd
      â”‚   â””â”€ bash
      â”‚       â””â”€ python

      ```

Il kernel mantiene relazioni **PPID (Parent Process ID)** per tracciare queste gerarchie.
Quando un padre termina, i figli diventano **orfani** e vengono â€œadottatiâ€ da `init`.

---

### ðŸ”¹ 9. Relazione con i thread

Un processo puÃ² contenere **uno o piÃ¹ thread**, ovvero **flussi di esecuzione paralleli** che condividono la stessa memoria e risorse del processo.
Il processo fornisce lâ€™**ambiente di esecuzione**, mentre i thread sono le **unitÃ  effettive di esecuzione**.
Questo concetto verrÃ  approfondito nella lezione successiva.

---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      PROCESSI
      â”‚
      â”œâ”€â”€ Definizione
      â”‚   â”œâ”€ UnitÃ  di esecuzione gestita dal SO
      â”‚   â””â”€ Programma + stato + risorse
      â”‚
      â”œâ”€â”€ Componenti
      â”‚   â”œâ”€ Spazio memoria â†’ code, data, heap, stack
      â”‚   â”œâ”€ Contesto CPU â†’ registri, PC, flag
      â”‚   â””â”€ PCB â†’ dati di controllo
      â”‚
      â”œâ”€â”€ Stati
      â”‚   â”œâ”€ New, Ready, Running, Waiting, Terminated
      â”‚   â””â”€ Sospesi (Ready/Blocked suspended)
      â”‚
      â”œâ”€â”€ Transizioni
      â”‚   â”œâ”€ newâ†’ready â†’running â†’waiting â†’readyâ†’terminated
      â”‚   â””â”€ Gestite da scheduler + dispatcher
      â”‚
      â”œâ”€â”€ Code di sistema
      â”‚   â”œâ”€ Ready queue
      â”‚   â”œâ”€ Device queues
      â”‚   â””â”€ Suspended queue
      â”‚
      â”œâ”€â”€ Operazioni
      â”‚   â”œâ”€ Creazione (fork)
      â”‚   â”œâ”€ Terminazione (exit / kill)
      â”‚   â””â”€ Blocco / sblocco
      â”‚
      â”œâ”€â”€ Gerarchie
      â”‚   â””â”€ Processi padre/figlio, PID e PPID
      â”‚
      â””â”€â”€ Relazione con i thread
         â””â”€ Processo = contenitore, thread = unitÃ  esecutiva

      ```

## ðŸ“˜ Thread

### ðŸ”¹ Introduzione generale

Il concetto di **thread** nasce dallâ€™esigenza di aumentare il grado di concorrenza allâ€™interno dei sistemi operativi moderni.
Un **thread** puÃ² essere definito come un **flusso indipendente di controllo** che si muove allâ€™interno di un processo. In altre parole, Ã¨ lâ€™unitÃ  piÃ¹ piccola di esecuzione che il sistema operativo puÃ² pianificare sulla CPU.

Un processo puÃ² contenere **uno o piÃ¹ thread**. Quando esiste un solo thread, si parla di processo *monothreaded*; quando invece il processo contiene piÃ¹ thread, si parla di *multithreaded*.
In un processo multithread, tutti i thread condividono le **stesse risorse** del processo (come spazio di indirizzamento, file aperti, variabili globali, heap), ma mantengono **stack separati** per poter gestire le proprie chiamate di funzione e variabili locali in modo indipendente.

Questo permette ai thread di operare contemporaneamente su diverse porzioni del programma, riducendo drasticamente il costo in termini di risorse rispetto alla creazione di nuovi processi.
Infatti, la **creazione di un processo** richiede di duplicare lo spazio di memoria, le strutture del kernel e lâ€™ambiente di esecuzione; invece, creare un thread richiede solo la creazione di uno stack e di poche informazioni di contesto.

---

### ðŸ”¹ Vantaggi dellâ€™approccio multithread

Lâ€™utilizzo dei thread consente di ottenere **parallelismo logico** anche su sistemi single-core, perchÃ© lâ€™OS alterna rapidamente i thread in esecuzione, dando lâ€™impressione di simultaneitÃ .
Nei sistemi multi-core, invece, i thread possono essere effettivamente eseguiti in **parallelo reale**, su core diversi.

I principali vantaggi dellâ€™uso dei thread sono:

1. **Maggiore efficienza**: la creazione, la terminazione e lo switch tra thread richiedono meno risorse e tempo rispetto ai processi.
2. **Migliore utilizzo della CPU**: se un thread Ã¨ bloccato in attesa di I/O, un altro dello stesso processo puÃ² continuare ad eseguire.
3. **Comunicazione piÃ¹ semplice**: i thread possono condividere direttamente le variabili e i dati nello stesso spazio di memoria, evitando il bisogno di meccanismi complessi come pipe o socket.
4. **Migliore strutturazione del programma**: un programma complesso puÃ² essere suddiviso in flussi logici separati (ad esempio: thread per lâ€™interfaccia grafica, thread per la logica applicativa, thread per I/O o rete).

---

### ðŸ”¹ Thread a livello utente (ULT) e a livello kernel (KLT)

Il modo in cui i thread vengono implementati puÃ² variare.
Esistono due approcci principali: i **thread a livello utente (ULT)** e i **thread a livello kernel (KLT)**.
La differenza sta in chi gestisce la loro esecuzione e schedulazione.

#### â–«ï¸ Thread a livello utente (ULT)

I thread a livello utente vengono gestiti da una **libreria nello user space**.
Il sistema operativo non Ã¨ consapevole della loro esistenza: per il kernel, lâ€™intero processo appare come unâ€™unica entitÃ  schedulabile.

Quando si fa uno *switch* tra thread nello stesso processo, lâ€™operazione Ã¨ gestita interamente dalla libreria di thread e non richiede alcuna chiamata di sistema.
Questo comporta tempi di esecuzione estremamente ridotti, poichÃ© si evita il passaggio da **user mode a kernel mode**, che rappresenta unâ€™operazione costosa.

Tuttavia, lâ€™assenza di intervento del kernel introduce alcuni problemi:

- se un thread effettua una chiamata bloccante (ad esempio una `read()` su un file o su un socket), **tutto il processo rimane bloccato**, perchÃ© il kernel non Ã¨ in grado di distinguere i singoli thread;
- in presenza di piÃ¹ CPU o core, non Ã¨ possibile sfruttare il parallelismo hardware, poichÃ© per il kernel câ€™Ã¨ sempre un solo processo attivo.

In sintesi, gli ULT sono veloci e leggeri, ma non adatti a sistemi multiprocessore e a programmi che fanno uso intensivo di operazioni bloccanti.

---

#### â–«ï¸ Thread a livello kernel (KLT)

I thread a livello kernel vengono invece **gestiti direttamente dal sistema operativo**.
Ogni thread Ã¨ riconosciuto come entitÃ  indipendente e schedulabile.

Questo significa che il kernel puÃ² eseguire un thread su un core e un altro thread dello stesso processo su un core diverso, ottenendo **vero parallelismo**.
Inoltre, se un thread si blocca, gli altri thread del processo possono continuare la loro esecuzione.

Il rovescio della medaglia Ã¨ che la gestione da parte del kernel introduce un **maggiore overhead**:

- ogni creazione o terminazione di thread richiede una chiamata di sistema;
- ogni cambio di contesto (context switch) implica il salvataggio dello stato nel PCB del thread e il passaggio in kernel mode.

Lo scheduling Ã¨ centralizzato e non puÃ² essere personalizzato dallâ€™applicazione, ma garantisce pieno supporto al multiprocessore e una gestione robusta delle risorse.

---

#### â–«ï¸ Riepilogo comparativo ULT vs KLT

| Aspetto                  | ULT (User Level Thread)   | KLT (Kernel Level Thread) |
| ------------------------ | ------------------------- | ------------------------- |
| Gestione                 | Libreria in user space    | Kernel                    |
| VisibilitÃ  OS            | Processo unico            | Ogni thread schedulabile  |
| Creazione / terminazione | Molto veloce              | PiÃ¹ costosa               |
| Context switch           | Solo user mode            | Richiede mode switch      |
| Blocco thread            | Blocca tutto il processo  | Blocca solo il thread     |
| Supporto multicore       | No                        | SÃ¬, pieno                 |
| Scheduling               | Personalizzabile dallâ€™app | Gestito dal kernel        |

---

### ðŸ”¹ Operazioni fondamentali sui thread

I thread, indipendentemente dal tipo di implementazione, possono trovarsi in stati diversi e compiere alcune operazioni tipiche:

- **Spawn**: creazione di un nuovo thread, che eredita il contesto del processo padre e viene aggiunto alla ready queue.
- **Block**: sospensione volontaria o forzata di un thread, ad esempio in attesa di un evento o di una risorsa condivisa.
- **Unblock**: riattivazione di un thread precedentemente sospeso, quando la condizione di attesa Ã¨ soddisfatta.
- **Finish**: terminazione del thread, che libera lo stack e le strutture di gestione associate.

Ogni thread mantiene il proprio **contesto di esecuzione**, costituito da:

- il valore dei registri del processore (incluso il program counter),
- lo stato (running, ready, waiting, ecc.),
- lo stack per le variabili locali,
- un puntatore alla memoria condivisa del processo.

Il **context switch** tra thread consiste nel salvare il contesto del thread uscente e nel caricare quello del thread entrante.
Nei sistemi ULT questo avviene in user mode (molto rapido), mentre nei KLT comporta il coinvolgimento del kernel (piÃ¹ lento ma piÃ¹ sicuro).

---

### ðŸ”¹ Thread in Linux: LWP e PCB

Nel sistema operativo Linux, lâ€™implementazione dei thread si basa su un concetto intermedio chiamato **Lightweight Process (LWP)**.
Un LWP Ã¨ una struttura schedulabile che rappresenta un thread, ma possiede molte caratteristiche di un processo classico.

In Linux, non esiste una distinzione netta tra processi e thread: entrambi sono entitÃ  gestite tramite la stessa struttura dati, chiamata **task_struct**, che funge da **Process Control Block (PCB)**.
Ogni LWP ha quindi un proprio PCB, ma piÃ¹ LWP possono condividere le stesse risorse, come lo spazio di indirizzamento, i file aperti e le aree di memoria.

I campi principali del PCB di Linux sono:

- **stato** del thread (TASK_RUNNING, TASK_INTERRUPTIBLE, ecc.);
- **registri salvati** e **puntatori allo stack del kernel**;
- **relazioni di parentela** (padre, figli, gruppo di thread);
- **informazioni di scheduling** (prioritÃ , CPU assegnata, contatori di tempo);
- **segnali e gestori di segnali**;
- **puntatori alle risorse condivise** (file, memoria, namespace, ecc.).

#### Stati principali in Linux

Linux utilizza un modello di stati piÃ¹ articolato rispetto a quello classico dei processi:

- **TASK_RUNNING** â†’ thread in esecuzione o pronto per lâ€™esecuzione;
- **TASK_INTERRUPTIBLE** â†’ thread bloccato ma risvegliabile da un segnale;
- **TASK_UNINTERRUPTIBLE** â†’ bloccato, non risvegliabile finchÃ© la risorsa non Ã¨ disponibile;
- **TASK_STOPPED / TASK_TRACED** â†’ thread fermato o sotto debug;
- **EXIT_ZOMBIE / EXIT_DEAD** â†’ thread terminato, ma non ancora completamente rimosso dalle strutture del kernel.

Ogni thread in Linux ha un **TID (Thread ID)** univoco e appartiene a un gruppo di thread identificato da un **TGID (Thread Group ID)**.
Il TGID corrisponde al PID del thread principale del gruppo, cioÃ¨ quello che rappresenta il processo â€œpadreâ€ visto dallâ€™esterno.

---

### ðŸ”¹ Sintesi finale

In Linux, i thread non sono entitÃ  separate dai processi ma ne rappresentano delle â€œversioni leggereâ€.
Tutti i thread che appartengono allo stesso processo condividono:

- il codice eseguibile,
- lo spazio di memoria virtuale,
- le risorse di I/O,
- i segnali e il gruppo di credenziali.

Ogni thread mantiene perÃ² il proprio **stack, registri e stato indipendente**, permettendo al kernel di schedularli singolarmente.

Questa architettura ibrida unisce la flessibilitÃ  dei KLT con la leggerezza degli ULT, rendendo il modello di Linux uno dei piÃ¹ efficienti per i sistemi multiprocessore.

### ðŸ”¹ Sincronizzazione tra Thread

Quando piÃ¹ thread condividono risorse comuni â€” ad esempio variabili globali, strutture dati in memoria, file o buffer di I/O â€” Ã¨ necessario **coordinare il loro accesso** per evitare conflitti e risultati incoerenti.
Questo problema prende il nome di **sincronizzazione**.

#### â–«ï¸ Problema di concorrenza e sezione critica

Il caso piÃ¹ tipico Ã¨ quello della **sezione critica**, ovvero una porzione di codice che accede a risorse condivise e che non deve essere eseguita da piÃ¹ thread contemporaneamente.

Senza unâ€™adeguata sincronizzazione, possono verificarsi condizioni di **race condition** (condizioni di competizione): due o piÃ¹ thread tentano di leggere o modificare la stessa variabile contemporaneamente, e il risultato finale dipende dallâ€™ordine di esecuzione, che Ã¨ imprevedibile.

Per garantire lâ€™integritÃ  dei dati, il sistema operativo (o la libreria dei thread) deve assicurare che la sezione critica soddisfi tre condizioni fondamentali:

1. **Mutua esclusione:** solo un thread per volta puÃ² trovarsi nella sezione critica.
2. **Progresso:** se nessun thread Ã¨ nella sezione critica, deve essere consentito lâ€™ingresso a uno di quelli in attesa.
3. **Attesa limitata:** nessun thread deve essere escluso indefinitamente.

---

### ðŸ”¹ Strumenti di sincronizzazione

La sincronizzazione puÃ² essere implementata in vari modi, a seconda del livello di astrazione (software, libreria o kernel).
I principali strumenti sono:

#### 1. **Mutex (Mutual Exclusion Lock)**

Il mutex Ã¨ il meccanismo piÃ¹ elementare per implementare la **mutua esclusione**.
Si tratta di una variabile binaria che puÃ² trovarsi in due stati: *libero* (unlocked) o *occupato* (locked).

- Quando un thread entra nella sezione critica, deve **acquisire (lock)** il mutex.
  Se il mutex Ã¨ libero, il thread entra; se invece Ã¨ giÃ  occupato, il thread viene sospeso finchÃ© non diventa disponibile.
- Quando il thread termina la sezione critica, **rilascia (unlock)** il mutex, permettendo ad altri di entrare.

Lâ€™uso corretto dei mutex garantisce che solo un thread per volta acceda alla risorsa condivisa.
Tuttavia, un uso scorretto puÃ² generare **deadlock**, ovvero situazioni in cui due o piÃ¹ thread rimangono bloccati perchÃ© ognuno attende un mutex posseduto da un altro.

- *Esempio logico:**

- Thread A blocca `mutex1` e poi tenta di bloccare `mutex2`.
- Thread B ha giÃ  bloccato `mutex2` e tenta di bloccare `mutex1`.
  Nessuno dei due potrÃ  proseguire â†’ deadlock.

---

#### 2. **Semafori**

I **semafori** sono una generalizzazione del mutex introdotta da Dijkstra.
Un semaforo Ã¨ una variabile intera non negativa che rappresenta il **numero di risorse disponibili**.

Si gestisce tramite due operazioni atomiche:

- `wait()` (o `P`): decrementa il semaforo. Se il valore diventa negativo, il thread si blocca.
- `signal()` (o `V`): incrementa il semaforo. Se ci sono thread bloccati, ne risveglia uno.

Esistono due tipi principali di semafori:

1. **Semaforo binario:** puÃ² assumere solo i valori 0 o 1 (equivalente a un mutex).
2. **Semaforo contatore:** puÃ² assumere valori maggiori di 1, utile per controllare un numero finito di risorse identiche (es. connessioni di rete, buffer).

I semafori sono potenti ma piÃ¹ difficili da gestire correttamente, poichÃ© non garantiscono automaticamente lâ€™esclusivitÃ  dâ€™accesso e possono facilmente portare a situazioni di **starvation** (alcuni thread attendono indefinitamente).

---

#### 3. **Condition Variable**

Le **condition variable** permettono a un thread di sospendersi in attesa di una certa condizione logica e di essere risvegliato quando quella condizione diventa vera.
Sono sempre usate insieme a un mutex.

Il meccanismo Ã¨ il seguente:

- Il thread acquisisce un mutex ed entra in una sezione monitorata.
- Se la condizione non Ã¨ ancora soddisfatta, chiama `wait()` sulla condition variable: questo rilascia temporaneamente il mutex e sospende il thread.
- Quando un altro thread modifica la condizione, chiama `signal()` o `broadcast()` sulla condition variable, risvegliando uno o piÃ¹ thread sospesi.
- I thread risvegliati riacquisiscono il mutex e ricontrollano la condizione.

Questo modello Ã¨ usato nei **monitor**, ovvero strutture di sincronizzazione di alto livello che incapsulano variabili condivise e le operazioni di accesso in modo sicuro.

---

#### 4. **Join e sincronizzazione del flusso**

Oltre alle sezioni critiche, Ã¨ necessario sincronizzare il **flusso di esecuzione** dei thread, ovvero controllare *quando* un thread deve attendere il completamento di un altro.
Il metodo piÃ¹ comune Ã¨ la **join operation**.

Quando un thread principale (ad esempio il thread "padre") crea altri thread figli, puÃ² eseguire su ciascuno di essi lâ€™operazione:

      ```c
      pthread_join(thread_id, NULL);

      ```

In questo modo, il thread padre si sospende fino a quando il thread figlio identificato da `thread_id` termina.
Questa operazione assicura che tutte le elaborazioni parallele si completino prima di proseguire.

---

#### 5. **Barrier**

Una **barriera** Ã¨ un meccanismo che consente a un gruppo di thread di sincronizzarsi a un punto preciso del programma.
Ogni thread, al raggiungimento della barriera, si blocca finchÃ© anche tutti gli altri non la raggiungono.
Solo quando tutti i thread sono arrivati, la barriera si apre e tutti possono proseguire.
Ãˆ molto utilizzata nei programmi scientifici o nei calcoli distribuiti, dove diverse parti di un algoritmo devono sincronizzarsi periodicamente.

---

### ðŸ”¹ Problemi tipici della sincronizzazione

#### â–«ï¸ Deadlock

Un **deadlock** si verifica quando due o piÃ¹ thread si bloccano reciprocamente, ognuno in attesa di una risorsa posseduta dallâ€™altro.
Le quattro condizioni necessarie per il verificarsi di un deadlock (secondo Coffman) sono:

1. **Mutua esclusione** â€“ le risorse non possono essere condivise.
2. **Hold and wait** â€“ un thread trattiene una risorsa e ne richiede altre.
3. **No preemption** â€“ le risorse non possono essere sottratte forzatamente.
4. **Attesa circolare** â€“ esiste una catena di thread in cui ciascuno attende una risorsa posseduta dal successivo.

Prevenire o evitare i deadlock richiede strategie come:

- imporre un **ordine globale di acquisizione delle risorse**,
- introdurre **timeout**,
- o applicare algoritmi di rilevamento e recupero (ad esempio rilasciando e ripetendo lâ€™operazione).

---

#### â–«ï¸ Starvation

La **starvation** si verifica quando uno o piÃ¹ thread non riescono mai ad accedere a una risorsa, a causa della presenza costante di altri thread con prioritÃ  piÃ¹ alta.
PuÃ² accadere, ad esempio, in algoritmi non equi di scheduling o in uso scorretto dei semafori.

#### â–«ï¸ Busy waiting e spinlock

Unâ€™altra problematica Ã¨ il **busy waiting**, che si verifica quando un thread, invece di sospendersi, continua a controllare in un ciclo se una risorsa Ã¨ libera (tipico degli spinlock).
Questo puÃ² sprecare tempo di CPU, ma su sistemi multiprocessore Ã¨ utile per sezioni critiche molto brevi, in quanto evita il costo del cambio di contesto.

---

### ðŸ”¹ Sincronizzazione in Linux

In ambiente Linux (e in generale nei sistemi POSIX), la sincronizzazione tra thread Ã¨ gestita tramite la **pthread library** (`<pthread.h>`).
Essa fornisce meccanismi standardizzati per:

- **Mutex** (`pthread_mutex_t`),
- **Condition variables** (`pthread_cond_t`),
- **Semafori** (`sem_t`),
- **Barrier** (`pthread_barrier_t`).

Il kernel Linux, inoltre, offre meccanismi di sincronizzazione interni (come *spinlock*, *seqlock*, *rwlock* e *RCU â€“ Read-Copy-Update*) utilizzati per proteggere strutture dati interne del kernel stesso, dove la rapiditÃ  Ã¨ piÃ¹ importante della sospensione dei thread.

---

### ðŸ”¹ Sintesi generale

In un sistema multithread, la sincronizzazione Ã¨ lâ€™elemento che garantisce la **correttezza logica** del programma e la **coerenza dei dati**.
Senza di essa, lâ€™esecuzione concorrente porterebbe a comportamenti imprevedibili e errori difficili da individuare.

Lâ€™obiettivo Ã¨ sempre trovare il **compromesso tra sicurezza e efficienza**:

- troppa sincronizzazione riduce il parallelismo;
- troppo poca genera condizioni di gara o inconsistenza.

Un buon sistema operativo (e un buon programmatore) deve quindi progettare sezioni critiche piccole, atomiche e protette da meccanismi adeguati, scegliendo il tipo di sincronizzazione piÃ¹ adatto alla situazione.

## Scheduling

### ðŸ”¹ Introduzione generale

In un sistema operativo multiprogrammato, **piÃ¹ processi o thread competono per lâ€™uso della CPU**.
PoichÃ© in genere il numero dei processi attivi Ã¨ superiore al numero dei processori disponibili, Ã¨ necessario stabilire un criterio che decida **chi debba essere eseguito in un dato momento**.
Questo insieme di criteri e politiche prende il nome di **scheduling** (o **pianificazione della CPU**).

Il componente del sistema operativo che si occupa di queste decisioni Ã¨ detto **scheduler**, mentre lâ€™azione di scegliere quale processo assegnare alla CPU si chiama **dispatching**.
Ogni decisione di scheduling implica un **context switch**, cioÃ¨ il salvataggio dello stato del processo in esecuzione e il caricamento di quello del processo successivo.

Lâ€™obiettivo fondamentale dello scheduling Ã¨ massimizzare **lâ€™utilizzo della CPU** mantenendo **reattivitÃ  e giustizia (fairness)** tra i processi.

---

### ðŸ”¹ Obiettivi dello scheduling

Gli obiettivi variano a seconda del tipo di sistema operativo (batch, interattivo, real-time), ma si possono distinguere due macro-categorie di prioritÃ .

#### 1. Obiettivi nei sistemi batch

Nei sistemi batch, dove i processi vengono eseguiti in blocco senza interazione con lâ€™utente, lo scheduling Ã¨ orientato allâ€™**efficienza globale** del sistema:

- **Massimizzare il throughput** â†’ aumentare il numero di processi completati per unitÃ  di tempo.
- **Minimizzare il tempo di turnaround** â†’ ridurre lâ€™intervallo tra la sottomissione e la conclusione di un processo.
- **Ridurre lâ€™overhead di CPU** â†’ minimizzare il tempo speso in cambio di contesto e gestione.

#### 2. Obiettivi nei sistemi interattivi

Nei sistemi interattivi, in cui lâ€™utente si aspetta risposte rapide, lâ€™attenzione si sposta sulla **reattivitÃ **:

- **Minimizzare il tempo di risposta** â†’ ridurre il ritardo tra lâ€™input dellâ€™utente e la risposta del sistema.
- **Garantire la fairness** â†’ evitare che processi a bassa prioritÃ  restino indefinitamente in attesa.
- **Gestire la prioritÃ ** â†’ consentire che processi critici (es. di sistema) vengano eseguiti prima.

#### 3. Compromessi

Lo scheduling cerca un equilibrio tra:

- **efficienza** (alto throughput)
- **reattivitÃ ** (risposta veloce)
- **giustizia** (tutti i processi ricevono attenzione)
- **predicibilitÃ ** (tempi di risposta costanti)

---

### ðŸ”¹ Tipi di scheduling

Il sistema operativo puÃ² applicare politiche di scheduling su **diversi livelli** del ciclo di vita dei processi.

#### 1. Long-Term Scheduling (a lungo termine)

Ãˆ responsabile della **selezione dei processi da ammettere in memoria** per lâ€™esecuzione.
Agisce nel momento in cui un nuovo job entra nel sistema.
Il suo compito Ã¨ regolare il **grado di multiprogrammazione**, ovvero quante attivitÃ  possono trovarsi contemporaneamente in memoria.

- Se il grado di multiprogrammazione Ã¨ troppo alto â†’ rischio di **thrashing** (eccessivo swapping e rallentamento generale).
- Se Ã¨ troppo basso â†’ CPU sotto-utilizzata.

Nei sistemi moderni (es. Linux desktop), questo tipo di scheduling Ã¨ spesso implicito o automatico, ma resta fondamentale nei sistemi batch e real-time.

#### 2. Medium-Term Scheduling (a medio termine)

Gestisce la **sospensione e riattivazione** dei processi.
Il suo obiettivo Ã¨ migliorare lâ€™utilizzo della memoria principale, eseguendo operazioni di:

- **swap out** â†’ rimuovere temporaneamente un processo dalla memoria.
- **swap in** â†’ ricaricarlo quando ci sono risorse disponibili.

Ãˆ un meccanismo utile nei sistemi con memoria limitata o con processi di lunga durata, e contribuisce al controllo del carico di sistema.

#### 3. Short-Term Scheduling (a breve termine)

Ãˆ lo **scheduling vero e proprio della CPU**.
Il suo compito Ã¨ selezionare, tra i processi pronti (stato *ready*), quello che dovrÃ  essere eseguito immediatamente.
Opera con frequenza molto elevata (millisecondi o microsecondi), poichÃ© ogni volta che:

- un processo termina il proprio quanto di tempo,
- entra un nuovo processo ready,
- o un processo viene risvegliato da uno stato di blocco,
  il CPU scheduler deve decidere chi eseguire.

Questo tipo di scheduling Ã¨ quello che ha **lâ€™impatto diretto sulla reattivitÃ  percepita dallâ€™utente**.

#### 4. I/O Scheduling

Gestisce lâ€™ordine di esecuzione delle richieste ai dispositivi di I/O.
PoichÃ© le operazioni di I/O sono molto piÃ¹ lente di quelle di CPU, lâ€™obiettivo Ã¨ **ridurre i tempi di attesa** e **ottimizzare il throughput del disco o della periferica**.
Viene approfondito in seguito, ma qui basta sapere che rappresenta una forma specializzata di scheduling, spesso gestita a livello di driver.

---

### ðŸ”¹ Tipologie di scheduling: preemptive vs non-preemptive

Uno dei parametri piÃ¹ importanti per classificare gli algoritmi di scheduling Ã¨ la possibilitÃ  o meno di **interrompere un processo in esecuzione**.

- **Non-preemptive** â†’ il processo mantiene la CPU fino a quando termina o entra in stato di attesa.
  Ãˆ piÃ¹ semplice, ma meno reattivo.
  Esempi: FCFS, SPN, HRRN.

- **Preemptive** â†’ il sistema puÃ² forzare la sospensione del processo per assegnare la CPU a un altro (ad esempio, piÃ¹ prioritario o appena arrivato).
  Ãˆ piÃ¹ complesso ma migliora lâ€™interattivitÃ .
  Esempi: RR, SRT.

---

### ðŸ”¹ Algoritmi di scheduling della CPU

Il cuore dello scheduling a breve termine Ã¨ costituito dagli **algoritmi di selezione del processo**.
Ogni algoritmo stabilisce un criterio di scelta e una politica di sostituzione tra processi nella ready queue.

#### FCFS â€“ *First Come, First Served*

- Ãˆ il piÃ¹ semplice algoritmo non-preemptive.
- I processi vengono eseguiti nellâ€™ordine di arrivo nella coda ready (FIFO).
- Una volta ottenuta la CPU, il processo la mantiene fino al termine.

- *Vantaggi:**

- Implementazione semplice.
- Nessun overhead di cambio di contesto.

- *Svantaggi:**

- PuÃ² causare il **convoy effect**: un processo lungo trattiene la CPU e costringe i successivi ad attendere.
- Tempi di risposta elevati per processi brevi.

Ãˆ adatto per sistemi batch, ma inefficiente in ambienti interattivi.

---

#### RR â€“ *Round Robin*

- Ãˆ una variante preemptive del FCFS.
- Ogni processo riceve un **quanto di tempo (time quantum)** fisso.
- Quando il quanto scade, il processo viene sospeso e rimesso in coda, mentre la CPU passa al successivo.

- *Vantaggi:**

- Garantisce **equitÃ ** (tutti i processi ottengono la CPU in modo ciclico).
- Migliora la **reattivitÃ ** nei sistemi interattivi.
- Semplice da implementare.

- *Svantaggi:**

- Se il quanto Ã¨ troppo grande â†’ degrada a FCFS.
- Se Ã¨ troppo piccolo â†’ aumenta il numero di context switch, riducendo lâ€™efficienza.

La scelta ottimale del **time quantum** Ã¨ quindi un compromesso tra reattivitÃ  e overhead.

---

#### SPN â€“ *Shortest Process Next* (o SJF â€“ Shortest Job First)

- Politica **non-preemptive** che seleziona il processo con il **burst time piÃ¹ breve**.
- Si basa sullâ€™ipotesi che il tempo di esecuzione di ciascun processo sia stimabile.

- *Vantaggi:**

- Minimizza il tempo medio di attesa e di turnaround.
- Teoricamente, Ã¨ lâ€™algoritmo piÃ¹ efficiente in termini di tempo medio.

- *Svantaggi:**

- Difficile stimare con precisione il burst time.
- Possibile **starvation** per processi lunghi che vengono continuamente rimandati.

---

#### SRT â€“ *Shortest Remaining Time*

- Ãˆ la versione **preemptive** di SPN.
- Ogni volta che arriva un nuovo processo, viene confrontato il suo burst con quello rimanente del processo in esecuzione.
- Se il nuovo processo ha un burst piÃ¹ breve, preempie lâ€™attuale.

- *Vantaggi:**

- Migliora il tempo medio di attesa rispetto a SPN.
- Ottimale nei sistemi con processi brevi e frequenti.

- *Svantaggi:**

- Elevato overhead dovuto ai continui preemption.
- Ancora piÃ¹ esposto al rischio di starvation per processi lunghi.

---

#### HRRN â€“ *Highest Response Ratio Next*

- Politica **non-preemptive** che migliora SPN introducendo un criterio di prioritÃ  dinamica:
  [
  R = \frac{W + S}{S}
  ]
  dove:
  ( W ) = tempo di attesa,
  ( S ) = tempo di servizio stimato.

- *Funzionamento:**

- I processi che attendono da molto tempo aumentano progressivamente la propria prioritÃ .
- In questo modo, un processo lungo ma in attesa da tempo ottiene la CPU prima o poi.

- *Vantaggi:**

- Evita starvation.
- Buon compromesso tra tempo medio di attesa e fairness.

- *Svantaggi:**

- Non preemptive â†’ non adatto a sistemi interattivi.
- Richiede calcolo periodico del rapporto ( R ).

---

#### Tabella comparativa algoritmi

| Algoritmo     | Preemptive | Vantaggi principali                | Svantaggi principali                 |
| ------------- | ---------- | ---------------------------------- | ------------------------------------ |
| **FCFS**      | No         | Semplice, poco overhead            | Convoy effect, scarsa reattivitÃ      |
| **RR**        | SÃ¬         | EquitÃ , buoni tempi di risposta    | Dipende dal quanto, overhead elevato |
| **SPN (SJF)** | No         | Ottimo tempo medio di attesa       | Starvation, stima burst difficile    |
| **SRT**       | SÃ¬         | Migliora SPN, ottimizza tempi medi | Starvation, overhead alto            |
| **HRRN**      | No         | Evita starvation, bilanciato       | Non preemptive, calcolo frequente    |

---

### ðŸ”¹ Scheduling multiprocessore e Scheduling UNIX/Linux

---

### ðŸ”¹ 1. Introduzione

Nei sistemi moderni, la presenza di **piÃ¹ CPU o core** rende necessario un tipo di scheduling piÃ¹ complesso, capace di distribuire in modo equilibrato il carico di lavoro tra i processori.
In questo contesto, il compito dello scheduler non Ã¨ piÃ¹ solo decidere *quale processo eseguire*, ma anche *su quale processore eseguirlo*.
Il problema viene quindi esteso da una dimensione temporale (â€œquandoâ€) a una dimensione spaziale (â€œdoveâ€).

Il principale obiettivo dello **scheduling multiprocessore** Ã¨ quello di garantire:

- un **uso bilanciato** delle CPU (nessun core sovraccarico o inattivo);
- un **throughput elevato** complessivo;
- la **minimizzazione del tempo di attesa e di risposta**;
- la **coerenza della cache**, cioÃ¨ evitare spostamenti inutili di thread tra core.

---

### ðŸ”¹ 2. Tipologie di scheduling multiprocessore

Esistono diversi modelli e strategie per gestire la pianificazione su piÃ¹ CPU, che si differenziano per il grado di **cooperazione e indipendenza** tra i processori.

#### a) Asymmetric Multiprocessing (AMP)

Nel modello **asimmetrico**, solo un processore (detto *master*) Ã¨ responsabile dello scheduling e della gestione dei processi di sistema.
Gli altri processori (*slave*) si limitano a eseguire i processi assegnati.

- *Caratteristiche:**

- Il processore master gestisce la ready queue globale e distribuisce il lavoro.
- I processori slave non prendono decisioni di scheduling.
- Ãˆ un modello semplice, ma con **collo di bottiglia**: il master puÃ² diventare un punto di congestione.
- Utilizzato nei primi sistemi multiprocessore o embedded.

---

#### b) Symmetric Multiprocessing (SMP)

Il modello **simmetrico** Ã¨ quello adottato dai sistemi moderni (inclusi Linux, Windows, macOS).
Tutti i processori sono equivalenti e ciascuno possiede **il proprio scheduler locale**.

- *Caratteristiche principali:**

- Tutte le CPU possono accedere alle stesse code dei processi (ready queue).
- Ogni CPU puÃ² schedulare processi in modo indipendente.
- I processi possono essere spostati da una CPU allâ€™altra (migrazione).

- *Problema principale:** la **migrazione dei processi** tra CPU comporta perdita di efficienza della cache (cache miss), poichÃ© i dati del processo devono essere caricati nella cache del nuovo processore.
Per questo motivo, i moderni scheduler SMP cercano di mantenere, se possibile, la **CPU affinity**.

---

### ðŸ”¹ 3. CPU Affinity

La **CPU affinity** (o *process affinity*) rappresenta la tendenza di un processo o thread a essere eseguito sempre sulla stessa CPU.
Questo migliora le prestazioni grazie al **riuso della cache**, riducendo il numero di cache miss e migliorando la localitÃ  dei dati.

#### Tipi di affinitÃ 

##### 1. Soft affinity

- Il sistema tenta di mantenere il processo sulla stessa CPU, ma non lo garantisce.
- Ãˆ una preferenza, non un vincolo.
- Usata nei sistemi generici per flessibilitÃ .

##### 2. Hard affinity

- Lâ€™associazione tra processo e CPU Ã¨ obbligatoria.
- PuÃ² essere impostata manualmente dallâ€™utente o dal sistema operativo (`taskset` in Linux).
- Riduce il bilanciamento dinamico ma aumenta la coerenza della cache.

---

### ðŸ”¹ 4. Load Balancing

In un sistema multiprocessore, puÃ² accadere che alcune CPU siano sovraccariche e altre inattive.
Il **load balancing** serve a distribuire equamente il carico di lavoro tra le CPU.

#### Strategie principali

##### Push migration

Lo scheduler controlla periodicamente le code di tutte le CPU e sposta attivamente processi da quelle sovraccariche a quelle libere.

##### Pull migration

Una CPU inattiva â€œpescaâ€ un processo da una coda di unâ€™altra CPU.

Il bilanciamento puÃ² essere:

- **globale:** tutte le CPU condividono una coda comune di processi (ready queue globale).
  â†’ PiÃ¹ equo ma meno scalabile.
- **locale:** ogni CPU ha la propria coda, con meccanismi di bilanciamento periodici.
  â†’ PiÃ¹ efficiente ma piÃ¹ complesso da mantenere coerente.

---

### ðŸ”¹ 5. Scheduling in UNIX / Linux

Linux utilizza un modello di scheduling **SMP completamente simmetrico**, con un approccio **multilivello** e **basato su prioritÃ  dinamiche**.
Nel corso delle versioni, sono stati sviluppati diversi scheduler; i piÃ¹ importanti sono:

- **O(1) Scheduler** (fino a Linux 2.6)
- **CFS â€“ Completely Fair Scheduler** (dal kernel 2.6.23 in poi, tuttâ€™ora in uso)

Oltre a questi, Linux supporta anche politiche real-time conformi allo standard **POSIX**.

---

### ðŸ”¹ 6. Scheduler O(1)

Lâ€™**O(1) scheduler** Ã¨ stato introdotto per ottenere una decisione di scheduling in tempo costante (complessitÃ  O(1)), indipendentemente dal numero di processi nel sistema.

#### Struttura

- Ogni CPU possiede due code:

  - **Active queue:** contiene i processi pronti allâ€™esecuzione.
  - **Expired queue:** contiene i processi che hanno esaurito il proprio quanto.
    Quando la coda attiva si svuota, le due code vengono scambiate.

#### Caratteristiche principali

- Ogni processo ha una **prioritÃ  dinamica**, che aumenta o diminuisce in base al comportamento (CPU-bound o I/O-bound).
- Gli I/O-bound vengono favoriti per ridurre i tempi di risposta.
- I processi di tipo batch vengono penalizzati progressivamente per evitare starvation.

Questo scheduler Ã¨ molto efficiente e scalabile, ma tende a favorire eccessivamente i processi interattivi.

---

### ðŸ”¹ 7. Completely Fair Scheduler (CFS)

Il **CFS (Completely Fair Scheduler)**, introdotto nelle versioni moderne di Linux, si basa sul principio di **equa condivisione della CPU** tra i processi, senza utilizzare code statiche nÃ© quanti di tempo fissi.

Lâ€™idea di fondo Ã¨ che **ogni processo deve ottenere una frazione di CPU proporzionale alla sua prioritÃ **, in modo â€œcompletamente equoâ€.

#### Principio di funzionamento

- Ogni processo ha un valore chiamato **vruntime (virtual runtime)**, che misura il tempo di CPU effettivamente ottenuto.
- Lo scheduler mantiene un **albero bilanciato (red-black tree)** ordinato per `vruntime`.
- Il processo con il minor `vruntime` (cioÃ¨ quello che ha ricevuto meno CPU) viene selezionato per lâ€™esecuzione.
- Quando un processo esegue, il suo `vruntime` aumenta; cosÃ¬, nel tempo, tutti ricevono un trattamento proporzionale.

#### Vantaggi del CFS

- Non richiede code distinte o scambi periodici.
- Bilancia automaticamente CPU-bound e I/O-bound.
- Supporta facilmente il bilanciamento tra CPU diverse.
- Ãˆ deterministico e scalabile.

#### Intervallo temporale

Il CFS non definisce un quanto fisso; calcola dinamicamente un **target latency**, cioÃ¨ il tempo in cui tutti i processi attivi dovrebbero ottenere la CPU almeno una volta.
Se ci sono pochi processi, ciascuno ottiene una fetta piÃ¹ grande; se i processi aumentano, la fetta diventa piÃ¹ piccola.

---

### ðŸ”¹ 8. Politiche di scheduling in Linux

Linux supporta tre **classi di scheduling principali**, ciascuna con logica e prioritÃ  distinte:

| Classe             | Descrizione                        | Politica                                | Note                                            |
| ------------------ | ---------------------------------- | --------------------------------------- | ----------------------------------------------- |
| **SCHED_OTHER**    | Default (CFS) per processi normali | Time-sharing                            | PrioritÃ  dinamiche, fairness                    |
| **SCHED_FIFO**     | Real-time, prioritÃ  assoluta       | Non-preemptive FIFO                     | Usata per processi critici, esempio audio/video |
| **SCHED_RR**       | Real-time, round-robin             | Preemptive                              | Simile a FIFO ma con quanto di tempo fisso      |
| **SCHED_DEADLINE** | Real-time soft                     | Basato su EDF (Earliest Deadline First) | Introdotto per sistemi deterministici           |

Le politiche real-time (`SCHED_FIFO`, `SCHED_RR`, `SCHED_DEADLINE`) hanno **prioritÃ  superiori** rispetto ai processi CFS.
In caso di conflitto, i thread real-time hanno sempre la precedenza.

---

### ðŸ”¹ 9. Struttura del PCB in Linux per lo scheduling

Il **PCB** (`task_struct`) contiene campi specifici per la gestione dello scheduling:

- **policy** â†’ indica la classe (OTHER, FIFO, RR, DEADLINE)
- **prio** e **static_prio** â†’ prioritÃ  statica e dinamica
- **vruntime** â†’ tempo di CPU virtuale
- **se.run_list** â†’ puntatore nellâ€™albero red-black del CFS
- **cpus_allowed** â†’ maschera di affinitÃ  CPU
- **se.load.weight** â†’ peso proporzionale alla prioritÃ 

Ogni CPU ha inoltre una propria **runqueue** locale (`rq`), che mantiene i processi ready e coordina il bilanciamento.

---

### ðŸ”¹ 10. Sintesi concettuale per mappa

      ```text
      SCHEDULING (II)
      â”‚
      â”œâ”€â”€ Scheduling multiprocessore
      â”‚   â”œâ”€ AMP â†’ master/slave, semplice ma collo di bottiglia
      â”‚   â””â”€ SMP â†’ CPU simmetriche, schedulazione locale
      â”‚
      â”œâ”€â”€ CPU Affinity
      â”‚   â”œâ”€ Soft affinity â†’ preferenza
      â”‚   â””â”€ Hard affinity â†’ vincolo fisso
      â”‚
      â”œâ”€â”€ Load balancing
      â”‚   â”œâ”€ Push migration â†’ spinta dai core attivi
      â”‚   â””â”€ Pull migration â†’ prelievo da core inattivi
      â”‚
      â”œâ”€â”€ Linux Scheduler
      â”‚   â”œâ”€ O(1) â†’ due code (active/expired), prioritÃ  dinamiche
      â”‚   â”œâ”€ CFS â†’ fairness tramite vruntime e red-black tree
      â”‚   â””â”€ Target latency â†’ fetta CPU proporzionale
      â”‚
      â”œâ”€â”€ Politiche Linux
      â”‚   â”œâ”€ SCHED_OTHER â†’ CFS (normale)
      â”‚   â”œâ”€ SCHED_FIFO â†’ real-time FIFO
      â”‚   â”œâ”€ SCHED_RR â†’ real-time Round Robin
      â”‚   â””â”€ SCHED_DEADLINE â†’ EDF (Earliest Deadline First)
      â”‚
      â””â”€â”€ PCB Linux
         â”œâ”€ policy, prio, vruntime
         â”œâ”€ se.load.weight
         â””â”€ cpus_allowed (affinitÃ )

      ```

## Sincronizzazione (I)

---

### ðŸ”¹ Introduzione

In un sistema multiprogrammato o multithread, piÃ¹ processi o thread possono essere **attivi contemporaneamente** e condividere **risorse comuni**, come variabili, file o dispositivi.
Quando due o piÃ¹ attivitÃ  tentano di accedere contemporaneamente a una risorsa condivisa, possono verificarsi **condizioni di competizione (race conditions)**, che portano a risultati **imprevedibili e non deterministici**.

Per evitare questi problemi, il sistema operativo (e il programmatore) devono garantire una **sincronizzazione corretta** tra i processi concorrenti, assicurando che **le operazioni critiche siano eseguite in modo mutualmente esclusivo**.

---

### ðŸ”¹ 1. Sezione critica

La **sezione critica** Ã¨ la parte di codice di un processo che **accede a risorse condivise** (variabili, buffer, dispositivi).
Durante lâ€™esecuzione della sezione critica, **nessun altro processo** deve poter accedere alle stesse risorse.

#### Struttura generale di un processo

      ```text
      while (true) {
         Entry Section    â†’ Richiede accesso alla sezione critica
         Critical Section â†’ Accesso alla risorsa condivisa
         Exit Section     â†’ Rilascia la risorsa
         Remainder Section â†’ Codice non critico
      }

      ```

Lâ€™obiettivo Ã¨ progettare **protocolli di sincronizzazione** che garantiscano tre proprietÃ  fondamentali:

1. **Mutua esclusione:**
   solo un processo alla volta puÃ² essere nella sezione critica.

2. **Progresso:**
   se nessun processo Ã¨ nella sezione critica, solo i processi che desiderano entrarvi possono decidere chi entra, evitando attese inutili.

3. **Attesa limitata (bounded waiting):**
   nessun processo deve restare in attesa indefinitamente (assenza di starvation).

---

### ðŸ”¹ 2. Condizioni di competizione (Race Conditions)

Una **race condition** si verifica quando lâ€™esito finale di un programma **dipende dallâ€™ordine di esecuzione** dei processi concorrenti.
Questo accade perchÃ© piÃ¹ processi **leggono e scrivono simultaneamente** su una risorsa condivisa senza sincronizzazione.

#### Esempio classico

Supponiamo due processi P1 e P2 che incrementano una variabile condivisa `x`:

      ```text
      P1: x = x + 1
      P2: x = x + 1

      ```

In assenza di sincronizzazione, la sequenza di esecuzione potrebbe essere:

      ```text
      P1 legge x = 5
      P2 legge x = 5
      P1 scrive x = 6
      P2 scrive x = 6

      ```

â†’ risultato finale: `x = 6` invece di `7`.

Questo problema nasce perchÃ© le operazioni non sono atomiche (lettura + modifica + scrittura) e si sovrappongono.

---

### ðŸ”¹ 3. Soluzioni software alla mutua esclusione

Prima dellâ€™introduzione di meccanismi hardware e primitivi del kernel, sono state sviluppate **soluzioni puramente software** per garantire lâ€™accesso esclusivo alla sezione critica.
Queste soluzioni operano tramite variabili condivise e cicli di controllo (busy waiting).

#### a) Disabilitazione degli interrupt (solo kernel)

Nel kernel, la CPU puÃ² **disabilitare gli interrupt** durante lâ€™esecuzione di codice critico:

      ```c

      disable_interrupts();
      critical_section();
      enable_interrupts();

      ```

â†’ impedisce che venga eseguito un context switch.

- *Vantaggi:**

- Soluzione semplice ed efficace per il codice del kernel.

- *Svantaggi:**

- Non applicabile ai processi utente.
- Rende il sistema meno reattivo (gli interrupt vengono ritardati).
- Pericolosa su architetture multicore (non blocca gli altri core).

---

#### b) Soluzione di Peterson

La **soluzione di Peterson** Ã¨ un algoritmo software classico per due processi, basato su due variabili condivise:

- `flag[i]`: indica se il processo *i* vuole entrare nella sezione critica.
- `turn`: indica a chi tocca entrare.

      ```c

      flag[i] = true;
      turn = j;
      while (flag[j] && turn == j);
      critical_section();
      flag[i] = false;

      ```

- *Funzionamento:**

- Ogni processo segnala la propria intenzione (`flag[i] = true`) e cede momentaneamente la prioritÃ  allâ€™altro (`turn = j`).
- Solo quando lâ€™altro non Ã¨ interessato o non ha il turno, puÃ² entrare nella sezione critica.

- *ProprietÃ :**
âœ” Mutua esclusione
âœ” Progresso
âœ” Attesa limitata

- *Limiti:** valida solo per due processi; inefficiente su sistemi multiprocessore.

---

#### c) Algoritmo del panettiere (Bakery Algorithm)

Proposto da Lamport, estende la soluzione di Peterson a **piÃ¹ processi**.

Ogni processo prende un â€œnumeroâ€ come in una panetteria:
quello con il numero piÃ¹ basso entra per primo nella sezione critica.

      ```c
      choosing[i] = true;
      number[i] = 1 + max(number[0..n-1]);
      choosing[i] = false;
      while (âˆƒ j: (choosing[j] || (number[j] != 0 &&
         (number[j], j) < (number[i], i))));
      critical_section();
      number[i] = 0;

      ```

- *ProprietÃ :**

- Garantisce mutua esclusione e ordine FIFO.
- Completamente software.

- *Svantaggi:**

- Elevato overhead per confronti multipli.
- Poco pratico nei sistemi reali.

---

### ðŸ”¹ 4. Soluzioni hardware

Per migliorare lâ€™efficienza, i moderni processori offrono **istruzioni atomiche** che garantiscono mutua esclusione senza busy waiting esplicito.

#### a) Test-and-Set

Istruzione atomica che **legge e modifica** contemporaneamente una variabile di lock.

      ```c
      boolean TestAndSet(boolean *target) {
         boolean old = *target;
         - target = true;
         return old;
      }

      ```

- *Esempio dâ€™uso:**

      ```c
      while (TestAndSet(&lock)); // attende finchÃ© lock non Ã¨ false
      critical_section();
      lock = false;

      ```

â†’ nessuna interruzione puÃ² interferire durante lâ€™istruzione atomica.

- *Problema:**
causa *busy waiting* (la CPU consuma cicli in attesa).

---

#### b) Swap (Exchange)

Scambia in modo atomico il contenuto di due variabili:

      ```c
      Swap(a, b):
         temp = a;
         a = b;
         b = temp;

      ```

PuÃ² essere usato per implementare meccanismi simili a Test-and-Set.

---

#### c) Compare-and-Swap (CAS)

Istruzione piÃ¹ evoluta: confronta il valore di una variabile e, se corrisponde a quello atteso, lo sostituisce con un nuovo valore.
Ãˆ la base dei **lock-free algorithms** nei sistemi multiprocessore.

      ```c
      boolean CAS(int *ptr, int expected, int new) {
         if (*ptr == expected) {
            - ptr = new;
            return true;
         } else return false;
      }

      ```

---

### ðŸ”¹ 5. Semafori

Proposti da Dijkstra, i **semafori** rappresentano una **soluzione generale e astratta** per gestire la sincronizzazione tra processi, evitando lâ€™uso diretto di busy waiting.

Un semaforo Ã¨ una **variabile intera S** che puÃ² assumere valori â‰¥ 0, e viene manipolata tramite due operazioni atomiche:

      ```text
      wait(S):   // P (proberen, "provare")
         while (S <= 0)
            ; // attende
         S = S - 1

      signal(S): // V (verhogen, "incrementare")
         S = S + 1

      ```

#### Tipologie di semafori

- **Semaforo binario (mutex):** puÃ² valere solo 0 o 1 â†’ usato per mutua esclusione.
- **Semaforo contatore:** rappresenta un numero di risorse disponibili (es. posti in un buffer).

#### Vantaggi

- Semplice da implementare a livello di kernel.
- Evita race conditions e garantisce mutua esclusione.

#### Svantaggi

- Se implementato con busy waiting â†’ spreco CPU.
  (In sistemi reali, il processo viene messo in coda e sospeso.)

---

### ðŸ”¹ 6. Problema Produttoreâ€“Consumatore

Il **problema del produttoreâ€“consumatore** (o **bounded buffer problem**) Ã¨ un classico esempio di uso dei semafori.

#### Descrizione

- Un **produttore** genera dati e li inserisce in un buffer.
- Un **consumatore** preleva dati dallo stesso buffer.
- Il buffer ha **capacitÃ  limitata** â†’ serve sincronizzazione per evitare:

  - produzione oltre la capacitÃ  (overflow),
  - consumo di buffer vuoto (underflow).

#### Soluzione con semafori

      ```c
      semaphore mutex = 1;   // accesso esclusivo al buffer
      semaphore full = 0;    // numero di elementi pieni
      semaphore empty = N;   // numero di spazi liberi

      Producer:
      while (true) {
         produce_item();
         wait(empty);
         wait(mutex);
         insert_item();
         signal(mutex);
         signal(full);
      }

      Consumer:
      while (true) {
         wait(full);
         wait(mutex);
         remove_item();
         signal(mutex);
         signal(empty);
         consume_item();
      }

      ```

âœ” Evita overflow e underflow
âœ” Garantisce mutua esclusione
âœ” Sincronizza correttamente produttore e consumatore

---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      SINCRONIZZAZIONE (I)
      â”‚
      â”œâ”€â”€ Sezione critica
      â”‚   â”œâ”€ Accesso a risorse condivise
      â”‚   â”œâ”€ ProprietÃ : mutua esclusione, progresso, attesa limitata
      â”‚
      â”œâ”€â”€ Race condition
      â”‚   â””â”€ Esito dipende dallâ€™ordine di esecuzione
      â”‚
      â”œâ”€â”€ Soluzioni software
      â”‚   â”œâ”€ Disabilitazione interrupt (solo kernel)
      â”‚   â”œâ”€ Peterson â†’ 2 processi
      â”‚   â””â”€ Bakery â†’ n processi, numerazione
      â”‚
      â”œâ”€â”€ Soluzioni hardware
      â”‚   â”œâ”€ Test-and-Set
      â”‚   â”œâ”€ Swap
      â”‚   â””â”€ Compare-and-Swap (CAS)
      â”‚
      â”œâ”€â”€ Semafori
      â”‚   â”œâ”€ Operazioni P (wait) / V (signal)
      â”‚   â”œâ”€ Binario e contatore
      â”‚   â””â”€ Gestiti dal kernel (no busy waiting)
      â”‚
      â””â”€â”€ Problema Produttoreâ€“Consumatore
         â”œâ”€ Buffer limitato
         â”œâ”€ Semafori: mutex, full, empty
         â””â”€ Evita overflow/underflow

      ```

## Sincronizzazione (II)

---

### ðŸ”¹ Introduzione

La sincronizzazione non si limita a garantire la mutua esclusione: in molti casi, piÃ¹ processi devono **cooperare e coordinare le proprie azioni** in modo ordinato.
Inoltre, lâ€™uso scorretto dei meccanismi di sincronizzazione puÃ² portare a **situazioni di blocco permanente (deadlock)**, in cui un gruppo di processi resta sospeso in attesa reciproca di risorse.

Questa lezione approfondisce:

- i **monitor** come astrazione ad alto livello per la sincronizzazione strutturata;
- la **natura del deadlock**;
- i **metodi per prevenirlo, evitarlo o rilevarlo**;
- e infine lâ€™**algoritmo del banchiere** di Dijkstra, che ne rappresenta un modello di evitamento dinamico.

---

### ðŸ”¹ 1. Monitor

Un **monitor** Ã¨ un **costrutto di sincronizzazione ad alto livello**, introdotto da Hoare e Brinch Hansen, che incapsula:

- le **variabili condivise**,
- le **procedure che operano su di esse**, e
- i **meccanismi di sincronizzazione** (implicitamente gestiti dal linguaggio o dal sistema).

#### Concetto

Solo **un processo alla volta** puÃ² trovarsi allâ€™interno del monitor â†’ garantisce **mutua esclusione automatica**.

      ```text
      monitor Buffer {
         item buffer[N];
         int count = 0;
         condition full, empty;

         procedure insert(item x) {
            if (count == N) wait(full);
            buffer[count++] = x;
            signal(empty);
         }

         procedure remove(item x) {
            if (count == 0) wait(empty);
            x = buffer[--count];
            signal(full);
         }
      }

      ```

#### Variabili di condizione

Le **variabili di condizione** permettono di sospendere e risvegliare i processi allâ€™interno del monitor:

- `wait(c)`: sospende il processo su `c` finchÃ© un altro non lo risveglia.
- `signal(c)`: risveglia un processo sospeso su `c` (se presente).

#### Vantaggi

- Sintassi chiara e strutturata: facile da integrare nei linguaggi ad alto livello (es. Java, C#, Ada).
- Elimina lâ€™uso esplicito dei semafori.
- Evita errori di sincronizzazione dovuti a dimenticanze o inversioni di ordine (`wait`/`signal`).

#### Svantaggi

- Minor controllo sul comportamento fine del sistema.
- La semantica di `signal` varia:

  - **Hoare semantics:** il processo risvegliato entra subito nel monitor.
  - **Mesa semantics (usata in Java):** il processo risvegliato Ã¨ solo pronto, ma non entra subito (puÃ² esserci starvation).

---

### ðŸ”¹ 2. Deadlock

Un **deadlock** si verifica quando un insieme di processi si trova in uno stato in cui **ognuno attende una risorsa posseduta da un altro processo del gruppo**, e **nessuno puÃ² progredire**.

#### Esempio classico

Due processi P1 e P2, due risorse R1 e R2:

      ```text
      P1: lock(R1); lock(R2);
      P2: lock(R2); lock(R1);

      ```

â†’ Possibile situazione:

- P1 ottiene R1 e attende R2.
- P2 ottiene R2 e attende R1.
  â†’ Nessuno puÃ² procedere â‡’ **deadlock**.

---

### ðŸ”¹ 3. Condizioni necessarie per il deadlock

PerchÃ© si verifichi un deadlock, devono sussistere **tutte e quattro** le seguenti condizioni (Coffman, 1971):

1. **Mutua esclusione:**
   almeno una risorsa non puÃ² essere condivisa (es. stampante, mutex).

2. **Hold and wait:**
   un processo trattiene una risorsa e ne richiede altre.

3. **Nessuna prelazione (No preemption):**
   le risorse non possono essere forzatamente sottratte a un processo.

4. **Attesa circolare (Circular wait):**
   esiste una catena di processi in cui ciascuno attende una risorsa detenuta dal successivo.

[
P_1 â†’ R_1 â†’ P_2 â†’ R_2 â†’ â€¦ â†’ P_n â†’ R_n â†’ P_1
]

Se anche una sola di queste condizioni viene impedita, il deadlock **non puÃ² verificarsi**.

---

### ðŸ”¹ 4. Rappresentazione con il grafo delle risorse

Un **Resource Allocation Graph (RAG)** rappresenta graficamente le relazioni tra processi e risorse:

- **Nodo processo** â†’ ( P_i )
- **Nodo risorsa** â†’ ( R_j )
- **Arco di richiesta:** ( P_i â†’ R_j )
- **Arco di assegnazione:** ( R_j â†’ P_i )

#### Esempio

      ```text
      R1 â†’ P1 â†’ R2 â†’ P2 â†’ R1

      ```

â†’ ciclo â†’ **deadlock potenziale**

- *Osservazioni:**

- Se non ci sono cicli â†’ nessun deadlock.
- Se câ€™Ã¨ un ciclo â†’ possibile deadlock (certo, se ogni risorsa ha un solo istanza).

---

### ðŸ”¹ 5. Strategie per la gestione del deadlock

#### a) Prevenzione

Evita a priori che si verifichi un deadlock, **impedendo una o piÃ¹ delle quattro condizioni**.

| Condizione       | Metodo di prevenzione                            |
| ---------------- | ------------------------------------------------ |
| Mutua esclusione | Usare risorse condivisibili dove possibile       |
| Hold and wait    | Richiedere tutte le risorse allâ€™inizio           |
| No preemption    | Rimuovere risorse a processi bloccati            |
| Circular wait    | Imporre un ordine totale di acquisizione risorse |

- *Esempio:**
numerare tutte le risorse e richiederle sempre in ordine crescente.

- *Svantaggi:**

- Poca flessibilitÃ .
- Spreco di risorse (processi che richiedono piÃ¹ del necessario).

---

#### b) Evitamento (Dynamic avoidance)

Lâ€™allocazione viene concessa solo se **mantiene il sistema in uno stato sicuro**.

Uno **stato sicuro** Ã¨ tale che esiste un ordine di esecuzione dei processi che consente a ciascuno di terminare senza deadlock.

â†’ Lâ€™algoritmo principale di questa categoria Ã¨ **lâ€™Algoritmo del Banchiere**.

---

#### c) Rilevazione e recupero

Si **permette che il deadlock avvenga**, ma il sistema:

1. lo **rileva** (analizzando periodicamente il grafo delle risorse);
2. esegue unâ€™azione di **recupero** (termina o sospende alcuni processi).

- *Metodi di recupero:**

- **Prelazione risorse:** forzare il rilascio da parte di un processo.
- **Rollback:** riportare un processo a uno stato precedente.
- **Terminazione selettiva:** uccidere uno o piÃ¹ processi coinvolti nel ciclo.

---

### ðŸ”¹ 6. Algoritmo del Banchiere (Bankerâ€™s Algorithm)

Proposto da Dijkstra, lâ€™**algoritmo del banchiere** Ã¨ un metodo di **evitamento del deadlock** in cui il sistema decide se concedere una richiesta di risorsa **in base alla sicurezza dello stato risultante**.

#### Concetto

Un â€œbanchiereâ€ (il sistema) concede un prestito (una risorsa) solo se, anche dopo la concessione, **puÃ² garantire che tutti i clienti (processi)** saranno in grado di completare le loro operazioni in qualche ordine.

#### Parametri principali

| Simbolo                            | Significato                              |
| ---------------------------------- | ---------------------------------------- |
| `Available`                        | Risorse attualmente libere               |
| `Max[i]`                           | Risorse massime richieste dal processo i |
| `Allocation[i]`                    | Risorse giÃ  assegnate al processo i      |
| `Need[i] = Max[i] - Allocation[i]` | Risorse ancora necessarie                |

#### Procedura

1. Quando un processo `P_i` richiede una risorsa, il sistema controlla se:

         ```text
            Request[i] <= Need[i]
            Request[i] <= Available
         ```

   Se sÃ¬, si **simula lâ€™assegnazione**.

2. Si verifica se il nuovo stato Ã¨ **sicuro**:

   - esiste un ordine in cui tutti i processi possono completare.

3. Se lo stato Ã¨ sicuro â†’ la risorsa viene concessa;
   altrimenti â†’ il processo viene sospeso.

#### Esempio (semplificato)

      ```text
      Available = [3, 3, 2]
      P1 Need = [7, 4, 3]
      P2 Need = [1, 2, 2]
      P3 Need = [6, 0, 0]

      ```

â†’ Il sistema valuta se concedere una richiesta senza uscire dallo stato sicuro.
Se la concessione rompe la condizione, la richiesta viene **posticipata**.

#### Limiti

- Richiede conoscenza preventiva di `Max[i]`.
- Costoso per grandi sistemi.
- Efficace solo per risorse riutilizzabili (CPU, I/O, memoria).

---

### ðŸ”¹ 7. Riepilogo comparativo

| Strategia                | Quando agisce | Meccanismo               | Vantaggi              | Svantaggi                |
| ------------------------ | ------------- | ------------------------ | --------------------- | ------------------------ |
| **Prevenzione**          | Prima         | Evita condizioni di base | Semplice, sicura      | Inefficiente             |
| **Evitamento (Banker)**  | Durante       | Stato sicuro             | Flessibile            | Costoso, richiede Max[i] |
| **Rilevazione/Recupero** | Dopo          | Analisi grafi            | Adatto a batch system | Possibile perdita dati   |

---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      SINCRONIZZAZIONE (II)
      â”‚
      â”œâ”€â”€ Monitor
      â”‚   â”œâ”€ Struttura: variabili, procedure, condizione
      â”‚   â”œâ”€ wait / signal
      â”‚   â””â”€ Mutua esclusione automatica
      â”‚
      â”œâ”€â”€ Deadlock
      â”‚   â”œâ”€ Attesa reciproca tra processi
      â”‚   â”œâ”€ Condizioni (Coffman):
      â”‚   â”‚   â”œâ”€ Mutua esclusione
      â”‚   â”‚   â”œâ”€ Hold and wait
      â”‚   â”‚   â”œâ”€ No preemption
      â”‚   â”‚   â””â”€ Attesa circolare
      â”‚   â””â”€ RAG â†’ rilevazione cicli
      â”‚
      â”œâ”€â”€ Gestione deadlock
      â”‚   â”œâ”€ Prevenzione â†’ elimina condizioni
      â”‚   â”œâ”€ Evitamento â†’ stato sicuro (Banker)
      â”‚   â””â”€ Rilevazione e recupero â†’ kill / rollback
      â”‚
      â””â”€â”€ Algoritmo del banchiere
         â”œâ”€ Available, Max, Allocation, Need
         â”œâ”€ Concede risorsa se stato resta sicuro
         â””â”€ Evita il deadlock dinamicamente

      ```

## Gestione della memoria (I)

---

### ðŸ”¹ Introduzione

La **memoria centrale (RAM)** Ã¨ una delle risorse piÃ¹ importanti e delicate di un sistema operativo, poichÃ© costituisce il **luogo fisico dove vengono caricati i programmi** durante la loro esecuzione.
Il compito del sistema operativo Ã¨ quello di **gestirla in modo efficiente, sicuro e flessibile**, consentendo la convivenza di piÃ¹ processi contemporaneamente senza che interferiscano tra loro.

La gestione della memoria deve garantire tre obiettivi fondamentali:

1. **Rilocazione** â†’ permettere a un processo di essere spostato in memoria senza modificarne il codice.
2. **Protezione** â†’ evitare che un processo acceda a zone di memoria appartenenti ad altri.
3. **Condivisione e uso efficiente** â†’ sfruttare al massimo lo spazio disponibile minimizzando la frammentazione.

Inoltre, Ã¨ necessario prevedere un meccanismo di **traduzione degli indirizzi logici in indirizzi fisici**, poichÃ© ogni processo â€œvedeâ€ la memoria come se fosse un suo spazio indipendente, ma in realtÃ  deve essere collocato da qualche parte nella RAM fisica.

---

### ðŸ”¹ 1. Rilocazione

Ogni programma, quando viene compilato, genera **indirizzi logici** (o virtuali), che partono generalmente da 0.
Tuttavia, quando il programma viene caricato in memoria per lâ€™esecuzione, **potrebbe non essere sempre possibile collocarlo nella stessa posizione fisica**.

#### Concetto

La **rilocazione** Ã¨ il meccanismo che permette di **trasformare gli indirizzi logici** generati dal programma negli **indirizzi fisici effettivi** utilizzati in memoria.
Questa traduzione puÃ² avvenire in diversi momenti:

##### 1. Rilocazione statica

Avviene **al momento del caricamento** del programma.
Il compilatore o il loader calcolano gli indirizzi fisici prima dellâ€™esecuzione.
â†’ Il programma non puÃ² essere spostato durante lâ€™esecuzione.

##### 2. Rilocazione dinamica

Avviene **durante lâ€™esecuzione** del programma.
Gli indirizzi logici vengono tradotti in indirizzi fisici **a runtime** tramite hardware dedicato (es. MMU â€“ *Memory Management Unit*).
â†’ Il processo puÃ² essere spostato in memoria senza doverlo ricompilare.

#### Implementazione hardware

Lâ€™MMU gestisce due registri principali:

- **Registro base (Base Register)** â†’ contiene lâ€™indirizzo fisico iniziale dello spazio di memoria del processo.
- **Registro limite (Limit Register)** â†’ indica la dimensione massima dello spazio del processo.

Ogni indirizzo logico generato dal programma viene tradotto come:

[
\text{Indirizzo fisico} = \text{Base} + \text{Indirizzo logico}
]

E viene controllato che non superi il valore di `Base + Limit`.

---

### ðŸ”¹ 2. Protezione

La **protezione della memoria** serve a impedire che un processo possa **leggere o scrivere in aree non autorizzate**, preservando cosÃ¬ lâ€™integritÃ  del sistema operativo e degli altri processi.

#### Meccanismi di protezione

1. **Controllo hardware con registri base/limite:**
   Ogni accesso a memoria Ã¨ verificato dalla MMU: se lâ€™indirizzo logico esce dal range consentito, viene generata unâ€™**eccezione (trap)** e il processo viene bloccato.

2. **Bit di protezione:**
   In sistemi piÃ¹ evoluti, ogni blocco o pagina di memoria puÃ² avere **bit che definiscono i permessi** (lettura, scrittura, esecuzione).
   â†’ Utilizzato nei sistemi a memoria virtuale (es. `rwx` in Linux).

3. **ModalitÃ  utente e kernel:**
   La CPU lavora in due modalitÃ  operative:

   - **User mode:** accesso limitato solo alla memoria utente.
   - **Kernel mode:** accesso completo a tutte le aree di memoria.

   Il cambio di modalitÃ  avviene solo tramite **system call o interrupt**.

---

### ðŸ”¹ 3. Partizionamento della memoria

Il partizionamento rappresenta uno dei primi approcci alla gestione della memoria multiprogrammata.
Consiste nel **suddividere la RAM in piÃ¹ blocchi (partizioni)** nei quali possono essere caricati diversi processi contemporaneamente.

#### Tipi principali

##### 1. Partizionamento fisso (Fixed Partitioning)

La memoria viene divisa in **partizioni di dimensione predefinita** (uguale o diversa).
Ogni processo viene caricato in una partizione libera sufficientemente grande.

- *Vantaggi:**

- Implementazione semplice.
- Buona protezione (ogni processo resta nella propria partizione).

- *Svantaggi:**

- **Frammentazione interna:** se un processo non riempie la sua partizione, parte della memoria resta inutilizzata.
- Numero di processi limitato al numero di partizioni.
- Difficile adattarsi a programmi di dimensioni variabili.

---

##### 2. Partizionamento variabile (Dynamic Partitioning)

In questo approccio non ci sono partizioni fisse: la memoria viene **assegnata dinamicamente** in base alla dimensione del processo.

Quando un processo termina, la sua area viene liberata, ma ciÃ² puÃ² generare **frammentazione esterna**, cioÃ¨ spazi liberi non contigui e inutilizzabili singolarmente.

- *Soluzioni possibili:**

- **Compattazione:** spostare i processi in modo da riunire le aree libere in un unico blocco (operazione costosa).
- **Allocazione con strategie specifiche:**

  - **First Fit:** assegna la prima area libera sufficientemente grande.
  - **Best Fit:** assegna lâ€™area piÃ¹ piccola possibile che soddisfi la richiesta.
  - **Worst Fit:** assegna lâ€™area piÃ¹ grande disponibile (per ridurre la frammentazione residua).

---

### ðŸ”¹ 4. Buddy System

Il **Buddy System** Ã¨ un metodo di allocazione della memoria che combina lâ€™efficienza del partizionamento variabile con la semplicitÃ  del fisso.
Ãˆ largamente usato nei sistemi moderni (incluso Linux) per gestire la memoria fisica.

#### Funzionamento

Lâ€™idea Ã¨ di dividere la memoria in blocchi di dimensione pari a potenze di 2.
Quando un processo richiede `n` byte, il sistema cerca il blocco piÃ¹ piccolo di potenza di 2 che possa contenerlo.

##### Allocazione

1. Se il blocco disponibile Ã¨ troppo grande, viene **diviso in due metÃ  (buddies)** di uguale dimensione.
2. Il processo viene collocato in uno dei due.
3. Le suddivisioni continuano finchÃ© non si trova un blocco sufficientemente piccolo.

##### Deallocazione

Quando il processo termina, il blocco viene liberato e, se il suo â€œbuddyâ€ adiacente Ã¨ anchâ€™esso libero, i due vengono **riuniti** (merge).
In questo modo il sistema riduce la frammentazione e riutilizza in modo efficiente la memoria.

#### Vantaggi

- Riduce la **frammentazione esterna**.
- Supporta facilmente la **compattazione dinamica**.
- Implementazione semplice con operazioni binarie.

#### Svantaggi

- Possibile **frammentazione interna** (se la richiesta non Ã¨ esattamente una potenza di 2).
- Gli split e merge frequenti possono introdurre **overhead di gestione**.

---

### ðŸ”¹ 5. Considerazioni generali

Ogni tecnica di gestione della memoria rappresenta un compromesso tra **flessibilitÃ **, **efficienza** e **overhead di gestione**.
Sistemi moderni utilizzano combinazioni di piÃ¹ tecniche (es. buddy system per la memoria fisica + paging per quella virtuale).

---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      GESTIONE DELLA MEMORIA (I)
      â”‚
      â”œâ”€â”€ Obiettivi
      â”‚   â”œâ”€ Rilocazione â†’ indirizzi logici â†’ fisici
      â”‚   â”œâ”€ Protezione â†’ accessi controllati
      â”‚   â””â”€ Uso efficiente â†’ frammentazione minima
      â”‚
      â”œâ”€â”€ Rilocazione
      â”‚   â”œâ”€ Statica â†’ traduzione al caricamento
      â”‚   â”œâ”€ Dinamica â†’ traduzione runtime (MMU)
      â”‚   â””â”€ Base + Limit Register
      â”‚
      â”œâ”€â”€ Protezione
      â”‚   â”œâ”€ Registri base/limite
      â”‚   â”œâ”€ Bit di protezione (rwx)
      â”‚   â””â”€ ModalitÃ  user/kernel
      â”‚
      â”œâ”€â”€ Partizionamento
      â”‚   â”œâ”€ Fisso â†’ frammentazione interna
      â”‚   â”œâ”€ Variabile â†’ frammentazione esterna
      â”‚   â”‚   â””â”€ Strategie: First Fit, Best Fit, Worst Fit
      â”‚
      â””â”€â”€ Buddy System
         â”œâ”€ Blocchi in potenze di 2
         â”œâ”€ Split / Merge dinamico
         â”œâ”€ Vantaggi â†’ meno frammentazione
         â””â”€ Svantaggi â†’ overhead e sprechi

      ```

## Gestione della memoria (II)

### ðŸ”¹ Introduzione

Le tecniche di **partizionamento fisso o variabile** viste in precedenza rappresentano i primi metodi di gestione della memoria multiprogrammata, ma hanno un limite evidente:
non permettono di eseguire programmi piÃ¹ grandi della memoria fisica disponibile.

Per superare questa restrizione nasce il concetto di **memoria virtuale**, una tecnica che consente di **astrarre la memoria logica da quella fisica**, permettendo ai processi di â€œvedereâ€ uno spazio di indirizzi molto piÃ¹ ampio di quello realmente presente nella RAM.

---

### ðŸ”¹ 1. Memoria virtuale

La **memoria virtuale** Ã¨ un meccanismo che consente lâ€™esecuzione di processi anche se **solo una parte del loro codice o dei loro dati Ã¨ effettivamente in memoria**.
Le porzioni non necessarie vengono mantenute su disco (spazio di swap) e caricate solo quando richieste.

#### Obiettivi principali

- **Aumentare lâ€™utilizzo della CPU:** i processi non restano in attesa di caricamento completo.
- **Permettere programmi piÃ¹ grandi della RAM fisica.**
- **Isolare gli spazi di memoria dei processi:** ogni processo ha una vista logica indipendente.
- **Gestire automaticamente il caricamento e lo scaricamento delle pagine.**

---

### ðŸ”¹ 2. Paging

Il **paging** Ã¨ la tecnica piÃ¹ diffusa per implementare la memoria virtuale.
Consiste nel suddividere la memoria (sia logica che fisica) in **blocchi di dimensione fissa**.

#### Concetti fondamentali

- **Pagina (Page):** unitÃ  logica di memoria (spazio del processo).
- **Frame:** blocco fisico di memoria (spazio RAM).
- Le dimensioni di pagina e frame sono identiche (tipicamente 4 KB, 8 KB, 16 KB).

Il sistema operativo mantiene una **mappa di corrispondenza** tra pagine logiche e frame fisici, contenuta nella **Page Table** (tabella delle pagine).

#### Funzionamento

1. Ogni indirizzo logico Ã¨ composto da due parti:

         ```text

            [numero di pagina | offset]
         ```

   - Il numero di pagina identifica quale pagina logica viene utilizzata.
   - Lâ€™offset indica la posizione allâ€™interno della pagina.

2. Lâ€™MMU, tramite la **Page Table**, traduce il numero di pagina nel **numero di frame** corrispondente:

         ```text
            indirizzo fisico = base frame + offset
         ```

3. Se la pagina non si trova in memoria (page fault), viene caricata dal disco nello spazio libero.

#### Vantaggi del paging

- Evita la **frammentazione esterna**, poichÃ© i frame sono di dimensione fissa.
- Consente la **rilocazione dinamica** e la **protezione per pagina**.
- Permette **memoria virtuale piÃ¹ ampia** della fisica.

#### Svantaggi

- **Frammentazione interna:** lâ€™ultima pagina di un processo potrebbe non essere completamente utilizzata.
- **Overhead di traduzione:** ogni accesso richiede consultare la tabella delle pagine.

---

### ðŸ”¹ 3. Page Table (Tabella delle pagine)

La **Page Table** Ã¨ una struttura dati fondamentale che associa ogni pagina logica a un frame fisico.
Ogni processo ha la propria tabella delle pagine.

#### Contenuto di ogni voce (entry)

| Campo                  | Descrizione                                                |
| ---------------------- | ---------------------------------------------------------- |
| **Frame number**       | Numero del frame fisico associato alla pagina              |
| **Present bit**        | Indica se la pagina Ã¨ attualmente in memoria               |
| **Modified/Dirty bit** | Indica se la pagina Ã¨ stata modificata (serve per lo swap) |
| **Access bit**         | Usato per implementare politiche di rimpiazzo              |
| **Protection bits**    | Specificano i permessi (lettura, scrittura, esecuzione)    |

---

#### Accesso alla Page Table

Lâ€™accesso alla Page Table introduce un **problema di prestazioni**, perchÃ© per ogni operazione di lettura/scrittura su memoria si dovrebbero fare **due accessi**:

1. Uno alla Page Table per ottenere lâ€™indirizzo fisico.
2. Uno alla memoria effettiva per leggere/scrivere i dati.

Per ridurre questo overhead, si introduce una cache hardware dedicata: la **TLB**.

---

### ðŸ”¹ 4. Translation Lookaside Buffer (TLB)

La **TLB (Translation Lookaside Buffer)** Ã¨ una **cache interna alla MMU** che memorizza le traduzioni recenti tra pagine logiche e frame fisici.
Il suo scopo Ã¨ **velocizzare la traduzione degli indirizzi**.

#### Funzionamento

1. Quando un processo genera un indirizzo logico, lâ€™MMU controlla prima nella TLB:

   - Se la traduzione Ã¨ presente (**TLB hit**) â†’ lâ€™indirizzo fisico Ã¨ immediatamente disponibile.
   - Se non Ã¨ presente (**TLB miss**) â†’ viene consultata la Page Table, e la traduzione viene poi memorizzata nella TLB.

2. La TLB ha dimensioni ridotte (tipicamente da 16 a 512 voci) e viene gestita con politiche di rimpiazzo simili a quelle della cache (LRU, FIFO).

#### Vantaggi

- Riduce drasticamente il tempo medio di accesso alla memoria.
- Migliora le prestazioni della memoria virtuale senza modificare la logica di paging.

#### Svantaggi

- Costo hardware elevato.
- NecessitÃ  di aggiornamento in caso di cambio di contesto (ogni processo ha la propria Page Table â†’ invalidazione TLB).

---

### ðŸ”¹ 5. Paging multilivello

Per processi molto grandi, la Page Table puÃ² diventare **enorme**.
Esempio: uno spazio di indirizzamento logico di 32 bit con pagine da 4 KB â†’ 2Â²â° voci per tabella (oltre 4 MB per processo).

Per ridurre lâ€™uso di memoria, si utilizza la **Page Table multilivello**, che suddivide la tabella in piÃ¹ parti.

#### Funzionamento

1. Lâ€™indirizzo logico Ã¨ diviso in piÃ¹ campi:

         ```text
            [indice livello 1 | indice livello 2 | offset]
         ```

2. Solo i livelli necessari vengono mantenuti in memoria (gli altri possono restare su disco).
3. In sistemi a 64 bit, si usano fino a **4 o 5 livelli** di tabelle (es. x86-64 con PML4, PDPT, PD, PT).

#### Vantaggi

- Riduce lâ€™uso di memoria per le tabelle.
- Supporta grandi spazi di indirizzamento (64 bit).
- Pagina le Page Table stesse (memoria virtuale ricorsiva).

#### Svantaggi

- Aumenta la complessitÃ  hardware e i tempi di traduzione (piÃ¹ accessi successivi).
- Compensato dalla presenza della TLB.

---

### ðŸ”¹ 6. Segmentazione

Il **paging** divide la memoria in blocchi di dimensione fissa, ma alcuni programmi sono piÃ¹ naturalmente suddivisi in **unitÃ  logiche di dimensione variabile** (funzioni, stack, heap, moduli).
Per questo nasce la **segmentazione**.

#### Concetto

La segmentazione suddivide la memoria logica in **segmenti** distinti, ciascuno con **un significato logico** (es. codice, dati, stack).

Ogni indirizzo logico Ã¨ composto da:

[
\text{<numero segmento, offset>}
]

#### Struttura hardware

Il sistema mantiene una **Segment Table**, in cui ogni voce contiene:

| Campo          | Descrizione                             |
| -------------- | --------------------------------------- |
| **Base**       | Indirizzo fisico di inizio del segmento |
| **Limit**      | Dimensione del segmento                 |
| **Protezione** | Permessi di accesso                     |

#### Vantaggi

- Maggiore **modularitÃ  e sicurezza** (ogni segmento puÃ² essere protetto).
- PiÃ¹ adatta ai linguaggi ad alto livello (mappa direttamente funzioni e strutture dati).
- Facile condivisione di segmenti comuni (es. librerie condivise).

#### Svantaggi

- **Frammentazione esterna** (i segmenti sono di dimensione variabile).
- ComplessitÃ  di gestione rispetto al paging puro.

---

### ðŸ”¹ 7. Segmentazione con Paging (ibrido)

I sistemi moderni (es. **x86**) combinano **segmentazione** e **paging**, sfruttando i vantaggi di entrambi.

#### Funzionamento

1. Ogni segmento ha la propria tabella delle pagine.
2. Lâ€™indirizzo logico diventa:

         ```text
            [segmento | pagina | offset]
         ```

3. Il segmento fornisce la base logica, mentre il paging gestisce la mappatura fisica.

#### Vantaggi

- FlessibilitÃ  e modularitÃ  della segmentazione.
- Efficienza e assenza di frammentazione esterna del paging.

#### Svantaggi

- Aumento dellâ€™overhead di traduzione (piÃ¹ livelli da risolvere).
- Implementazione hardware piÃ¹ complessa.

---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      GESTIONE DELLA MEMORIA (II)
      â”‚
      â”œâ”€â”€ Memoria virtuale
      â”‚   â”œâ”€ Spazio logico > spazio fisico
      â”‚   â”œâ”€ Swap su disco
      â”‚   â””â”€ Caricamento su richiesta (page fault)
      â”‚
      â”œâ”€â”€ Paging
      â”‚   â”œâ”€ Pagine (logiche) â†” Frame (fisici)
      â”‚   â”œâ”€ Page Table â†’ mappa logico/fisico
      â”‚   â””â”€ Frammentazione interna
      â”‚
      â”œâ”€â”€ Page Table
      â”‚   â”œâ”€ Frame, Present, Dirty, Access, Protection
      â”‚   â”œâ”€ Overhead di traduzione
      â”‚   â””â”€ Soluzione â†’ TLB
      â”‚
      â”œâ”€â”€ TLB
      â”‚   â”œâ”€ Cache hardware delle traduzioni
      â”‚   â”œâ”€ Hit/Miss
      â”‚   â””â”€ Politiche di rimpiazzo
      â”‚
      â”œâ”€â”€ Paging multilivello
      â”‚   â”œâ”€ Page Table gerarchiche
      â”‚   â”œâ”€ Riduzione uso memoria
      â”‚   â””â”€ Aumento tempi traduzione
      â”‚
      â”œâ”€â”€ Segmentazione
      â”‚   â”œâ”€ UnitÃ  logiche variabili
      â”‚   â”œâ”€ Segment Table (Base, Limit)
      â”‚   â””â”€ Frammentazione esterna
      â”‚
      â””â”€â”€ Segmentazione + Paging
         â”œâ”€ Indirizzo = [segmento | pagina | offset]
         â”œâ”€ FlessibilitÃ  e protezione
         â””â”€ Maggiore complessitÃ 

      ```

## Gestione della memoria (III)

---

### ðŸ”¹ Introduzione

Dopo aver introdotto la memoria virtuale e i meccanismi di paging, resta da affrontare uno degli aspetti piÃ¹ complessi della gestione della memoria: **la scelta delle pagine da mantenere in RAM e quelle da rimpiazzare** quando la memoria fisica Ã¨ piena.

Ogni volta che un processo accede a una pagina non presente in memoria, si verifica un **page fault**, che richiede di caricare la pagina dal disco.
Questo evento Ã¨ molto costoso (migliaia di cicli di CPU) e influisce direttamente sulle prestazioni del sistema.

Per questo motivo, Ã¨ fondamentale adottare **algoritmi di rimpiazzo** efficienti e strategie di controllo che limitino il numero di page fault e prevengano fenomeni di **thrashing**.

---

### ðŸ”¹ 1. Page Fault e Swapping

Un **page fault** si verifica quando un processo accede a una pagina che **non Ã¨ attualmente in memoria fisica**.
Il sistema operativo interviene con una serie di operazioni:

1. **Interruzione** â†’ la CPU rileva il page fault e passa il controllo al sistema operativo.
2. **Verifica** â†’ si controlla se lâ€™indirizzo richiesto Ã¨ valido e la pagina appartiene effettivamente al processo.
3. **Scelta del frame da liberare** â†’ se la memoria Ã¨ piena, occorre liberare un frame usando un **algoritmo di rimpiazzo**.
4. **Scrittura su disco** â†’ se la pagina nel frame scelto Ã¨ â€œdirtyâ€, viene salvata (scritta su disco).
5. **Caricamento della nuova pagina** â†’ la pagina mancante viene caricata dallo spazio di swap nel frame libero.
6. **Aggiornamento delle tabelle** (Page Table e TLB).
7. **Ripresa dellâ€™esecuzione** dal punto in cui il processo era stato interrotto.

Il **tempo medio di accesso effettivo alla memoria (EAT)** dipende dalla frequenza di page fault e dal tempo necessario per gestirli:

[
EAT = (1 - p) \times t_m + p \times t_{pf}
]

dove:

- ( t_m ) = tempo di accesso alla memoria,
- ( p ) = probabilitÃ  di page fault,
- ( t_{pf} ) = tempo di servizio del page fault (molto elevato).

Anche una piccola percentuale di page fault (es. 0,01%) puÃ² aumentare drasticamente il tempo medio di accesso.

---

### ðŸ”¹ 2. Algoritmi di rimpiazzo delle pagine

Quando non ci sono frame liberi, il sistema operativo deve scegliere **quale pagina rimuovere dalla memoria** per fare spazio a quella nuova.
Questa decisione Ã¨ critica: una scelta sbagliata puÃ² aumentare il numero di page fault.

Di seguito i principali algoritmi, dal piÃ¹ semplice al piÃ¹ sofisticato.

---

#### FIFO â€“ *First In, First Out*

- Le pagine vengono gestite in una coda circolare: la piÃ¹ vecchia viene rimpiazzata per prima.
- Implementazione semplice, ma **non tiene conto dellâ€™utilizzo effettivo**.

- *Problemi:**

- Possibile **anomalÃ¬a di Belady** â†’ aumentando il numero di frame, i page fault possono aumentare invece di diminuire.
- Scarsa efficienza per programmi che riutilizzano frequentemente le stesse pagine.

---

#### OPT â€“ *Optimal Replacement* (teorico)

- Rimpiazza la pagina che **non sarÃ  piÃ¹ utilizzata per il periodo di tempo piÃ¹ lungo**.
- Ãˆ lâ€™algoritmo ideale in termini di prestazioni minime di page fault.

- *Limite:**
Non puÃ² essere implementato realmente, perchÃ© richiede la conoscenza futura della sequenza di accessi.
â†’ Viene usato come **riferimento teorico** per confrontare le prestazioni degli altri algoritmi.

---

#### LRU â€“ *Least Recently Used*

- Rimpiazza la pagina **non utilizzata da piÃ¹ tempo**.
- Si basa sul principio di **localitÃ  temporale**: le pagine usate di recente tenderanno a essere usate ancora a breve.

- *Implementazioni possibili:**

1. **Contatori temporali:** ogni pagina ha un timestamp aggiornato a ogni accesso.
   â†’ quando serve rimpiazzare, si sceglie quella con il timestamp piÃ¹ vecchio.
   (Preciso ma costoso da aggiornare a ogni accesso).

2. **Stack (lista ordinata):** le pagine sono mantenute in una lista, e ogni accesso sposta la pagina in testa.
   â†’ buona accuratezza ma overhead alto.

- *Vantaggi:**

- Prestazioni vicine allâ€™ottimo.

- *Svantaggi:**

- Costi hardware e software elevati per mantenere lo storico.

---

#### Second-Chance (Clock Algorithm)

Ãˆ una **versione approssimata di LRU**, molto usata nei sistemi reali.
Le pagine sono disposte in un **buffer circolare** (come FIFO), ma ogni pagina ha un **bit di riferimento (R)**.

- *Funzionamento:**

1. Quando si deve rimpiazzare una pagina, si controlla il bit R della pagina â€œpiÃ¹ vecchiaâ€:

   - Se R = 0 â†’ viene rimpiazzata.
   - Se R = 1 â†’ il bit viene azzerato e la pagina riceve una â€œseconda possibilitÃ â€.
2. Lâ€™indicatore (clock hand) avanza fino a trovare una pagina con R = 0.

- *Vantaggi:**

- Prestazioni simili a LRU, ma con overhead ridotto.
- Implementazione efficiente a livello hardware.

---

#### NRU â€“ *Not Recently Used*

Classifica le pagine in quattro categorie, combinando due bit:

| Bit R | Bit M | Categoria                        | PrioritÃ  di rimpiazzo |
| ----- | ----- | -------------------------------- | --------------------- |
| 0     | 0     | Non usata nÃ© modificata          | Alta                  |
| 0     | 1     | Non usata, modificata            | Media                 |
| 1     | 0     | Usata di recente, non modificata | Bassa                 |
| 1     | 1     | Usata e modificata               | Molto bassa           |

Lâ€™algoritmo sceglie una pagina casuale dalla **classe con prioritÃ  piÃ¹ alta** disponibile.
Semplice ma meno preciso rispetto a LRU.

---

#### LFU â€“ *Least Frequently Used*

Rimuove la pagina **meno utilizzata nel tempo** (in base a un contatore di accessi).
Buono per carichi stabili, ma puÃ² reagire male a variazioni improvvise di comportamento (pagine vecchie ma â€œpopolariâ€ restano troppo a lungo).

---

### ðŸ”¹ 3. Algoritmi di allocazione dei frame

Ogni processo deve avere assegnato un certo numero di **frame** in memoria fisica.
Il sistema operativo deve stabilire **quanti frame concedere** e come gestirli nel tempo.

#### Allocazione fissa vs dinamica

- **Allocazione fissa:**
  ogni processo riceve un numero costante di frame per tutta la durata.
  â†’ semplice ma inefficiente se i processi cambiano comportamento.

- **Allocazione dinamica:**
  i frame vengono assegnati e revocati dinamicamente in base al carico o al numero di page fault.

#### Allocazione proporzionale

I frame vengono assegnati in proporzione alla dimensione del processo:
[
\text{frame_i} = \frac{\text{dimensione_i}}{\text{totale_memoria}} \times \text{frame_totali}
]

#### Allocazione con prioritÃ 

I processi con prioritÃ  piÃ¹ alta ricevono piÃ¹ frame (o frame riservati) per ridurre il rischio di page fault critici.

---

### ðŸ”¹ 4. Thrashing

Il **thrashing** Ã¨ un fenomeno che si verifica quando un processo spende piÃ¹ tempo a eseguire operazioni di **paging (swap in/out)** che ad eseguire istruzioni utili.
In pratica, la memoria Ã¨ troppo piccola per mantenere il **working set** del processo, causando continui page fault.

#### Cause principali

- Numero di processi troppo alto rispetto alla RAM disponibile.
- Allocazione inadeguata dei frame.
- Algoritmi di rimpiazzo non ottimali.

#### Effetti

- Crollo del throughput.
- CPU fortemente sotto-utilizzata (la maggior parte del tempo attende I/O).
- Drastico rallentamento del sistema.

---

### ðŸ”¹ 5. Modelli di controllo del thrashing

#### a) Working Set Model

Il **working set** di un processo Ã¨ lâ€™insieme delle pagine che **sono state utilizzate recentemente** in una finestra temporale âˆ† (numero di riferimenti).

Lâ€™idea Ã¨ che un processo ha bisogno di mantenere in RAM il proprio working set per funzionare in modo efficiente.

- *Strategia:**

- Si monitora il working set di ciascun processo.
- Se la somma dei working set di tutti i processi supera la memoria fisica, il sistema sospende o swap-out alcuni processi.
  â†’ Evita il thrashing globale.

#### b) Page Fault Frequency (PFF)

Si basa sulla **frequenza di page fault** del processo:

- Se la frequenza di page fault Ã¨ **troppo alta**, vengono assegnati piÃ¹ frame.
- Se Ã¨ **troppo bassa**, alcuni frame vengono tolti (per essere assegnati ad altri processi).

Questo metodo consente un adattamento dinamico in base al comportamento effettivo.

---

### ðŸ”¹ 6. Prestazioni e compromessi

Il controllo della memoria virtuale si basa su un equilibrio tra:

- **Numero di frame assegnati** â†” **page fault rate**
- **Politiche di rimpiazzo** â†” **overhead di gestione**
- **Multiprogrammazione** â†” **thrashing**

Un sistema operativo efficiente deve saper **adattare dinamicamente le politiche di allocazione e sostituzione** in funzione del carico.

---

### ðŸ§  Mappa concettuale di sintesi

      ```text

      GESTIONE DELLA MEMORIA (III)
      â”‚
      â”œâ”€â”€ Page Fault
      â”‚   â”œâ”€ Rilevamento e gestione
      â”‚   â”œâ”€ Swapping su disco
      â”‚   â””â”€ Tempo medio EAT = (1-p)*tm + p*tpf
      â”‚
      â”œâ”€â”€ Algoritmi di rimpiazzo
      â”‚   â”œâ”€ FIFO â†’ semplice, ma Belady
      â”‚   â”œâ”€ OPT â†’ ideale, teorico
      â”‚   â”œâ”€ LRU â†’ localitÃ  temporale
      â”‚   â”œâ”€ Second-Chance â†’ approssimazione LRU
      â”‚   â”œâ”€ NRU â†’ classi R/M
      â”‚   â””â”€ LFU â†’ frequenza accessi
      â”‚
      â”œâ”€â”€ Allocazione frame
      â”‚   â”œâ”€ Fissa vs dinamica
      â”‚   â”œâ”€ Proporzionale â†’ dimensione processo
      â”‚   â””â”€ Per prioritÃ 
      â”‚
      â”œâ”€â”€ Thrashing
      â”‚   â”œâ”€ Cause â†’ troppe page fault
      â”‚   â”œâ”€ Effetti â†’ CPU inattiva, swap continuo
      â”‚   â””â”€ Soluzioni â†’ Working Set, PFF
      â”‚
      â””â”€â”€ Controllo dinamico
         â”œâ”€ Working Set â†’ memoria minima necessaria
         â””â”€ PFF â†’ adattamento automatico

      ```

---

Vuoi che per **MartedÃ¬ 14/10 â€“ File System (I)** passiamo alla parte su **organizzazione, strutture, e gestione dei file (directory, metadati, allocazione)** con lo stesso stile e profonditÃ ?

## File System (I)

### ðŸ”¹ Introduzione generale

Il **file system** Ã¨ la componente del sistema operativo che gestisce la **memorizzazione permanente dei dati**.
A differenza della memoria principale (RAM), la memoria di massa Ã¨ **non volatile**, quindi mantiene i dati anche dopo lo spegnimento del sistema.

Il file system si occupa di:

- **organizzare i dati** in strutture logiche (file, directory);
- **gestire lo spazio su disco**;
- **fornire accesso controllato e sicuro** ai dati;
- **astrarre i dispositivi fisici**, offrendo unâ€™interfaccia uniforme ai programmi.

Dal punto di vista dellâ€™utente e dei processi, il file system fornisce un modello **astratto** del disco:
ogni dispositivo di memoria Ã¨ visto come un insieme di **file e cartelle**, indipendentemente dal tipo di hardware sottostante.

---

### ðŸ”¹ 1. Concetto di file

Un **file** Ã¨ un insieme di informazioni memorizzate su un supporto di memoria secondaria, gestite come unâ€™unica unitÃ  logica.
Il sistema operativo fornisce una **struttura uniforme** per tutti i file, indipendentemente dal loro contenuto.

#### Tipi di file

- **File di testo:** sequenze di caratteri leggibili (es. `.txt`, `.c`, `.md`).
- **File binari:** contengono dati non interpretati direttamente come caratteri (es. eseguibili, immagini, database).
- **File di sistema:** file speciali gestiti dal kernel (es. `/proc` in Linux, device file in `/dev`).

#### Attributi di un file

Ogni file possiede una serie di **metadati**, che ne descrivono le proprietÃ .
Queste informazioni vengono mantenute nella **directory** o in strutture specifiche come gli **inode** (nei sistemi UNIX).

| Attributo             | Descrizione                                 |
| --------------------- | ------------------------------------------- |
| Nome                  | Identificatore del file nel file system     |
| Tipo                  | Binario, testo, eseguibile, directory, ecc. |
| Dimensione            | Numero di byte occupati                     |
| Permessi              | Lettura, scrittura, esecuzione              |
| Proprietario e gruppo | Utente/i che possono accedere               |
| Data e ora            | Creazione, ultima modifica, ultimo accesso  |
| Puntatori ai blocchi  | Indirizzi fisici dei dati sul disco         |

---

### ðŸ”¹ 2. Operazioni sui file

Il sistema operativo fornisce una serie di **primitive** o **chiamate di sistema (system call)** per la gestione dei file.
Le principali operazioni sono:

| Operazione | Descrizione                                           |
| ---------- | ----------------------------------------------------- |
| **Create** | Crea un nuovo file nel file system                    |
| **Open**   | Apre un file esistente per la lettura o scrittura     |
| **Read**   | Legge dati dal file nella memoria                     |
| **Write**  | Scrive dati dalla memoria nel file                    |
| **Seek**   | Sposta il puntatore interno a una posizione specifica |
| **Close**  | Chiude un file aperto                                 |
| **Delete** | Elimina un file dal file system                       |

Ogni file aperto Ã¨ associato a un **file descriptor**, un identificatore univoco che il kernel usa per tenere traccia dei file aperti da ciascun processo.

---

### ðŸ”¹ 3. Struttura logica del file system

Il file system non si limita a gestire file individuali, ma organizza lâ€™intera memoria di massa in **livelli logici**.
Questa stratificazione permette di separare le funzioni astratte (viste dallâ€™utente) dai dettagli fisici del disco.

#### Livelli principali

1. **File system utente (User view):**
   Lâ€™utente interagisce con i file tramite percorsi e directory (`/home/emiliano/documenti/`).
   â†’ Livello logico e simbolico.

2. **File system logico (Logical):**
   Il sistema operativo gestisce metadati, strutture, permessi e indirizzamenti logici.
   â†’ Qui operano le funzioni di allocazione e protezione.

3. **File system fisico (Physical):**
   Interfaccia diretta con il **device driver del disco**, che gestisce i blocchi fisici e la cache.

Questa stratificazione consente di cambiare il tipo di disco o supporto (SSD, HDD, chiavetta) **senza modificare i programmi utente**, poichÃ© il file system fornisce un livello di astrazione hardware-indipendente.

---

### ðŸ”¹ 4. Struttura delle directory

Le **directory** (o cartelle) sono file speciali che contengono **elenco e metadati** dei file presenti in una determinata area del file system.
Servono a organizzare e raggruppare logicamente i dati.

#### Tipi di struttura delle directory

##### a) Struttura a livello singolo

Tutti i file si trovano in unâ€™unica directory.
â†’ Molto semplice ma **non scalabile**: i nomi devono essere univoci e lâ€™organizzazione diventa caotica.

##### b) Struttura a due livelli

Ogni utente ha la propria directory separata (es. `/home/utente1/`, `/home/utente2/`).
â†’ Migliora lâ€™organizzazione, ma non consente gerarchie piÃ¹ profonde.

##### c) Struttura gerarchica (ad albero)

Ãˆ la struttura piÃ¹ comune (usata in UNIX, Linux, Windows).
Ogni directory puÃ² contenere file e altre directory.
â†’ Permette unâ€™organizzazione logica e modulare.

- *Esempio:**

      ```text
      /
      â”œâ”€â”€ bin/
      â”œâ”€â”€ home/
      â”‚   â”œâ”€â”€ emiliano/
      â”‚   â”‚   â”œâ”€â”€ documenti/
      â”‚   â”‚   â””â”€â”€ immagini/
      â””â”€â”€ etc/

      ```

##### d) Strutture con link

Alcuni file system supportano **collegamenti (link)** che puntano a file o directory esistenti:

- **Hard link:** riferimento diretto allo stesso inode (identico file).
- **Symbolic link (soft link):** file separato che contiene il percorso del file originale.

---

### ðŸ”¹ 5. Gestione dello spazio su disco

Il disco Ã¨ suddiviso in **blocchi fisici** (tipicamente da 512 byte a 4 KB).
Il file system deve assegnare questi blocchi ai file in modo efficiente, tenendo conto di prestazioni e frammentazione.

#### Metodi di allocazione

##### a) Allocazione contigua

I blocchi di un file sono memorizzati in **posizioni consecutive** sul disco.

- *Vantaggi:**

- Accesso sequenziale molto veloce (i dati sono adiacenti).
- Facile calcolo dellâ€™indirizzo fisico.

- *Svantaggi:**

- Necessario conoscere la dimensione del file in anticipo.
- **Frammentazione esterna**: difficile trovare blocchi contigui liberi.

---

##### b) Allocazione concatenata (Linked allocation)

Ogni file Ã¨ una **catena di blocchi** collegati da puntatori.
Il primo blocco contiene un riferimento al successivo, e cosÃ¬ via.

- *Vantaggi:**

- Nessuna frammentazione esterna.
- Facile estendere i file.

- *Svantaggi:**

- Accesso casuale lento (necessario attraversare la catena).
- Overhead di spazio per i puntatori.
- Rischio di perdita di dati se un blocco della catena si danneggia.

---

##### c) Allocazione indicizzata

Ogni file ha una **tabella di indice** (index block) che elenca tutti i blocchi che compongono il file.
Simile alla Page Table nella memoria virtuale.

- *Vantaggi:**

- Accesso diretto e casuale efficiente.
- Nessuna frammentazione esterna.
- Facile estensione del file.

- *Svantaggi:**

- Overhead di spazio per mantenere gli indici.
- Lâ€™indice stesso deve essere memorizzato e gestito come file.

- *Esempio (in UNIX):**
Il sistema usa strutture **inode**, dove ogni inode contiene:

- indirizzi diretti (blocchi immediati),
- indiretti singoli, doppi e tripli (puntatori a tabelle di indirizzi).

---

### ðŸ”¹ 6. Gestione dei metadati: inode

Nei sistemi UNIX/Linux, ogni file Ã¨ rappresentato da un **inode** (index node), una struttura che memorizza **tutte le informazioni sul file tranne il nome**.

#### Contenuto di un inode

| Campo                         | Descrizione                                |
| ----------------------------- | ------------------------------------------ |
| Identificatore (inode number) | Numero univoco del file                    |
| Tipo di file                  | Normale, directory, device, link           |
| Permessi e modalitÃ            | rwx per utente, gruppo e altri             |
| Proprietario / gruppo         | UID e GID                                  |
| Dimensione                    | In byte                                    |
| Timestamp                     | Creazione, modifica, accesso               |
| Puntatori ai blocchi          | Diretti, indiretti singoli, doppi e tripli |

Il nome del file Ã¨ mantenuto separatamente nella directory, che associa il nome allâ€™inode corrispondente.
Questo meccanismo consente la presenza di piÃ¹ **hard link** per lo stesso file (piÃ¹ nomi che puntano allo stesso inode).

---

### ðŸ”¹ 7. Montaggio del file system

I moderni sistemi supportano **piÃ¹ file system contemporaneamente** (es. ext4, FAT32, NTFS, ecc.), montati in una **gerarchia unica**.

Lâ€™operazione di **mount** associa un file system fisico (es. una partizione o chiavetta) a una directory esistente nel file system principale.

- *Esempio:**

      ```bash
      mount /dev/sdb1 /mnt/usb
      ```

      â†’ La partizione `sdb1` sarÃ  accessibile sotto la directory `/mnt/usb`.

      ---

### ðŸ§  Mappa concettuale di sintesi

      ```text
      FILE SYSTEM (I)
      â”‚
      â”œâ”€â”€ Definizione
      â”‚   â”œâ”€ Organizzazione dati su memoria permanente
      â”‚   â”œâ”€ Interfaccia astratta ai dispositivi
      â”‚   â””â”€ Gestione accesso e protezione
      â”‚
      â”œâ”€â”€ File
      â”‚   â”œâ”€ Tipi â†’ testo, binario, sistema
      â”‚   â”œâ”€ Attributi â†’ nome, tipo, permessi, dimensione, date
      â”‚   â””â”€ Metadati â†’ gestiti in inode
      â”‚
      â”œâ”€â”€ Operazioni
      â”‚   â”œâ”€ Create, Open, Read, Write
      â”‚   â”œâ”€ Seek, Close, Delete
      â”‚   â””â”€ File descriptor
      â”‚
      â”œâ”€â”€ Struttura logica
      â”‚   â”œâ”€ Livello utente â†’ percorsi
      â”‚   â”œâ”€ Livello logico â†’ metadati, allocazione
      â”‚   â””â”€ Livello fisico â†’ blocchi e driver
      â”‚
      â”œâ”€â”€ Directory
      â”‚   â”œâ”€ Singolo livello
      â”‚   â”œâ”€ Due livelli
      â”‚   â”œâ”€ Gerarchico (ad albero)
      â”‚   â””â”€ Link simbolici / hard link
      â”‚
      â”œâ”€â”€ Allocazione spazio
      â”‚   â”œâ”€ Contigua â†’ veloce, ma frammentata
      â”‚   â”œâ”€ Concatenata â†’ flessibile, lenta
      â”‚   â””â”€ Indicizzata â†’ efficiente, overhead indice
      â”‚
      â”œâ”€â”€ Inode
      â”‚   â”œâ”€ Identifica file
      â”‚   â”œâ”€ Metadati e puntatori
      â”‚   â””â”€ Supporta hard link
      â”‚
      â””â”€â”€ Montaggio
         â”œâ”€ mount device â†’ directory
         â””â”€ Unione di piÃ¹ FS in una gerarchia

      ```

## File System (II)

### ðŸ”¹ Introduzione

Dopo aver analizzato la struttura logica dei file system e i meccanismi di allocazione dei file, in questa lezione approfondiamo **la gestione dello spazio libero**, **le strutture dati interne (FAT e inode)**, e i meccanismi che garantiscono **lâ€™integritÃ  e la coerenza dei dati**, come **il journaling e la cache del disco**.

Lâ€™obiettivo del file system Ã¨ non solo memorizzare i dati, ma **preservarli in modo sicuro e coerente** anche in caso di crash o spegnimenti improvvisi, mantenendo buone prestazioni di accesso.

---

### ðŸ”¹ 1. Gestione dello spazio libero

Ogni file system deve gestire **lâ€™insieme dei blocchi liberi** del disco, in modo da poterli assegnare ai file che crescono o ai nuovi file creati.
La scelta della tecnica influenza fortemente la **velocitÃ  di allocazione**, lâ€™**uso efficiente dello spazio** e la **facilitÃ  di recupero** in caso di errore.

#### Tecniche principali

##### a) Bitmap (mappa dei bit)

Il disco Ã¨ rappresentato da una sequenza di **bit**, uno per ogni blocco:

- `1` â†’ blocco occupato
- `0` â†’ blocco libero

- *Vantaggi:**

- Ricerca rapida di blocchi liberi (si possono usare istruzioni bitwise).
- Struttura compatta (es. 1 bit per 4 KB â†’ 128 KB di bitmap per 1 TB di disco).
- Facile salvataggio e aggiornamento.

- *Svantaggi:**

- Serve scansionare la bitmap per trovare gruppi contigui di blocchi (per file grandi).
- Se frammentata, le prestazioni di lettura peggiorano.

---

##### b) Lista concatenata di blocchi liberi (Linked free list)

Tutti i blocchi liberi sono collegati tra loro tramite puntatori: ogni blocco libero contiene lâ€™indirizzo del successivo.

- *Vantaggi:**

- Implementazione semplice.
- Non serve una tabella separata in memoria.

- *Svantaggi:**

- Accesso lento (deve attraversare lâ€™intera lista).
- Se un blocco della lista si danneggia â†’ perdita di collegamento a tutti i blocchi successivi.

---

##### c) Gruppi di blocchi liberi (Grouping)

Usata in alcuni file system UNIX:
ogni blocco libero contiene **indirizzi di piÃ¹ blocchi liberi** (un piccolo array di puntatori), e lâ€™ultimo puntatore rimanda al gruppo successivo.

â†’ Compromesso tra lista concatenata e bitmap: riduce il numero di accessi per individuare nuovi blocchi.

---

##### d) Contatori (Counting)

Usata quando piÃ¹ blocchi liberi sono consecutivi:
invece di elencarli tutti, si memorizza una coppia `(indirizzo iniziale, quantitÃ )`.

- *Esempio:**
(200, 5) â†’ blocchi liberi 200â€“204.

- *Vantaggi:**

- Ideale per file system che liberano interi segmenti di blocchi insieme.
- Molto compatta.

---

### ðŸ”¹ 2. Strutture dati interne: FAT e inode

#### a) FAT â€“ *File Allocation Table*

Usata nei file system della famiglia **MS-DOS, FAT16, FAT32**.

La FAT Ã¨ una **grande tabella** in cui ogni voce corrisponde a un blocco del disco e contiene:

- `0` â†’ blocco libero
- `EOF` â†’ ultimo blocco del file
- valore `x` â†’ blocco successivo nella catena del file

Il sistema tiene una sola copia (o due per sicurezza) della tabella FAT allâ€™inizio del disco.

- *Esempio:**

      ```text
      Blocco 5 â†’ 9
      Blocco 9 â†’ 13
      Blocco 13 â†’ EOF
      ```

Significa che il file occupa i blocchi 5 â†’ 9 â†’ 13.

- *Vantaggi:**

- Implementazione semplice.
- Facile navigazione sequenziale dei file.
- Indipendente dal tipo di dispositivo.

- *Svantaggi:**

- Tutta la tabella deve risiedere in memoria â†’ poco scalabile per dischi grandi.
- Accesso casuale costoso (bisogna attraversare la catena).
- Facilmente danneggiabile (la corruzione della FAT puÃ² compromettere tutto il file system).

---

#### b) inode (UNIX / Linux)

Ogni file Ã¨ descritto da un **inode**, che contiene tutte le informazioni di gestione e i puntatori ai blocchi di dati.

Come visto, lâ€™inode mantiene:

- **Puntatori diretti** â†’ fino a 12 blocchi dati immediati
- **Puntatori indiretti singoli, doppi, tripli** â†’ strutture ricorsive che permettono di raggiungere file molto grandi

- *Esempio tipico (ext4):**

| Tipo di puntatore   | Descrizione                                       | Copertura approssimata |
| ------------------- | ------------------------------------------------- | ---------------------- |
| 12 diretti          | Puntano direttamente ai blocchi dati              | File piccoli (~48 KB)  |
| 1 indiretto singolo | Puntatore a blocco contenente altri indirizzi     | ~4 MB                  |
| 1 indiretto doppio  | Puntatore a blocchi di indirizzi di altri blocchi | ~4 GB                  |
| 1 indiretto triplo  | Puntatore a blocchi di indirizzi di indirizzi     | ~4 TB                  |

Questo approccio rende gli inode **flessibili e scalabili**, ma introduce un **overhead maggiore** per i file di grandi dimensioni (piÃ¹ accessi a livelli intermedi).

---

### ðŸ”¹ 3. Gestione dello spazio libero e allocazione combinata

I file system moderni (es. ext4, NTFS, APFS, XFS) combinano piÃ¹ tecniche per **massimizzare efficienza e integritÃ **:

- **Bitmap per lo spazio libero** â†’ rapida individuazione blocchi.
- **Inode o strutture indicizzate** â†’ gestione efficiente dei file.
- **Allocazione per estensioni (extent)** â†’ blocchi contigui trattati come unâ€™unica unitÃ  logica (riduce frammentazione e overhead).

#### Extent

Un **extent** rappresenta una sequenza contigua di blocchi fisici assegnati a un file.
Invece di memorizzare ogni blocco singolo, lâ€™inode memorizza `(blocco_inizio, lunghezza)`.

- *Vantaggi:**

- Migliore localitÃ  spaziale (file piÃ¹ compatti sul disco).
- Meno frammentazione e minore overhead nella tabella degli indici.

- *Usato in:** ext4, XFS, NTFS, Btrfs.

---

### ðŸ”¹ 4. Journaling e coerenza del file system

Uno dei problemi principali dei file system tradizionali Ã¨ la **perdita di coerenza** in caso di crash (es. interruzione di corrente durante la scrittura).
Il **journaling** Ã¨ un meccanismo che registra **le operazioni imminenti su unâ€™area speciale del disco (journal)** prima di eseguirle realmente.

#### Funzionamento

1. Ogni operazione (creazione, eliminazione, modifica) viene **scritta nel journal** come transazione.
2. Solo dopo la conferma della scrittura nel journal, lâ€™operazione viene **eseguita sui dati reali**.
3. Se il sistema si blocca prima del completamento, al riavvio il file system **legge il journal** e:

   - applica le operazioni non ancora completate, oppure
   - le annulla per mantenere la consistenza.

#### Tipi di journaling

- **Write-ahead logging:** scrive prima nel journal, poi nei blocchi dati (metodo standard).
- **Ordered journaling:** prima i dati, poi i metadati (usato in ext3/ext4).
- **Full data journaling:** registra anche i contenuti dei file (massima sicurezza, ma rallenta).

#### Vantaggi

- Riduce drasticamente i tempi di recupero dopo crash.
- Garantisce la **consistenza dei metadati**.
- Evita la necessitÃ  di eseguire lo scan completo del disco (come `fsck`).

#### Svantaggi

- Overhead in scrittura (ogni operazione viene duplicata).
- Journal stesso puÃ² frammentarsi nel tempo.

---

### ðŸ”¹ 5. Cache del disco e buffering

Per migliorare le prestazioni, il sistema operativo utilizza **buffer in memoria** per evitare accessi frequenti e lenti al disco.
Questa tecnica Ã¨ gestita dal **buffer cache** o **page cache** del kernel.

#### Tipologie di cache

1. **Read cache:**
   Le pagine lette dal disco vengono mantenute in RAM; se lo stesso file viene letto di nuovo, lâ€™accesso Ã¨ immediato.

2. **Write-back cache:**
   Le scritture non vengono eseguite subito sul disco ma accumulate e scritte periodicamente o al rilascio del file.

3. **Write-through cache:**
   Ogni scrittura aggiorna immediatamente il disco â†’ maggiore sicurezza ma minore velocitÃ .

#### Vantaggi

- Accesso ai file fino a 100Ã— piÃ¹ rapido rispetto allâ€™I/O diretto.
- Riduzione delle scritture ridondanti.
- Maggiore parallelismo tra processi e I/O.

#### Svantaggi

- Perdita di dati in caso di crash prima dello svuotamento del buffer.
- NecessitÃ  di sincronizzazione (`sync`, `fsync`) per forzare il flush dei dati sul disco.

---

### ðŸ”¹ 6. Verifica e recupero della consistenza

Nonostante i meccanismi di journaling, possono verificarsi errori dovuti a:

- danni fisici del disco,
- corruzione del journal,
- errori di sincronizzazione.

I sistemi UNIX/Linux utilizzano comandi di controllo come:

- **`fsck` (file system check):** analizza e corregge le incongruenze (blocchi orfani, inode non referenziati).
- **`e2fsck`:** specifico per file system ext2/3/4.
- **`xfs_repair`:** per XFS.

Durante la verifica, il sistema confronta bitmap, inode e directory per ricostruire la struttura logica corretta.

---

### ðŸ§  Mappa concettuale di sintesi

      ```text

      FILE SYSTEM (II)
      â”‚
      â”œâ”€â”€ Gestione spazio libero
      â”‚   â”œâ”€ Bitmap â†’ veloce, compatta
      â”‚   â”œâ”€ Lista concatenata â†’ semplice, lenta
      â”‚   â”œâ”€ Gruppi di blocchi â†’ ibrido
      â”‚   â””â”€ Contatori â†’ blocchi contigui
      â”‚
      â”œâ”€â”€ Strutture dati
      â”‚   â”œâ”€ FAT â†’ tabella globale, semplice
      â”‚   â”œâ”€ inode â†’ puntatori diretti/indiretti
      â”‚   â””â”€ Extent â†’ blocchi contigui in gruppo
      â”‚
      â”œâ”€â”€ Journaling
      â”‚   â”œâ”€ Journal = log delle operazioni
      â”‚   â”œâ”€ Recupero dopo crash
      â”‚   â”œâ”€ Tipi: write-ahead, ordered, full
      â”‚   â””â”€ Vantaggi â†’ consistenza, tempi ridotti
      â”‚
      â”œâ”€â”€ Cache e buffering
      â”‚   â”œâ”€ Read cache â†’ dati letti
      â”‚   â”œâ”€ Write-back â†’ scrittura differita
      â”‚   â”œâ”€ Write-through â†’ scrittura immediata
      â”‚   â””â”€ Rischi â†’ perdita dati se crash
      â”‚
      â””â”€â”€ Consistenza e verifica
         â”œâ”€ fsck, e2fsck, xfs_repair
         â””â”€ Ricostruzione metadati e directory

      ```

## Sicurezza e Protezione

---

### ðŸ”¹ Introduzione

Un sistema operativo non deve solo gestire risorse e processi in modo efficiente: deve anche **proteggerli** da accessi non autorizzati e **preservare la sicurezza dei dati e delle operazioni**.
In altre parole, deve garantire che ogni processo o utente **possa accedere solo alle risorse per le quali Ã¨ autorizzato**.

La **protezione** riguarda la **correttezza e lâ€™integritÃ  interna del sistema**, mentre la **sicurezza** si estende anche a minacce esterne (es. accessi da rete, utenti malevoli, malware).

Questi due concetti, spesso sovrapposti, si distinguono cosÃ¬:

| Aspetto             | Protezione                             | Sicurezza                           |
| ------------------- | -------------------------------------- | ----------------------------------- |
| Scopo               | Limitare lâ€™uso improprio delle risorse | Impedire violazioni e attacchi      |
| Origine del rischio | Interna (errori, conflitti)            | Esterna (malware, intrusione)       |
| Mezzo               | Meccanismi di controllo accessi        | Cifratura, autenticazione, auditing |

---

### ðŸ”¹ 1. Obiettivi della protezione

Il sistema operativo deve garantire:

1. **IntegritÃ :** le risorse possono essere modificate solo da soggetti autorizzati.
2. **Riservatezza:** le informazioni sono accessibili solo a chi ne ha diritto.
3. **DisponibilitÃ :** le risorse devono rimanere accessibili agli utenti legittimi.

Per ottenere questi obiettivi, il sistema definisce un **modello di accesso controllato** tra *soggetti* (processi, utenti) e *oggetti* (file, dispositivi, aree di memoria).

---

### ðŸ”¹ 2. Domini di protezione

Un **dominio di protezione** Ã¨ un insieme di risorse e permessi associati a un soggetto (es. utente o processo).
Ogni dominio definisce **cosa un soggetto puÃ² fare** su un determinato oggetto.

Esempio:

| Oggetto         | Operazioni consentite |
| --------------- | --------------------- |
| File personale  | read, write           |
| File di sistema | read                  |
| Stampante       | write                 |
| Disco di swap   | nessuna               |

Durante lâ€™esecuzione, un processo puÃ² **cambiare dominio** (es. quando passa da modalitÃ  utente a kernel tramite una *system call*).

#### Implementazione pratica

- In UNIX/Linux ogni processo ha **UID (User ID)** e **GID (Group ID)**.
- Il kernel verifica i permessi ogni volta che viene effettuata unâ€™operazione su un file o una risorsa.

---

### ðŸ”¹ 3. Matrice di accesso

Il modello generale di protezione puÃ² essere rappresentato da una **matrice di accesso**, dove:

- **righe** = soggetti (utenti, processi);
- **colonne** = oggetti (file, dispositivi, memoria);
- **celle** = diritti di accesso concessi (read, write, execute).

#### Esempio

|             | file1   | file2 | stampante |
| ----------- | ------- | ----- | --------- |
| **utente1** | r, w    | r     | w         |
| **utente2** | r       | â€“     | â€“         |
| **root**    | r, w, x | r, w  | w         |

#### Rappresentazioni compatte

PoichÃ© la matrice completa Ã¨ molto grande e sparsa (molti campi vuoti), nella pratica si usano due approcci:

##### a) Liste di controllo dâ€™accesso (ACL â€“ Access Control List)

Per ogni **oggetto** si mantiene lâ€™elenco dei soggetti che possono accedervi e con quali permessi.

Esempio:

      ```text
      file1 â†’ [(utente1, rw), (utente2, r), (root, rwx)]

      ```

â†’ tipico modello UNIX (`rwxr-xr--`).

##### b) Capability List

Per ogni **soggetto** si mantiene lâ€™elenco degli oggetti a cui puÃ² accedere e con quali diritti.

Esempio:

      ```text
      utente1 â†’ [(file1, rw), (stampante, w)]

      ```

â†’ tipico dei sistemi distribuiti o microkernel (es. Mach, seL4).

---

### ðŸ”¹ 4. Meccanismi di controllo accessi

#### a) File system e permessi UNIX

Ogni file ha associati tre insiemi di permessi:

| Categoria      | Descrizione                            |
| -------------- | -------------------------------------- |
| **User (u)**   | Proprietario del file                  |
| **Group (g)**  | Utenti appartenenti allo stesso gruppo |
| **Others (o)** | Tutti gli altri utenti                 |

E tre bit di permesso:

| Permesso | Significato |
| -------- | ----------- |
| **r**    | lettura     |
| **w**    | scrittura   |
| **x**    | esecuzione  |

Esempio:

      ```text
      -rwxr-xr--
      ```

= il proprietario puÃ² leggere/scrivere/eseguire,
il gruppo puÃ² leggere/eseguire,
gli altri possono solo leggere.

#### b) Bit speciali

- **setuid (s):** esegue il programma con i permessi del proprietario, non dellâ€™utente corrente (es. `passwd`).
- **setgid (s):** eredita il gruppo del file.
- **sticky bit (t):** nei file condivisi (es. `/tmp`) impedisce la cancellazione da parte di utenti non proprietari.

---

### ðŸ”¹ 5. Autenticazione e autorizzazione

#### Autenticazione

Ãˆ il processo di **verifica dellâ€™identitÃ ** dellâ€™utente.

Metodi principali:

1. **Password (tradizionale):** confrontata con hash sicuro nel file `/etc/shadow`.
2. **Autenticazione a piÃ¹ fattori:** combinazione di elementi (password + token + biometria).
3. **Kerberos:** protocollo basato su ticket temporanei e cifrati (usato in ambienti enterprise).
4. **PAM (Pluggable Authentication Modules):** in Linux, sistema modulare per definire politiche di autenticazione (password, smartcard, LDAP, ecc.).

#### Autorizzazione

Avviene dopo lâ€™autenticazione: il sistema verifica **quali risorse e azioni** sono consentite allâ€™utente, consultando ACL, capability o policy del sistema.

---

### ðŸ”¹ 6. Protezione in modalitÃ  kernel e utente

Le CPU moderne operano in **due modalitÃ  di esecuzione**:

- **User mode:** accesso limitato, usata dai processi utente.
- **Kernel mode:** privilegi totali, usata dal sistema operativo.

Ogni **system call** implica un passaggio temporaneo in modalitÃ  kernel, seguito da un ritorno alla modalitÃ  utente.
Questo meccanismo serve a:

- proteggere la memoria del kernel e le tabelle del sistema;
- evitare che processi utente accedano direttamente allâ€™hardware.

---

### ðŸ”¹ 7. Sicurezza dei dati e cifratura

Per garantire la riservatezza delle informazioni anche in caso di furto fisico o attacco esterno, vengono adottate **tecniche di cifratura** (encryption).

#### a) Cifratura simmetrica

Stesso segreto (chiave) per cifrare e decifrare.

- Esempi: AES, DES, ChaCha20.
- Veloce, ma richiede un canale sicuro per scambiare la chiave.

#### b) Cifratura asimmetrica

Usa una coppia di chiavi:

- *pubblica** per cifrare, **privata** per decifrare.
- Esempi: RSA, ECC.
- Fondamentale per autenticazione, firme digitali, SSH.

#### c) Hash e integritÃ 

Funzioni unidirezionali che producono una *firma digitale* dei dati:

- SHA-256, SHA-3, BLAKE2.
- Usate per verificare che i file non siano stati alterati.

#### d) Cifratura del file system

- **LUKS (Linux Unified Key Setup)** o **BitLocker (Windows)**:
  cifrano intere partizioni o dischi con chiave derivata dalla password utente.

---

### ðŸ”¹ 8. Audit e logging

Ogni sistema operativo mantiene **registri di log** che tracciano eventi, accessi e modifiche critiche.
Servono per:

- **analisi forense** in caso di violazioni;
- **monitoraggio di sicurezza**;
- **rilevamento di intrusioni** (IDS, SIEM).

In Linux:

- `/var/log/auth.log` â†’ accessi e login;
- `/var/log/syslog` â†’ eventi di sistema;
- `auditd` â†’ log dettagliato delle system call.

---

### ðŸ”¹ 9. Backup e ripristino

Nessun sistema Ã¨ completamente sicuro senza **strategie di backup**.
Il backup garantisce la **disponibilitÃ ** dei dati anche dopo guasti o compromissioni.

#### Tipi principali

- **Full backup:** copia completa di tutti i file.
- **Incremental:** salva solo i file modificati dallâ€™ultimo backup.
- **Differential:** salva tutti i file modificati dal backup completo piÃ¹ recente.

#### Buone pratiche

- Backup periodici automatizzati (cron).
- Copie su supporti esterni o cloud cifrati.
- Test regolari dei ripristini.

---

### ðŸ§  Mappa concettuale di sintesi

      ```text

      SICUREZZA E PROTEZIONE
      â”‚
      â”œâ”€â”€ Obiettivi
      â”‚   â”œâ”€ IntegritÃ 
      â”‚   â”œâ”€ Riservatezza
      â”‚   â””â”€ DisponibilitÃ 
      â”‚
      â”œâ”€â”€ Domini di protezione
      â”‚   â”œâ”€ Ogni processo â†’ risorse + permessi
      â”‚   â””â”€ UID / GID in UNIX
      â”‚
      â”œâ”€â”€ Matrice di accesso
      â”‚   â”œâ”€ ACL â†’ per oggetto
      â”‚   â””â”€ Capability â†’ per soggetto
      â”‚
      â”œâ”€â”€ Meccanismi
      â”‚   â”œâ”€ Permessi UNIX (rwx)
      â”‚   â”œâ”€ setuid, setgid, sticky bit
      â”‚   â””â”€ ModalitÃ  kernel / utente
      â”‚
      â”œâ”€â”€ Autenticazione e autorizzazione
      â”‚   â”œâ”€ Password, Kerberos, PAM
      â”‚   â”œâ”€ ACL e policy
      â”‚   â””â”€ Controllo post-login
      â”‚
      â”œâ”€â”€ Cifratura e sicurezza dati
      â”‚   â”œâ”€ Simmetrica â†’ AES
      â”‚   â”œâ”€ Asimmetrica â†’ RSA, ECC
      â”‚   â”œâ”€ Hash â†’ SHA, BLAKE2
      â”‚   â””â”€ Full disk encryption (LUKS, BitLocker)
      â”‚
      â”œâ”€â”€ Audit e logging
      â”‚   â”œâ”€ /var/log/, auditd
      â”‚   â”œâ”€ IDS / SIEM
      â”‚   â””â”€ Analisi forense
      â”‚
      â””â”€â”€ Backup e ripristino
         â”œâ”€ Full, Incremental, Differential
         â””â”€ Copie sicure e test periodici

      ```
