# Sincronizzazione (I)

---

## üîπ Introduzione

In un sistema multiprogrammato o multithread, pi√π processi o thread possono essere **attivi contemporaneamente** e condividere **risorse comuni**, come variabili, file o dispositivi.
Quando due o pi√π attivit√† tentano di accedere contemporaneamente a una risorsa condivisa, possono verificarsi **condizioni di competizione (race conditions)**, che portano a risultati **imprevedibili e non deterministici**.

Per evitare questi problemi, il sistema operativo (e il programmatore) devono garantire una **sincronizzazione corretta** tra i processi concorrenti, assicurando che **le operazioni critiche siano eseguite in modo mutualmente esclusivo**.

---

## üîπ 1. Sezione critica

La **sezione critica** √® la parte di codice di un processo che **accede a risorse condivise** (variabili, buffer, dispositivi).
Durante l‚Äôesecuzione della sezione critica, **nessun altro processo** deve poter accedere alle stesse risorse.

### Struttura generale di un processo

```plaintext
while (true) {
    Entry Section    ‚Üí Richiede accesso alla sezione critica
    Critical Section ‚Üí Accesso alla risorsa condivisa
    Exit Section     ‚Üí Rilascia la risorsa
    Remainder Section ‚Üí Codice non critico
}
```

L‚Äôobiettivo √® progettare **protocolli di sincronizzazione** che garantiscano tre propriet√† fondamentali:

1. **Mutua esclusione:**
   solo un processo alla volta pu√≤ essere nella sezione critica.

2. **Progresso:**
   se nessun processo √® nella sezione critica, solo i processi che desiderano entrarvi possono decidere chi entra, evitando attese inutili.

3. **Attesa limitata (bounded waiting):**
   nessun processo deve restare in attesa indefinitamente (assenza di starvation).

---

## üîπ 2. Condizioni di competizione (Race Conditions)

Una **race condition** si verifica quando l‚Äôesito finale di un programma **dipende dall‚Äôordine di esecuzione** dei processi concorrenti.
Questo accade perch√© pi√π processi **leggono e scrivono simultaneamente** su una risorsa condivisa senza sincronizzazione.

### Esempio classico

Supponiamo due processi P1 e P2 che incrementano una variabile condivisa `x`:

```text
P1: x = x + 1
P2: x = x + 1
```

In assenza di sincronizzazione, la sequenza di esecuzione potrebbe essere:

```text
P1 legge x = 5
P2 legge x = 5
P1 scrive x = 6
P2 scrive x = 6
```

‚Üí risultato finale: `x = 6` invece di `7`.

Questo problema nasce perch√© le operazioni non sono atomiche (lettura + modifica + scrittura) e si sovrappongono.

---

## üîπ 3. Soluzioni software alla mutua esclusione

Prima dell‚Äôintroduzione di meccanismi hardware e primitivi del kernel, sono state sviluppate **soluzioni puramente software** per garantire l‚Äôaccesso esclusivo alla sezione critica.
Queste soluzioni operano tramite variabili condivise e cicli di controllo (busy waiting).

### a) Disabilitazione degli interrupt (solo kernel)

Nel kernel, la CPU pu√≤ **disabilitare gli interrupt** durante l‚Äôesecuzione di codice critico:

```c
disable_interrupts();
critical_section();
enable_interrupts();
```

‚Üí impedisce che venga eseguito un context switch.

**Vantaggi:**

* Soluzione semplice ed efficace per il codice del kernel.

**Svantaggi:**

* Non applicabile ai processi utente.
* Rende il sistema meno reattivo (gli interrupt vengono ritardati).
* Pericolosa su architetture multicore (non blocca gli altri core).

---

### b) Soluzione di Peterson

La **soluzione di Peterson** √® un algoritmo software classico per due processi, basato su due variabili condivise:

* `flag[i]`: indica se il processo *i* vuole entrare nella sezione critica.
* `turn`: indica a chi tocca entrare.

```c
flag[i] = true;
turn = j;
while (flag[j] && turn == j);
critical_section();
flag[i] = false;
```

**Funzionamento:**

* Ogni processo segnala la propria intenzione (`flag[i] = true`) e cede momentaneamente la priorit√† all‚Äôaltro (`turn = j`).
* Solo quando l‚Äôaltro non √® interessato o non ha il turno, pu√≤ entrare nella sezione critica.

**Propriet√†:**
‚úî Mutua esclusione
‚úî Progresso
‚úî Attesa limitata

**Limiti:** valida solo per due processi; inefficiente su sistemi multiprocessore.

---

### c) Algoritmo del panettiere (Bakery Algorithm)

Proposto da Lamport, estende la soluzione di Peterson a **pi√π processi**.

Ogni processo prende un ‚Äúnumero‚Äù come in una panetteria:
quello con il numero pi√π basso entra per primo nella sezione critica.

```c
choosing[i] = true;
number[i] = 1 + max(number[0..n-1]);
choosing[i] = false;
while (‚àÉ j: (choosing[j] || (number[j] != 0 && 
     (number[j], j) < (number[i], i))));
critical_section();
number[i] = 0;
```

**Propriet√†:**

* Garantisce mutua esclusione e ordine FIFO.
* Completamente software.

**Svantaggi:**

* Elevato overhead per confronti multipli.
* Poco pratico nei sistemi reali.

---

## üîπ 4. Soluzioni hardware

Per migliorare l‚Äôefficienza, i moderni processori offrono **istruzioni atomiche** che garantiscono mutua esclusione senza busy waiting esplicito.

### a) Test-and-Set

Istruzione atomica che **legge e modifica** contemporaneamente una variabile di lock.

```c
boolean TestAndSet(boolean *target) {
    boolean old = *target;
    *target = true;
    return old;
}
```

**Esempio d‚Äôuso:**

```c
while (TestAndSet(&lock)); // attende finch√© lock non √® false
critical_section();
lock = false;
```

‚Üí nessuna interruzione pu√≤ interferire durante l‚Äôistruzione atomica.

**Problema:**
causa *busy waiting* (la CPU consuma cicli in attesa).

---

### b) Swap (Exchange)

Scambia in modo atomico il contenuto di due variabili:

```c
Swap(a, b):
    temp = a;
    a = b;
    b = temp;
```

Pu√≤ essere usato per implementare meccanismi simili a Test-and-Set.

---

### c) Compare-and-Swap (CAS)

Istruzione pi√π evoluta: confronta il valore di una variabile e, se corrisponde a quello atteso, lo sostituisce con un nuovo valore.
√à la base dei **lock-free algorithms** nei sistemi multiprocessore.

```c
boolean CAS(int *ptr, int expected, int new) {
    if (*ptr == expected) {
        *ptr = new;
        return true;
    } else return false;
}
```

---

## üîπ 5. Semafori

Proposti da Dijkstra, i **semafori** rappresentano una **soluzione generale e astratta** per gestire la sincronizzazione tra processi, evitando l‚Äôuso diretto di busy waiting.

Un semaforo √® una **variabile intera S** che pu√≤ assumere valori ‚â• 0, e viene manipolata tramite due operazioni atomiche:

```plaintext
wait(S):   // P (proberen, "provare")
    while (S <= 0)
        ; // attende
    S = S - 1

signal(S): // V (verhogen, "incrementare")
    S = S + 1
```

### Tipologie di semafori

* **Semaforo binario (mutex):** pu√≤ valere solo 0 o 1 ‚Üí usato per mutua esclusione.
* **Semaforo contatore:** rappresenta un numero di risorse disponibili (es. posti in un buffer).

### Vantaggi

* Semplice da implementare a livello di kernel.
* Evita race conditions e garantisce mutua esclusione.

### Svantaggi

* Se implementato con busy waiting ‚Üí spreco CPU.
  (In sistemi reali, il processo viene messo in coda e sospeso.)

---

## üîπ 6. Problema Produttore‚ÄìConsumatore

Il **problema del produttore‚Äìconsumatore** (o **bounded buffer problem**) √® un classico esempio di uso dei semafori.

### Descrizione

* Un **produttore** genera dati e li inserisce in un buffer.
* Un **consumatore** preleva dati dallo stesso buffer.
* Il buffer ha **capacit√† limitata** ‚Üí serve sincronizzazione per evitare:

  * produzione oltre la capacit√† (overflow),
  * consumo di buffer vuoto (underflow).

### Soluzione con semafori

```c
semaphore mutex = 1;   // accesso esclusivo al buffer
semaphore full = 0;    // numero di elementi pieni
semaphore empty = N;   // numero di spazi liberi

Producer:
while (true) {
    produce_item();
    wait(empty);
    wait(mutex);
    insert_item();
    signal(mutex);
    signal(full);
}

Consumer:
while (true) {
    wait(full);
    wait(mutex);
    remove_item();
    signal(mutex);
    signal(empty);
    consume_item();
}
```

‚úî Evita overflow e underflow
‚úî Garantisce mutua esclusione
‚úî Sincronizza correttamente produttore e consumatore

---

## üß† Mappa concettuale di sintesi

```plaintext
SINCRONIZZAZIONE (I)
‚îÇ
‚îú‚îÄ‚îÄ Sezione critica
‚îÇ   ‚îú‚îÄ Accesso a risorse condivise
‚îÇ   ‚îú‚îÄ Propriet√†: mutua esclusione, progresso, attesa limitata
‚îÇ
‚îú‚îÄ‚îÄ Race condition
‚îÇ   ‚îî‚îÄ Esito dipende dall‚Äôordine di esecuzione
‚îÇ
‚îú‚îÄ‚îÄ Soluzioni software
‚îÇ   ‚îú‚îÄ Disabilitazione interrupt (solo kernel)
‚îÇ   ‚îú‚îÄ Peterson ‚Üí 2 processi
‚îÇ   ‚îî‚îÄ Bakery ‚Üí n processi, numerazione
‚îÇ
‚îú‚îÄ‚îÄ Soluzioni hardware
‚îÇ   ‚îú‚îÄ Test-and-Set
‚îÇ   ‚îú‚îÄ Swap
‚îÇ   ‚îî‚îÄ Compare-and-Swap (CAS)
‚îÇ
‚îú‚îÄ‚îÄ Semafori
‚îÇ   ‚îú‚îÄ Operazioni P (wait) / V (signal)
‚îÇ   ‚îú‚îÄ Binario e contatore
‚îÇ   ‚îî‚îÄ Gestiti dal kernel (no busy waiting)
‚îÇ
‚îî‚îÄ‚îÄ Problema Produttore‚ÄìConsumatore
    ‚îú‚îÄ Buffer limitato
    ‚îú‚îÄ Semafori: mutex, full, empty
    ‚îî‚îÄ Evita overflow/underflow
```
